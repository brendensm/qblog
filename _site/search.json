[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Brenden Smith, MPH",
    "section": "",
    "text": "Hi, I’m Brenden. I am an epidemiologist, community researcher, and R enthusiast. I am passionate about health equity, harm reduction, and community engagement.\nIf you would like to see some of my current and past work, you can visit my portfolio page or check out my blog."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome to my Blog",
    "section": "",
    "text": "This is hard for me to do! I’ve been wanting to start blogging for some time now. This whole website is only possible because of the wonderful blog posts by Bea Milz and Alber Rapp. A huge huge thank you to them both. Their posts demonstrate how easy it is to get up and running with a Quarto blog!\nInspired by their words, there is no better time to start writing. So consider this a first introduction. I am setting the intention to post monthly to this blog."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Posts related to R are shared to R-bloggers.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCDCPLACES 1.1.8: 2024 Release\n\n\n\n\n\n\nR\n\n\npackages\n\n\nmaps\n\n\nCDCPLACES\n\n\n\nNew measures, query ZCTAs, and filter by category.\n\n\n\n\n\nAug 12, 2024\n\n\nBrenden Smith\n\n\n\n\n\n\n\n\n\n\n\n\nInteractive Map Filter in Shiny\n\n\n\n\n\n\nR\n\n\nmaps\n\n\n\n\n\n\n\n\n\nJun 26, 2024\n\n\nBrenden Smith\n\n\n\n\n\n\n\n\n\n\n\n\nI Made R Text For Me\n\n\n\n\n\n\nR\n\n\nCommand line\n\n\n\nDo you ever wish that text message would just send itself?\n\n\n\n\n\nMar 23, 2024\n\n\nBrenden Smith\n\n\n\n\n\n\n\n\n\n\n\n\nWhat’s New in CDCPLACES 1.1.5\n\n\n\n\n\n\nR\n\n\npackages\n\n\nAPI\n\n\nvignette\n\n\nmaps\n\n\nCDCPLACES\n\n\n\nMap PLACES data easily with the help of tigris.\n\n\n\n\n\nMar 19, 2024\n\n\nBrenden Smith\n\n\n\n\n\n\n\n\n\n\n\n\nIntroducing the CDCPLACES Package\n\n\n\n\n\n\nR\n\n\npackages\n\n\nAPI\n\n\nvignette\n\n\nCDCPLACES\n\n\n\nA brief vignette demonstrating the use of the package CDCPLACES.\n\n\n\n\n\nJan 10, 2024\n\n\nBrenden Smith\n\n\n\n\n\n\n\n\n\n\n\n\nIntro to Bash Scripting\n\n\n\n\n\n\nCommand line\n\n\nR\n\n\n\nCreating a simple R project set up tool.\n\n\n\n\n\nNov 15, 2023\n\n\nBrenden Smith\n\n\n\n\n\n\n\n\n\n\n\n\nSurvival Analysis in R\n\n\n\n\n\n\nR\n\n\nEpi\n\n\nggplot2\n\n\n\nExploring survival analysis with the package survival.\n\n\n\n\n\nOct 24, 2023\n\n\nBrenden Smith\n\n\n\n\n\n\n\n\n\n\n\n\nHM878: Helper Functions\n\n\n\n\n\n\nR\n\n\npackages\n\n\nvignette\n\n\n\nA walkthrough of the helper functions in the package hm878\n\n\n\n\n\nOct 12, 2023\n\n\nBrenden Smith\n\n\n\n\n\n\n\n\n\n\n\n\nTwitter Bots\n\n\n\n\n\n\nR\n\n\ncolor\n\n\nweb-scraping\n\n\n\n‘Suppose I were to begin by saying that I had fallen in love with a color.’\n\n\n\n\n\nMar 1, 2023\n\n\nBrenden Smith\n\n\n\n\n\n\n\n\n\n\n\n\nMichigan COVID-19 County Maps\n\n\n\n\n\n\nR\n\n\nmaps\n\n\n\nTwo quick, interactive COVID-19 maps.\n\n\n\n\n\nOct 11, 2022\n\n\nBrenden Smith\n\n\n\n\n\n\n\n\n\n\n\n\nOpioid Plotting Practice\n\n\n\n\n\n\nR\n\n\nggplot2\n\n\n\nA basic ggplot2 walkthrough and an introduction to plotly.\n\n\n\n\n\nOct 9, 2022\n\n\nBrenden Smith\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html#header-two",
    "href": "posts/welcome/index.html#header-two",
    "title": "Welcome",
    "section": "Header two",
    "text": "Header two\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/test post/index.html",
    "href": "posts/test post/index.html",
    "title": "test post",
    "section": "",
    "text": "This is my test."
  },
  {
    "objectID": "posts/welcome/index.html#who-am-i",
    "href": "posts/welcome/index.html#who-am-i",
    "title": "Welcome to my Blog (-:",
    "section": "Who am I?",
    "text": "Who am I?\nMy name is Brenden Smith. At this point, I am a little over a year into my graduate studies. I attend Michigan State University and I am working towards my Master in Public Health."
  },
  {
    "objectID": "posts/welcome/index.html#what-will-i-post",
    "href": "posts/welcome/index.html#what-will-i-post",
    "title": "Welcome to my Blog",
    "section": "What will I post?",
    "text": "What will I post?\nTo start, I think I will document certain projects I’ve taken on that relate to data analysis and visualization. I consider myself a beginning to intermediate level R user. To help me retain the information I’m learning, I will try to blog everything that seems worth sharing. I hope that these help you, if you are trying to learn more about R like I am.\nI don’t want my posts to be exclusive to R. Like any tool, the language has its strengths and weaknesses. I will likely include some content on PowerBI and perhaps its integration with R. I also want to document notable takeaways from my experiences in graduate school and other projects I am involved with in my professional work."
  },
  {
    "objectID": "posts/welcome/index.html#stay-in-touch",
    "href": "posts/welcome/index.html#stay-in-touch",
    "title": "Welcome to my Blog",
    "section": "Stay in touch",
    "text": "Stay in touch\nIf this description interests you, please follow along with my journey. If you are interested in hearing more about my work or would like to share resources, let me know! I have included links to my GitHub, Twitter, and LinkedIn. Feel free to reach out to my on any of those platforms (or comment here on my blog)."
  },
  {
    "objectID": "posts/Michigan COVID Cases and Deaths by County/index.html",
    "href": "posts/Michigan COVID Cases and Deaths by County/index.html",
    "title": "Michigan COVID-19 County Maps",
    "section": "",
    "text": "This post is intended to demonstrate some basic ways to map data in R. For our example, we will be creating a choropleth map of Michigan’s counties featuring COVID-19 data. The result is something quite similar to the map featured on the state’s dashboard. The data used in this post is from October 4, 2022.\nFor the sake of practice, we will walk through two different ways to go about this process. First we will use ggplot2. We will use a function called map_data to pull in shape file data easily. In our second example, we will use leaflet to create a better looking version of this map and use a raw shape file."
  },
  {
    "objectID": "posts/shiny/index.html",
    "href": "posts/shiny/index.html",
    "title": "Shiny test",
    "section": "",
    "text": "Warning: package 'tidycensus' was built under R version 4.1.2\n\n\nWarning: package 'leaflet' was built under R version 4.1.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.2      ✔ forcats 0.5.1 \n\n\nWarning: package 'tibble' was built under R version 4.1.2\n\n\nWarning: package 'tidyr' was built under R version 4.1.2\n\n\nWarning: package 'readr' was built under R version 4.1.2\n\n\nWarning: package 'dplyr' was built under R version 4.1.2\n\n\nWarning: package 'stringr' was built under R version 4.1.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nTo install your API key for use in future sessions, run this function with `install = TRUE`.\n\n\nGetting data from the 2016-2020 5-year ACS\n\n\nDownloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.\n\n\nFetching data by table type (\"B/C\", \"S\", \"DP\") and combining the result.\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |=======                                                               |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |================                                                      |  22%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |=================================                                     |  48%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |===================================                                   |  51%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |=======================================                               |  55%\n  |                                                                            \n  |========================================                              |  56%\n  |                                                                            \n  |========================================                              |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |===============================================                       |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |=====================================================                 |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |==========================================================            |  82%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |=================================================================     |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |======================================================================|  99%\n  |                                                                            \n  |======================================================================| 100%"
  },
  {
    "objectID": "posts/Michigan COVID Cases and Deaths by County/index.html#using-leaflet",
    "href": "posts/Michigan COVID Cases and Deaths by County/index.html#using-leaflet",
    "title": "Michigan COVID-19 County Maps",
    "section": "Using Leaflet",
    "text": "Using Leaflet\n\n\nCode\n# leaflet -----------------------------------------------------------------\nlibrary(sp)\nlibrary(tigris)\nlibrary(leaflet)\n\nmiCounties &lt;- counties(state = \"MI\", cb = TRUE, progress_bar = FALSE)\n\nmicovid &lt;- micovid %&gt;%\n  mutate(NAME = case_when(\n    COUNTY == \"St Clair\" ~ \"St. Clair\",\n    COUNTY == \"St Joseph\" ~ \"St. Joseph\",\n    TRUE ~ COUNTY\n  ))\n\ncombined &lt;- merge(miCounties, micovid)\n\n\n# pals and labels for each map -------------------------------------------------------\n\ncase_bins &lt;- c(0, 1000, 5000, 15000, 30000, 100000, Inf)\ncase_pal &lt;- colorBin(\"Blues\", domain = combined$total_cases, bins = case_bins)\n\ncase_labels &lt;- sprintf(\n  \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br/&gt;Cases: %g\",\n  combined$NAME, combined$total_cases\n) %&gt;% lapply(htmltools::HTML)\n\ndeath_bins &lt;- c(0, 50, 100, 150, 500, 1500, 3000, Inf)\n\ndeath_pal &lt;- colorBin(\"Reds\", domain = combined$total_deaths, bins = death_bins)\n\ndeath_labels  &lt;- sprintf(\n  \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br/&gt;Deaths: %g\",\n  combined$NAME, combined$total_deaths\n) %&gt;% lapply(htmltools::HTML)\n\nleaflet() %&gt;% \n  addTiles(group = \"base\") %&gt;%\n  addPolygons(data = combined,\n              group = \"Cases\",\n              fillColor = ~case_pal(total_cases),\n              weight = 2,\n              opacity = 1,\n              color = \"white\",\n              dashArray = \"3\",\n              fillOpacity = 0.7,\n              highlightOptions = highlightOptions(\n                weight = 5,\n                color = \"#666\",\n                dashArray = \"\",\n                fillOpacity = 0.7,\n                bringToFront = TRUE),\n              label = case_labels,\n              labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"15px\",\n                direction = \"auto\")) %&gt;%\n  addLegend(data = combined,\n            title = \"Cases\",\n            pal = case_pal, values = ~total_cases, opacity = 0.7,\n            position = \"bottomright\", group = \"Cases\") %&gt;%\n  addPolygons(data = combined,\n              group = \"Deaths\",\n              fillColor = ~death_pal(total_deaths),\n              weight = 2,\n              opacity = 1,\n              color = \"white\",\n              dashArray = \"3\",\n              fillOpacity = 0.7,\n              highlightOptions = highlightOptions(\n                weight = 5,\n                color = \"#666\",\n                dashArray = \"\",\n                fillOpacity = 0.7,\n                bringToFront = TRUE),\n              label = death_labels,\n              labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"15px\",\n                direction = \"auto\")) %&gt;%\n  addLegend(data = combined, \n            title = \"Deaths\",\n            pal = death_pal, values = ~total_deaths, opacity = 0.7,\n            position = \"bottomright\", group = \"Deaths\") %&gt;%\n  addLayersControl(overlayGroups = c(\"Cases\", \"Deaths\"),\n                   options = layersControlOptions(collapsed = FALSE)) %&gt;%\n  hideGroup(\"Deaths\")"
  },
  {
    "objectID": "posts/welcome/index.html#so-who-am-i",
    "href": "posts/welcome/index.html#so-who-am-i",
    "title": "Welcome to my Blog",
    "section": "So who am I?",
    "text": "So who am I?\nMy name is Brenden Smith. At this point, I am a little over a year into my graduate studies. I attend Michigan State University and I am working towards my Master in Public Health. I am most interested in data analysis, visualization, community-engaged research, and health disparities.\nPublic health as a field can be very broad. By its very nature, the field is multidisciplinary and covers a wide array of topics. I come from primarily a policy background. I received my Bachelor of Arts in social relations and policy from James Madison College (also here at MSU). My senior seminar was focused on US health care and policy and pretty much ever since I’ve been interested in a career in PH.\nDuring my undergrad I was also introduced to R for the first time in a quantitative methods course. That introduction began my interest in the programming language. More recently I have discovered the tidyverse and shiny packages. It is so exciting to be a part of the open-source community. I hope to contribute to it as I have most definitely benefited from the wealth of knowledge already available on the internet."
  },
  {
    "objectID": "posts/Michigan COVID Cases and Deaths by County/index.html#ggplot2-map",
    "href": "posts/Michigan COVID Cases and Deaths by County/index.html#ggplot2-map",
    "title": "Michigan COVID-19 County Maps",
    "section": "Ggplot2 map",
    "text": "Ggplot2 map\nTo start, we will make a base map with ggplot2 and make it interactive with plotly. First, as always, we load in the libraries we will be using.\n\n\nCode\n# Load packages -----------------------------------------------------------\nlibrary(tidyverse) # really just dplyr but the whole verse can't hurt\nlibrary(openxlsx) # to read in excel data\nlibrary(plotly) # for the interactive part\nlibrary(RColorBrewer) # to set our color palette\n\n\nNext, we will get our county map. To do this we can simply call the function map_data and specify that we want it at the county level. This will give us data for every county in the US. Because we are only mapping Michigan, we add a second line to subset our first data frame ‘counties’ to only include Michigan.\n\n\nCode\n# Make the base state map -------------------------------------------------\ncounties &lt;- map_data(\"county\")\nmi_county &lt;- subset(counties, region == \"michigan\")\n\n\nFor our COVID-19 data, I am importing an older file from state’s website (linked previously). If you want a current version to follow along, you can find it there. Once the file is loaded into R Studio, we need to make a few adjustments. The original file splits the cases into two categories, confirmed and probable. On the state’s dashboard, they combine these numbers into a total for map reporting. We will do the same. This is easily done with the group_by and summarise functions. We will also change the county names to lowercase in preparation for merging.\n\n\nCode\n# Data prep ---------------------------------------------------------------\nmicovid &lt;- read.xlsx(\"Cases and Deaths by County 2022-10-04.xlsx\")\n\nmicovid &lt;- micovid %&gt;%\n  group_by(COUNTY) %&gt;%\n  summarise(total_cases = sum(Cases),\n            total_deaths = sum(Deaths)) %&gt;%\n  ungroup() %&gt;%\n  mutate(subregion = tolower(COUNTY))\n\ncases_and_county &lt;- inner_join(mi_county, micovid, by = \"subregion\")\ncases_and_county &lt;- cases_and_county %&gt;%\n  rename(county = COUNTY)\n\n\n\n\nCode\ncases_and_county&lt;- cases_and_county %&gt;%\n  mutate(Category = case_when(total_cases &lt; 1000 ~ '0-999', \n                              total_cases &lt; 5000 ~ '1000-4999',\n                              total_cases &lt;15000 ~ '5000-14999',\n                              total_cases &lt; 30000 ~ '15000-29999',\n                              total_cases &lt; 100000~ '30000-99999',\n                              total_cases &lt; 1000000 ~ '100000+',\n                              TRUE ~ 'NA'))\n\ncases_and_county$Category &lt;- as.factor(cases_and_county$Category)\n\nlvls &lt;- c('0-999', \n          '1000-4999',\n          '5000-14999',\n          '15000-29999',\n          '30000-99999',\n          '100000+')\n\ncases_and_county$Category &lt;- fct_relevel(cases_and_county$Category, lvls)\n\n\n\n\nCode\n# Making the map ----------------------------------------------------------\n\np &lt;- c(\"#ACD1E7\", \"#82BADC\", \"#59A1CF\", \"#236893\",\"#174562\", \"#122548\")\n\nlabel &lt;- list(\n  bgcolor = \"#EEEEEE\",\n  font = list(color = \"black\")\n)\n\nnoax &lt;- list(\n  title = \"\",\n  zeroline = FALSE,\n  showline = FALSE,\n  showticklabels = FALSE,\n  showgrid = FALSE\n)\n\ng &lt;- cases_and_county %&gt;%\n  ggplot(aes(long, lat, \n                group = group,\n                text = paste('&lt;/br&gt;County:', county, '&lt;/br&gt;Category:', Category,\n                             '&lt;/br&gt;Cases:', total_cases)))+\n  geom_polygon(colour = alpha(\"black\", 1/2), fill = NA) +\n  geom_polygon(data = cases_and_county, colour = \"black\", aes(fill = Category))+\n  theme_void() +\n  scale_fill_manual(values = p) \n\n\n\n\nCode\nggplotly(g, tooltip = c(\"text\"), width = 700, height = 600) %&gt;%\n  layout(xaxis = noax,\n         yaxis = noax) %&gt;%\n  style(hoverlabel = label) %&gt;%\n  config(displayModeBar = FALSE)"
  },
  {
    "objectID": "posts/Michigan COVID Cases and Deaths by County/index.html#conclusion",
    "href": "posts/Michigan COVID Cases and Deaths by County/index.html#conclusion",
    "title": "Michigan COVID-19 County Maps",
    "section": "Conclusion",
    "text": "Conclusion"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Portfolio",
    "section": "",
    "text": "R Shiny Apps\n\n\nFeatured work using Shiny.\n\n\n\nBrenden Smith\n\n\nJan 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAcademic Posters\n\n\nVarious academic and professional projects that I have prepared into poster presentations.\n\n\n\nBrenden Smith\n\n\nAug 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTidy Tuesday\n\n\nAn ongoing collection of practice visualizations from the Tidy Tuesday weekly data project.\n\n\n\nBrenden Smith\n\n\nFeb 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPowerBI Dashboards\n\n\nA collection of work of mine in PowerBI.\n\n\n\nBrenden Smith\n\n\nDec 10, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/Michigan COVID-19 Dashboard/index.html",
    "href": "projects/Michigan COVID-19 Dashboard/index.html",
    "title": "PowerBI Dashboards",
    "section": "",
    "text": "Power BI\nThis page shows the Power BI projects that I have created in my academic and professional work. Samples below contain publicly available data.\n\n\nCOVID-19 Long Term Care Data Dashboard\nThis project was created to support the MDHHS long term care data reporting live on their website. I joined this project in early 2023 and recreated an existing dashboard that was made in Tableau into a PowerBI format. This was done to ease the integration process. The dashboard went live in March and was regularly updated until mid-May. This change was due to changing data reporting requirements.\n\n\n\nCOVID-19 Cases and Deaths by County\nThis past semester, I had the pleasure of taking a course on health informatics. We were tasked with creating an entire interactive dashboard using Power BI. This is my first experience using the software, and I have to say it is a lot of fun to play around with. After learning some of the ins and outs of exporting and transforming data, formatting beautiful visualizations came surprisingly easy.\nThe dashboard featured here is a re-imagining of the State’s current COVID-19 dashboard. I began with recreating the content they already provide. This entire project was made using the publicly available data files on the SOM’s website. In the last tab, I incorporated the CDC’s community level data that they provide for each state. I included this as the data provided is made comparable by population standardization, and increasingly, it seems that officials are looking to these levels specifically for policy guidance.\nTo view the dashboard in full screen you can use the link here. Below is the embedded dashboard. Enjoy!"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "#####Minor in Chicano/Latino Studies"
  },
  {
    "objectID": "projects/Tidy Tuesday/index.html",
    "href": "projects/Tidy Tuesday/index.html",
    "title": "Tidy Tuesday",
    "section": "",
    "text": "::: .g-col-12 .g-col-md-6} \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "posts/Bluets/index.html",
    "href": "posts/Bluets/index.html",
    "title": "Twitter Bots",
    "section": "",
    "text": "Update: Since a certain someone took over the bird app, this bot is no longer functional. Unfortunately, it is not worth paying $100/month to post random shades of blue. What an injustice."
  },
  {
    "objectID": "posts/Bluets/index.html#using-rvest",
    "href": "posts/Bluets/index.html#using-rvest",
    "title": "Twitter Bots",
    "section": "Using ‘rvest’",
    "text": "Using ‘rvest’\nTo help us source our data, the library 'rvest' provides everything we need. In order to create a data frame containing the color name and the hex code, we need to:\n\nimport the web search’s html\npull out the two elements from the code (name, hex code)\nthen repeat this process for each of the 89 pages\n\nThe function 'read_html' from rvest makes the first step incredibly easily. For this, we simply pass in the web address as an argument in the function and save the output as a new value called 'page'.\n\n\nCode\nlibrary(rvest)\nlink &lt;- \"https://www.color-name.com/search/blue\"\npage &lt;- read_html(link)\n\n\nNext, we’ll pass 'page' into the function 'html_nodes' and then into 'html_text' to extract the desired string vector. The text passed through 'html_nodes' must be sourced from the webpage you are scraping from. You can use the ‘inspect’ feature in Google Chrome, or the Chrome extension ‘SelectorGadget’ to find the proper tag to use.\n\n\nCode\nname &lt;- page |&gt; html_nodes(\"h2 a\") |&gt; html_text()\nhex &lt;- page |&gt; html_nodes(\".hx\") |&gt; html_text()\n\n\nOnce that is done, we can take both vectors and create a data frame.\n\n\nCode\ncolors &lt;- data.frame(name, hex, stringsAsFactors = FALSE)\n\n\nIn order to collect each page of data, it is easiest to use a for loop. For this we make a couple of changes. First, we will create an empty data frame titled 'colors' to store data in for each iteration of the loop. Because there are 89 pages, we set the for loop to iterate that many times. We store this as 'page_result' in the loop and change the url to match what is displayed on each page number then use 'paste0' to put them together. Lastly, I added 'rbind' to add the new rows to the 'colors' data frame and a print command to keep track of the loop progress.\n\n\nCode\ncolors &lt;- data.frame()\n\nfor (page_result in 1:89){\n  \n  link &lt;- paste0(\"https://www.color-name.com/search/blue/page/\", page_result)\n  \n  page &lt;- read_html(link)\n  \n  name &lt;- page |&gt; html_nodes(\"h2 a\") |&gt; html_text()\n  hex &lt;- page |&gt; html_nodes(\".hx\") |&gt; html_text()\n  \n  colors &lt;- rbind(colors, data.frame(name, hex, stringsAsFactors = FALSE))\n  \n  print(paste(\"Page:\", page_result))\n}\n\n\nAnd as a last step, I decided to clean up the colors a bit. Even though the search used the key word 'blue', I noticed that the last page displayed colors that did not have the word 'blue' in the title. To fix this, I filtered out any color that did not contain the word.\n\n\nCode\nlibrary(dplyr)\nblues &lt;- colors |&gt; filter(grepl('Blue', name))"
  },
  {
    "objectID": "projects/AcademyHealth Poster/index.html",
    "href": "projects/AcademyHealth Poster/index.html",
    "title": "Academic Posters",
    "section": "",
    "text": "Opioid Overdose Mortalities and Emergency Department Visits in Michigan Counties and ZCTAs\nThis poster was presented at the Michigan Epidemiology Conference in Saginaw, Michigan on April 12, 2024.\n\n\n\nBarriers to Refuse Disposal in Larteh, Ghana\nThis poster was put together as a result of my research experiences in Ghana. This project fulfilled my practicum requirement for my MPH program. This poster was presented at the Consortium of Universities for Global Health Conference on March 9, 2024, in Los Angeles, California.\n\n\n\nAcademyHealth Poster: Mental Health and the Pandemic\nThis research was put together in collaboration with Ann Annis and Wenjuan Ma. This poster would not be possible without their dedication and support!"
  },
  {
    "objectID": "projects/Mental Health and the Pandemic/index.html",
    "href": "projects/Mental Health and the Pandemic/index.html",
    "title": "Mental Health and the Pandemic",
    "section": "",
    "text": "Introduction\nThis project was originally a submission to the National Center for Health Statistics and AcademyHealth sponsored Data Visualization Challenge in Fall of 2022.\nThis web application was my first experience building a Shiny application! I found it fascinating to dive into the mechanics of making a usable, interactive web application for data exploration.\nThis project uses data from the Household Pulse Survey as well as data from the Uniform Data System to understand mental illness during the pandemic years. HHP data shows national trends for varying mental illnesses while the UDS data speaks to the experience of patients accessing care at federally qualified health centers throughout the country. We added this data and compared it with poverty rates across U.S. counties (American Community Survey) and mental health provider shortage levels (Area Health Resources Files).\nMy favorite part of this challenge was getting to create large, interactive maps to explore these data.\nWhile the application could be embedded here, it is best viewed in its own window. You can access the app and the full data here."
  },
  {
    "objectID": "posts/opioid plotting practice/index.html",
    "href": "posts/opioid plotting practice/index.html",
    "title": "Opioid Plotting Practice",
    "section": "",
    "text": "Over the summer, I took a course on public health surveillance. As a culminating project, we were tasked with creating original data visualizations for a fact sheet on a topic of our choosing. I chose to examine local opioid overdose and mortality data for my project.\nThis is a topic that is near to me. The opioid crisis has impacted many communities across the country. At this point, the topic is well known to most people. Despite awareness, overdoses are still rising.\nIn the following post, I will demonstrate how easily you can spice up basic ggplot graphics. In particular we will look at:\n\na basic ggplot2 line chart\nggthemes we can use to make a more professional looking figure\nand a brief glimpse at plotly (because interactive graphs are so cool!)"
  },
  {
    "objectID": "posts/opioid plotting practice/index.html#data-prep",
    "href": "posts/opioid plotting practice/index.html#data-prep",
    "title": "Opioid Plotting Practice",
    "section": "Data Prep",
    "text": "Data Prep\nTo begin, we will load in our libraries. Be sure to install them if you haven’t already.\n\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(readxl)\nlibrary(plotly)\n\nNext, we will read in our data using readxl. The data I am using comes from the Michigan Substance Use Disorder Data Repository (SUDDR). You can download the data yourself here. Keep in mind that the numbers we are working with in this example are raw counts of opioid overdose deaths by county, NOT rates. Therefore, we should not compare these counties against each other without considering population size differences. I’m interested in looking at changes over time with this dataset.\nBecause I’m focusing on the three counties in my area, I’m going to create a vector with the names of the capital area counties. This will make subsetting the data a little easier.\n\nopdeaths &lt;- read_xlsx(\"Opioid Overdose Deaths.xlsx\")\n\ncounties &lt;- c(\"Ingham\", \"Eaton\", \"Clinton\")"
  },
  {
    "objectID": "posts/opioid plotting practice/index.html#time-to-plot",
    "href": "posts/opioid plotting practice/index.html#time-to-plot",
    "title": "Opioid Plotting Practice",
    "section": "Time to Plot!",
    "text": "Time to Plot!\nFrom here, we can start our first plot. I will select my target counties using the filter() function that comes from the dplyr package. Be sure to specify which aesthetics you want to plot on the respective axes. Here we are putting the variable Year on the x-axis and Opioid Overdose Deaths on the y.\n\nopdeaths %&gt;%\n  filter(County %in% counties) %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line()\n\n\n\n\nOh no! What happened? We didn’t tell ggplot which lines we wanted to see. It is important that within the layer geom_line() we specify that we want to plot different lines based on our county variable. To do this, we simply add an aes() layer and assign color to County.\n\nopdeaths %&gt;%\n  filter(County %in% counties) %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(aes(color = County))\n\n\n\n\nThat looks a lot better! But we can do more. The lines look a bit skinny to me. I would like them to stand out more. It also might help to adjust the opacity of the lines. This can make points that cross over easier to read. To make these changes, we can specify linewidth and alpha in geom_line() outside of the aes() argument.\nI think it would be great to add points to our plot, too. Like the geom_line() layer, I want these to be large enough and overlap easily. I will pass through similar arguments in the geom_point() layer, also specifying the color.\n\nopdeaths %&gt;%\n  filter(County %in% counties)  %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(linewidth = 1, alpha = 0.8, aes(color = County)) +\n  geom_point(size = 2, alpha = 0.8, aes(color = County))\n\n\n\n\nLastly, I want to add labels and theme to really polish up our plot. This is surprisingly easy! To add our labels, we add another layer called labs(). Here we can add a proper title, and more accurate labels for the axes.\nAdding a theme is even easier. We can quickly add on a layer and pick a theme that we like. For my example, I’m using the fivethirtyeight theme that comes from ggthemes. Be sure to check out the other options available in this package.\nAfter our theme_fivethrityeight() layer, I’m adding a general theme() layer to specify that I want all my main title and axes titles to be shown. I am also adjusting the text size to make the title a bit more readable.\n\nopdeaths %&gt;%\n  filter(County %in% counties)  %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(linewidth = 1, alpha = 0.8, aes(color = County)) +\n  geom_point(size = 2, alpha = 0.8, aes(color = County)) +\n  labs(title = \"Opioid Overdose Deaths in Michigan's Capital Area \\nCounties, 1999 – 2020\",\n       x = \"Year\",\n       y = \"Number of Deaths\") +\n  theme_fivethirtyeight() +\n  theme(plot.title = element_text(size = 16),\n        plot.title.position = \"plot\",\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size = 11),\n        axis.title.y = element_text(vjust = +3),\n        axis.title.x = element_text(vjust = -0.75),\n        text = element_text(family = \"Georgia\"),\n        plot.margin = unit(c(1, 1, 1, 1), \"lines\"))\n\n\n\n\nAnd just like that, we have a very nice looking line chart!"
  },
  {
    "objectID": "posts/opioid plotting practice/index.html#a-glimpse-of-plotly",
    "href": "posts/opioid plotting practice/index.html#a-glimpse-of-plotly",
    "title": "Opioid Plotting Practice",
    "section": "A Glimpse of Plotly",
    "text": "A Glimpse of Plotly\nNext I want to briefly show how easy it is to take a basic ggplot figure and make it interactive with the amazing package plotly. If I save the figure we created before as an object, we can pass it through the function ggplotly(), and as a result, we get a chart where we can zoom in and hover over points to gain more insight. I will demonstrate this below.\n\np1 &lt;- opdeaths %&gt;%\n  filter(County %in% counties)  %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(linewidth = 1, alpha = 0.8, aes(color = County)) +\n  geom_point(size = 2, alpha = 0.8, aes(color = County)) +\n  labs(title = \"Opioid Overdose Deaths in Michigan's Capital Area Counties, 1999 – 2020\",\n       x = \"Year\",\n       y = \"Number of Deaths\") +\n  theme_fivethirtyeight() +\n  theme(plot.title = element_text(size = 16),\n        plot.title.position = \"plot\",\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size = 11),\n        axis.title.y = element_text(vjust = +3),\n        axis.title.x = element_text(vjust = -0.75),\n        text = element_text(family = \"Georgia\"),\n        plot.margin = unit(c(1, 1, 1, 1), \"lines\"))\n\nggplotly(p1)\n\n\n\n\n\nIt’s amazing how quickly you can produce interactive charts with R! The output from this function in an html widget. So it can easily be viewed on a website or a local html file. This makes it ideal for sharing graphics quickly among coworkers.\nFor my project, I created a few more graphics with the same color palette and arranged them on a pdf for easy distribution. If you want to view the finished product you can find that here.\nI hope you found this post helpful. Next time I want to focus more on plotly demonstrating its capabilities with spatial data analysis. Until next time!"
  },
  {
    "objectID": "index.html#blog-highlights",
    "href": "index.html#blog-highlights",
    "title": "Brenden Smith",
    "section": "Blog Highlights",
    "text": "Blog Highlights\n\nBlog post 1\nBlog post 2\nBlog post 3"
  },
  {
    "objectID": "index.html#featured-projects",
    "href": "index.html#featured-projects",
    "title": "Brenden Smith",
    "section": "Featured Projects",
    "text": "Featured Projects\n\nThis div...\n...required...\n...no offset (it’s still in the first row)"
  },
  {
    "objectID": "index.html#recent-blog-posts",
    "href": "index.html#recent-blog-posts",
    "title": "Brenden Smith",
    "section": "Recent Blog Posts",
    "text": "Recent Blog Posts\n\n\n\n\n\n\n\n\n\n\n\n\nTwitter Bots\n\n\n6 min\n\n\n\nR\n\n\ncolor\n\n\nweb-scraping\n\n\n\n\nBrenden Smith\n\n\nMar 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichigan COVID-19 County Maps\n\n\n8 min\n\n\n\nR\n\n\nmaps\n\n\n\n\nBrenden Smith\n\n\nOct 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpioid Plotting Practice\n\n\n6 min\n\n\n\nR\n\n\nggplot2\n\n\n\n\nBrenden Smith\n\n\nOct 9, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#mph-candidate-research-assistant-michigan-state-university-institute-for-health-policy",
    "href": "index.html#mph-candidate-research-assistant-michigan-state-university-institute-for-health-policy",
    "title": "Brenden Smith",
    "section": "",
    "text": "Hi, I’m Brenden. I am an MPH candidate with interests in health equity, harm reduction, and community engagement. I am a data analyst, community researcher, and R enthusiast.\nIf you would like to see some of my current and past work, you can visit my portfolio page or check out my blog."
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Brenden Smith",
    "section": "Projects",
    "text": "Projects\n\n\n\n\n\n\n\n\n\n\nAcademyHealth Poster\n\n\n\n\n\n\n\n\n\n\n\n\n\nTidy Tuesday\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichigan COVID-19 Dashboard\n\n\n\n\n\n\n\n\n\n\n\n\n\nMental Health and the Pandemic\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#blog-posts",
    "href": "index.html#blog-posts",
    "title": "Brenden Smith",
    "section": "Blog Posts",
    "text": "Blog Posts\n\n\n\n\n\n\n\n\n\n\nTwitter Bots\n\n\n\nR\n\n\ncolor\n\n\nweb-scraping\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichigan COVID-19 County Maps\n\n\n\nR\n\n\nmaps\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpioid Plotting Practice\n\n\n\nR\n\n\nggplot2\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/opioid plotting practice/index.html#introduction",
    "href": "posts/opioid plotting practice/index.html#introduction",
    "title": "Opioid Plotting Practice",
    "section": "",
    "text": "Over the summer, I took a course on public health surveillance. As a culminating project, we were tasked with creating original data visualizations for a fact sheet on a topic of our choosing. I chose to examine local opioid overdose and mortality data for my project.\nThis is a topic that is near to me. The opioid crisis has impacted many communities across the country. At this point, the topic is well known to most people. Despite awareness, overdoses are still rising.\nIn the following post, I will demonstrate how easily you can spice up basic ggplot graphics. In particular we will look at:\n\na basic ggplot2 line chart\nggthemes we can use to make a more professional looking figure\nand a brief glimpse at plotly (because interactive graphs are so cool!)"
  },
  {
    "objectID": "posts/Michigan COVID Cases and Deaths by County/index.html#introduction",
    "href": "posts/Michigan COVID Cases and Deaths by County/index.html#introduction",
    "title": "Michigan COVID-19 County Maps",
    "section": "",
    "text": "This post is intended to demonstrate some basic ways to map data in R. For our example, we will be creating a choropleth map of Michigan’s counties featuring COVID-19 data. The result is something quite similar to the map featured on the state’s dashboard. The data used in this post is from October 4, 2022.\nFor the sake of practice, we will walk through two different ways to go about this process. First we will use ggplot2. We will use a function called map_data to pull in shape file data easily. In our second example, we will use leaflet to create a better looking version of this map and use a raw shape file."
  },
  {
    "objectID": "posts/HM878: Helper Functions/index.html",
    "href": "posts/HM878: Helper Functions/index.html",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "This vignette demonstrates how to use the functions included in this package so far. If you have not yet, install the package with the following code: devtools::install_github(\"brendensm/hm878\"). If you do not have the package devtools, be sure to install that first install.packages(\"devtools\").\nTo start, we load the package\n\nlibrary(hm878)\n\nLet’s assume we are running a binomial logistic regression using the data from mtcars, a built-in data set included with R. We will use vs (engine type as V-shaped or straight) as the dependent variable, and cyl (number of cylinders) as the independent variable. We will store our models for block 1 and block 2.\n\nmb1 &lt;- glm(vs ~ 1, data = mtcars, family = \"binomial\")\nmb2 &lt;- glm(vs ~ cyl, data = mtcars, family = \"binomial\")\n\n\n\nTo assess the fit of our models, we may want to use the function chi_log. To use it, simply type in the name of your model as the first argument, followed by the data set that the model uses. Optionally, you can provide labels for each model using the third argument. Here I will label each block.\n\nchi_log(mb1, mtcars, \"Block 1\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 1:  32 \n Degrees of freedom for Block 1:  31 \n P-value for Block 1:  0.416744 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\nchi_log(mb2, mtcars, \"Block 2\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 2:  27.42 \n Degrees of freedom for Block 2:  30 \n P-value for Block 2:  0.6013516 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\n\nThe function gives us the chi-squared statistic, degrees of freedom, and a p-value. It also reminds us of the null and alternative hypotheses. Both models appear to be a good fit.\n\n\n\nWe may want to also check the accuracy of our models. To do this, we can use predict_percent. To use this function, enter the name of the model in the first argument, followed by the dependent variable we used in the model. For this, we must use the data$variable format. In the example below, we use the variable vs from the data set mtcars. Once again, we can label the output with a string as the optional third argument.\n\npredict_percent(mb1, mtcars$vs, \"Block 1\")\n\n\nAccuracy for Block 1: 56.25%\n\npredict_percent(mb2, mtcars$vs, \"Block 2\")\n\n\nAccuracy for Block 2: 84.38%\n\n\n\n\n\nTo calculate odds ratios for the models, simply pass the model through the function or.\n\nor(mb1)\n\n            Odds_Ratio  CI_Lower CI_Upper  p_values\n(Intercept)  0.7777778 0.3801366 1.558936 0.4806496\n\nor(mb2)\n\n              Odds_Ratio    CI_Lower     CI_Upper    p_values\n(Intercept) 10873.447296 95.35600799 6.507716e+07 0.002692584\ncyl             0.204474  0.04827075 4.455527e-01 0.001917098\n\n\nThe output results in a data frame with the odds ratios, confidence intervals, and p-values.\n\n\n\nIf you want to revise and adjust your model, it can be helpful to limit outliers. To find upper and lower fences quickly, use the function fences. To do this, pass the continuous variable you are interested in examining through the function. Once again, use the format data$variable.\n\nfences(mtcars$cyl)\n\n    Lower Upper\n25%    -2    14\n\nfences(mtcars$cyl)$Upper\n\n[1] 14\n\nfences(mtcars$cyl)$Lower\n\n[1] -2\n\n\n\n\n\nLastly, when you are putting together multiple models, it can be helpful to view them all at the same time, next to one another. This is particularly helpful if you have more than two models you are comparing. For this function, pass through however many models you have to compare, and optionally label each one, using a vector of strings for each model. To demonstrate, I will add on another model mb3 that will have another continuous independent variable.\n\nmb3 &lt;- glm(vs ~ cyl + wt, data = mtcars, family = \"binomial\")\n\ncompare_models(mb1, mb2, mb3, labels = c(\"Model 1 Block 1\", \"Model 1 Block 2\", \"Model Block 3\"))\n\n$`Model 1 Block 1`\n\nCall:  glm(formula = vs ~ 1, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)  \n    -0.2513  \n\nDegrees of Freedom: 31 Total (i.e. Null);  31 Residual\nNull Deviance:      43.86 \nResidual Deviance: 43.86    AIC: 45.86\n\n$`Model 1 Block 2`\n\nCall:  glm(formula = vs ~ cyl, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl  \n      9.294       -1.587  \n\nDegrees of Freedom: 31 Total (i.e. Null);  30 Residual\nNull Deviance:      43.86 \nResidual Deviance: 17.96    AIC: 21.96\n\n$`Model Block 3`\n\nCall:  glm(formula = vs ~ cyl + wt, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl           wt  \n     10.619       -2.931        2.100  \n\nDegrees of Freedom: 31 Total (i.e. Null);  29 Residual\nNull Deviance:      43.86 \nResidual Deviance: 15.55    AIC: 21.55\n\n\n\n\n\n\ndeviance_aic(mb1, mb2, mb3)\n\nmb1 \nResidual Deviance: 43.86 \nNull Deviance: 43.86 \nAIC: 45.86 \n\nmb2 \nResidual Deviance: 17.96 \nNull Deviance: 43.86 \nAIC: 21.96 \n\nmb3 \nResidual Deviance: 15.55 \nNull Deviance: 43.86 \nAIC: 21.55"
  },
  {
    "objectID": "posts/HM878: Helper Functions/index.html#testing-goodness-of-fit-with-chi_log",
    "href": "posts/HM878: Helper Functions/index.html#testing-goodness-of-fit-with-chi_log",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "To assess the fit of our models, we may want to use the function chi_log. To use it, simply type in the name of your model as the first argument, followed by the data set that the model uses. Optionally, you can provide labels for each model using the third argument. Here I will label each block.\n\nchi_log(mb1, mtcars, \"Block 1\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 1:  32 \n Degrees of freedom for Block 1:  31 \n P-value for Block 1:  0.416744 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\nchi_log(mb2, mtcars, \"Block 2\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 2:  27.42 \n Degrees of freedom for Block 2:  30 \n P-value for Block 2:  0.6013516 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\n\nThe function gives us the chi-squared statistic, degrees of freedom, and a p-value. It also reminds us of the null and alternative hypotheses. Both models appear to be a good fit."
  },
  {
    "objectID": "posts/HM878: Helper Functions/index.html#accuracy-percentage-with-predict_percent",
    "href": "posts/HM878: Helper Functions/index.html#accuracy-percentage-with-predict_percent",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "We may want to also check the accuracy of our models. To do this, we can use predict_percent. To use this function, enter the name of the model in the first argument, followed by the dependent variable we used in the model. For this, we must use the data$variable format. In the example below, we use the variable vs from the data set mtcars. Once again, we can label the output with a string as the optional third argument.\n\npredict_percent(mb1, mtcars$vs, \"Block 1\")\n\n\nAccuracy for Block 1: 56.25%\n\npredict_percent(mb2, mtcars$vs, \"Block 2\")\n\n\nAccuracy for Block 2: 84.38%"
  },
  {
    "objectID": "posts/HM878: Helper Functions/index.html#calculating-odds-ratios-with-or",
    "href": "posts/HM878: Helper Functions/index.html#calculating-odds-ratios-with-or",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "To calculate odds ratios for the models, simply pass the model through the function or.\n\nor(mb1)\n\n            Odds_Ratio  CI_Lower CI_Upper  p_values\n(Intercept)  0.7777778 0.3801366 1.558936 0.4806496\n\nor(mb2)\n\n              Odds_Ratio    CI_Lower     CI_Upper    p_values\n(Intercept) 10873.447296 95.35600799 6.507716e+07 0.002692584\ncyl             0.204474  0.04827075 4.455527e-01 0.001917098\n\n\nThe output results in a data frame with the odds ratios, confidence intervals, and p-values."
  },
  {
    "objectID": "posts/HM878: Helper Functions/index.html#upper-and-lower-fences-with-fences",
    "href": "posts/HM878: Helper Functions/index.html#upper-and-lower-fences-with-fences",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "If you want to revise and adjust your model, it can be helpful to limit outliers. To find upper and lower fences quickly, use the function fences. To do this, pass the continuous variable you are interested in examining through the function. Once again, use the format data$variable.\n\nfences(mtcars$cyl)\n\n    Lower Upper\n25%    -2    14\n\nfences(mtcars$cyl)$Upper\n\n[1] 14\n\nfences(mtcars$cyl)$Lower\n\n[1] -2"
  },
  {
    "objectID": "posts/HM878: Helper Functions/index.html#comparing-model-results-with-compare_models",
    "href": "posts/HM878: Helper Functions/index.html#comparing-model-results-with-compare_models",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "Lastly, when you are putting together multiple models, it can be helpful to view them all at the same time, next to one another. This is particularly helpful if you have more than two models you are comparing. For this function, pass through however many models you have to compare, and optionally label each one, using a vector of strings for each model. To demonstrate, I will add on another model mb3 that will have another continuous independent variable.\n\nmb3 &lt;- glm(vs ~ cyl + wt, data = mtcars, family = \"binomial\")\n\ncompare_models(mb1, mb2, mb3, labels = c(\"Model 1 Block 1\", \"Model 1 Block 2\", \"Model Block 3\"))\n\n$`Model 1 Block 1`\n\nCall:  glm(formula = vs ~ 1, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)  \n    -0.2513  \n\nDegrees of Freedom: 31 Total (i.e. Null);  31 Residual\nNull Deviance:      43.86 \nResidual Deviance: 43.86    AIC: 45.86\n\n$`Model 1 Block 2`\n\nCall:  glm(formula = vs ~ cyl, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl  \n      9.294       -1.587  \n\nDegrees of Freedom: 31 Total (i.e. Null);  30 Residual\nNull Deviance:      43.86 \nResidual Deviance: 17.96    AIC: 21.96\n\n$`Model Block 3`\n\nCall:  glm(formula = vs ~ cyl + wt, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl           wt  \n     10.619       -2.931        2.100  \n\nDegrees of Freedom: 31 Total (i.e. Null);  29 Residual\nNull Deviance:      43.86 \nResidual Deviance: 15.55    AIC: 21.55"
  },
  {
    "objectID": "posts/HM878: Helper Functions/index.html#deviance_aic-pull-the-deviances-and-aics-from-model-summarys",
    "href": "posts/HM878: Helper Functions/index.html#deviance_aic-pull-the-deviances-and-aics-from-model-summarys",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "deviance_aic(mb1, mb2, mb3)\n\nmb1 \nResidual Deviance: 43.86 \nNull Deviance: 43.86 \nAIC: 45.86 \n\nmb2 \nResidual Deviance: 17.96 \nNull Deviance: 43.86 \nAIC: 21.96 \n\nmb3 \nResidual Deviance: 15.55 \nNull Deviance: 43.86 \nAIC: 21.55"
  },
  {
    "objectID": "posts/Intro to Bash Scripting/index.html",
    "href": "posts/Intro to Bash Scripting/index.html",
    "title": "Intro to Bash Scripting",
    "section": "",
    "text": "And I thought R gave me super powers…"
  },
  {
    "objectID": "posts/Intro to Bash Scripting/index.html#introduction",
    "href": "posts/Intro to Bash Scripting/index.html#introduction",
    "title": "Intro to Bash Scripting",
    "section": "Introduction",
    "text": "Introduction\nRecently, I’ve been having fun with Linux. I really didn’t know much about Linux or how it was different from MacOS or Windows. All I really knew was that very smart people use it and many computers depend on it!\nBy recommendation of a friend, I tried loading Pop!_OS on an old Macbook Air I had laying around. I quickly learned how lightweight many distributions of Linux are, and how customizable they can be.\nFor anyone familiar with Linux you know that, even when you are just setting up a computer with the OS, you have to start using a bit of the command line. I had used this before learning some helpful functions with git, but nothing has exposed me to the command line and Bash more than this endeavor.\nI have been inspired by this exposure and want to start learning more about the functionality of Bash. As a part of this, I wanted to try creating a Bash script of my own that I could implement into my current workflows."
  },
  {
    "objectID": "posts/Intro to Bash Scripting/index.html#the-idea",
    "href": "posts/Intro to Bash Scripting/index.html#the-idea",
    "title": "Intro to Bash Scripting",
    "section": "The Idea",
    "text": "The Idea\nI work primarily in R. And I love a good R Project. One of my usual habits for creating a project include adding sub folders and a starting script. I realized Bash is really good for doing this! So with some basic commands, I wanted to create a single executable script that makes a new R project, default sub folders, and a starting script."
  },
  {
    "objectID": "posts/Intro to Bash Scripting/index.html#writing-the-script",
    "href": "posts/Intro to Bash Scripting/index.html#writing-the-script",
    "title": "Intro to Bash Scripting",
    "section": "Writing the Script",
    "text": "Writing the Script\nFor the script I wanted several tasks accomplished:\n\nCreated an R project file within a contained folder\nSeveral sub-directories within that folder (data-raw, data, ref, output)\nA blank R script file\n\nTo start, I had the script ask for the name of the project. This was done by using echo to print the prompt, then read takes in the name of the project.\n\n\nCode\n#!/bin/bash\n\necho \"Please enter your project title: \"\n\nread name\n\n\nNext, I had to make the script navigate to the folder I want my projects in (for me, this is a folder on my desktop called ‘R’). Then, I had a directory made with sub-folders using mkdir -p. Here we use $name to use the variable stored as the name of the project. Within the {} are the names of the sub-folder I most commonly use. This could be anything you like though! Lastly, touch creates the blank R script.\n\n\nCode\ncd Desktop/R\n\nmkdir -p $name/{data-raw,data,ref,output}\n\ncd $name\n\ntouch script.R\n\n\nNext, we have an extra step that allows RStudio to open our new project properly. When I first tried this script out, I created a blank file with the .Rproj extension to set up the project. This immediately gave me problems when I tried to open the project. Specifically, I recall an issue with the version being unspecified.\nAfter a bit a research, I discovered that files with .Rproj are nothing really but a .txt file. I opened one of my existing R projects with a text editor and copied the contents exactly into the code chunk below. I wrote this text into the new R project. After some trial and error, I can confirm this method works!\n\n\nCode\n\necho -e 'Version: 1.0\n\nRestoreWorkspace: Default\nSaveWorkspace: Default\nAlwaysSaveHistory: Default\n\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 2\nEncoding: UTF-8\n\nRnwWeave: Sweave\nLaTex: pdfLaTeX' &gt;&gt; $name.Rproj\n\n\nThe last few lines of code echo some responses to the terminal and launch the new R project.\n\n\nCode\necho \"Project $name has been created.\"\necho \"It is stored in the R directory.\"\necho \"Opening project now...\"\n\nopen $name.Rproj"
  },
  {
    "objectID": "posts/Intro to Bash Scripting/index.html#making-it-accessible",
    "href": "posts/Intro to Bash Scripting/index.html#making-it-accessible",
    "title": "Intro to Bash Scripting",
    "section": "Making it Accessible",
    "text": "Making it Accessible\nFor me, personally, I like to be able to execute my scripts without worrying where I am in the terminal. Once my script was working properly, I moved it to the /usr/local/bin folder.\n\n\nCode\nmv setupr /usr/local/bin\n\n\nAnd that’s it! You can find the full script code below. I hope this is helpful! It was certainly useful to me to learn more about bash and make a useful script to help me set up projects."
  },
  {
    "objectID": "posts/Intro to Bash Scripting/index.html#full-script-code",
    "href": "posts/Intro to Bash Scripting/index.html#full-script-code",
    "title": "Intro to Bash Scripting",
    "section": "Full Script Code",
    "text": "Full Script Code\n\n\nCode\n#!/bin/bash\n\necho \"Please enter your project title: \"\n\nread name\n\ncd Desktop/R\n\nmkdir -p $name/{data-raw,data,ref,output}\n\ncd $name\n\ntouch script.R\n\necho -e 'Version: 1.0\n\nRestoreWorkspace: Default\nSaveWorkspace: Default\nAlwaysSaveHistory: Default\n\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 2\nEncoding: UTF-8\n\nRnwWeave: Sweave\nLaTex: pdfLaTeX' &gt;&gt; $name.Rproj\n\necho \"Project $name has been created.\"\necho \"It is stored in the R directory.\"\necho \"Opening project now...\"\n\nopen $name.Rproj"
  },
  {
    "objectID": "posts/Survival Analysis/index.html",
    "href": "posts/Survival Analysis/index.html",
    "title": "Survival Analysis in R",
    "section": "",
    "text": "At first I was afraid, I was petrified…"
  },
  {
    "objectID": "posts/Survival Analysis/index.html#introduction",
    "href": "posts/Survival Analysis/index.html#introduction",
    "title": "Survival Analysis in R",
    "section": "Introduction",
    "text": "Introduction\nIn this blog post, I’ll be exploring some basic survival analysis in R. Survival analysis focuses on describing the occurrence of an event (in this example death) in a set time frame. Survival analysis is often used in clinical research and cancer epidemiology. For more reading, I recommend visiting The Epidemiologist R Handbook page on survival analysis, as well as their listed resources. The following blog post was adapted from my biostatistics coursework and features data used in that course. We will create Kaplan-Meier plots and go through Cox Hazard Regression."
  },
  {
    "objectID": "posts/Survival Analysis/index.html#packages-and-data",
    "href": "posts/Survival Analysis/index.html#packages-and-data",
    "title": "Survival Analysis in R",
    "section": "Packages and Data",
    "text": "Packages and Data\nFor this blog post, I will use the packages have, dplyr, survival.\n\n\nCode\n# Load in libraries\nlibrary(dplyr)\nlibrary(readr)\nlibrary(survival)\nlibrary(sjPlot)\n\n\nNext, we will load the data.\n\n\nCode\nsd &lt;- read_csv(\"data/HM 878 730 Clements - Survival Analysis R Data.csv\") %&gt;% \n  mutate(\n    #death = factor(death, levels = c(0, 1),\n                 #  labels = c(\"Living\", \"Died\")),\n    cursmoke = factor(cursmoke, levels = c(0, 1), \n                      labels = c(\"Not current smoker\", \"Current smoker\")),\n    diabetes = factor(diabetes, levels = c(0, 1),\n                      labels = c(\"Not diabetic\", \"Diabetic\")),\n    educ = factor(educ, levels = c(1, 2, 3, 4),\n                  labels = c(\"0-11 years\", \"HS Diploma/GED\", \n                             \"Some College/Vocational School\",\n                             \"College degree or more\")),\n    prevchd = factor(prevchd, levels = c(0, 1),\n                    labels = c(\"No\", \"Yes\")),\n    sex = factor(sex, levels = c(0, 1),\n                 labels = c(\"Female\", \"Male\"))\n  )"
  },
  {
    "objectID": "posts/Survival Analysis/index.html#cox-regression",
    "href": "posts/Survival Analysis/index.html#cox-regression",
    "title": "Survival Analysis in R",
    "section": "Cox Regression",
    "text": "Cox Regression\n\nHazard Ratios\n\n\nCode\ncm &lt;- coxph(Surv(TimeDeathYears, death) ~ cursmoke + diabetes +\n              educ + prevchd + age + bmi + sex, data = sd)\n\nsummary(cm)\n\n\nCall:\ncoxph(formula = Surv(TimeDeathYears, death) ~ cursmoke + diabetes + \n    educ + prevchd + age + bmi + sex, data = sd)\n\n  n= 3165, number of events= 746 \n   (98 observations deleted due to missingness)\n\n                                        coef exp(coef)  se(coef)      z\ncursmokeCurrent smoker              0.432597  1.541256  0.081165  5.330\ndiabetesDiabetic                    0.741622  2.099338  0.100251  7.398\neducHS Diploma/GED                 -0.007861  0.992169  0.092149 -0.085\neducSome College/Vocational School -0.158231  0.853652  0.111205 -1.423\neducCollege degree or more         -0.454487  0.634773  0.131159 -3.465\nprevchdYes                          0.790013  2.203425  0.086862  9.095\nage                                 0.092917  1.097370  0.005068 18.333\nbmi                                -0.012792  0.987290  0.009667 -1.323\nsexMale                             0.672732  1.959583  0.075393  8.923\n                                   Pr(&gt;|z|)    \ncursmokeCurrent smoker             9.83e-08 ***\ndiabetesDiabetic                   1.39e-13 ***\neducHS Diploma/GED                  0.93201    \neducSome College/Vocational School  0.15477    \neducCollege degree or more          0.00053 ***\nprevchdYes                          &lt; 2e-16 ***\nage                                 &lt; 2e-16 ***\nbmi                                 0.18575    \nsexMale                             &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                                   exp(coef) exp(-coef) lower .95 upper .95\ncursmokeCurrent smoker                1.5413     0.6488    1.3146    1.8070\ndiabetesDiabetic                      2.0993     0.4763    1.7248    2.5551\neducHS Diploma/GED                    0.9922     1.0079    0.8282    1.1886\neducSome College/Vocational School    0.8537     1.1714    0.6865    1.0615\neducCollege degree or more            0.6348     1.5754    0.4909    0.8208\nprevchdYes                            2.2034     0.4538    1.8585    2.6124\nage                                   1.0974     0.9113    1.0865    1.1083\nbmi                                   0.9873     1.0129    0.9688    1.0062\nsexMale                               1.9596     0.5103    1.6904    2.2716\n\nConcordance= 0.761  (se = 0.009 )\nLikelihood ratio test= 688.4  on 9 df,   p=&lt;2e-16\nWald test            = 686.8  on 9 df,   p=&lt;2e-16\nScore (logrank) test = 783.3  on 9 df,   p=&lt;2e-16\n\n\nCode\nsjPlot::tab_model(cm)\n\n\n\n\n\n\n\n\n\n\n\n \nSurv(Time Death\nYears,death)\n\n\nPredictors\nEstimates\nCI\np\n\n\ncursmoke [Current smoker]\n1.54\n1.31 – 1.81\n&lt;0.001\n\n\ndiabetes [Diabetic]\n2.10\n1.72 – 2.56\n&lt;0.001\n\n\neduc [HS Diploma/GED]\n0.99\n0.83 – 1.19\n0.932\n\n\neduc [Some\nCollege/Vocational\nSchool]\n0.85\n0.69 – 1.06\n0.155\n\n\neduc [College degree or\nmore]\n0.63\n0.49 – 0.82\n0.001\n\n\nprevchd [Yes]\n2.20\n1.86 – 2.61\n&lt;0.001\n\n\nage\n1.10\n1.09 – 1.11\n&lt;0.001\n\n\nbmi\n0.99\n0.97 – 1.01\n0.186\n\n\nsex [Male]\n1.96\n1.69 – 2.27\n&lt;0.001\n\n\nObservations\n3165\n\n\nR2 Nagelkerke\n0.200\n\n\n\n\n\n\n\n\n\nSurvival Curves\n\n\nCode\nsurv_fit_diab &lt;-  survfit(Surv(TimeDeathYears, death) ~ diabetes, data = sd)\n\ncol_diab &lt;- c(\"lightgreen\", \"darkgreen\")\n\nplot(\n  surv_fit_diab,\n  col = col_diab,\n  xlab = \"Years\",\n  ylab = \"Survival Probability\")\nlegend(\n  \"bottomright\",\n  legend = c(\"Not diabetic\",\"Diabetic\"),\n  col = col_diab,\n  lty = 1,\n  cex = .9,\n  bty = \"n\")\n\n\n\n\n\n\n\nInterpretation\nHazard ratios for the cox regression show that smoker status, diabetic status, prevalent coronary heart disease, age, sex, and the highest level of education all have significant p-values. This means that each were found to impact the outcome of death in our survival analysis.\nSmoker status has a hazard ratio of 1.54 meaning that, compared to non-smokers, current smokers have 1.54 times the risk of death.\nDiabetic status has a hazard ratio of 2.10. This means that those with diabetes, compared to those that were not diabetic, had 2.1 times greater risk of death.\nEducation at the level of college degree or more had a hazard ratio of 0.63. Compared to those with 0-11 years of education, this group had 37% decreased risk of death.\nPrevalence of coronary heart disease has a hazard ratio of 2.20, meaning that compared to those without CHD, they had 120% increased risk of death.\nAge also has a significant p-value, and a hazard ratio of 1.10. This means for every increase unit in age, there is 10% greater risk of death.\nLastly, sex had a hazard ratio of 1.96. This means that compared to females, males had 95% greater risk of death.\nThe survival curve shows the difference in survival probability between diabetics and non-diabetics. The differences are quite noticeably, with a lower survival probability among diabetics. This is in line with the results of the cox regression. For example, at 10 years, the survival probability among non-diabetics is about 85%, while the probability among diabetics is 65%."
  },
  {
    "objectID": "posts/Survival Analysis/index.html#kaplan-meier",
    "href": "posts/Survival Analysis/index.html#kaplan-meier",
    "title": "Survival Analysis in R",
    "section": "Kaplan-Meier",
    "text": "Kaplan-Meier\nConduct Kaplan-Meier for each categorical IV. Interpret the summary, mean and median survival time, Log Rank Mantel-Cox Test, survival probability at 10 years. Compare and contrast between each variable.\n\nFunction for Analysis\nBecause I have to compare quite a few variables, I make a quick function to output exactly what I need.\n\n\nCode\nkm &lt;- function(time, event, data, iv, title_label){\n  \nmodel &lt;-  survfit(Surv(time, event) ~ iv, data = sd)\n\ncols &lt;- RColorBrewer::brewer.pal(4, \"Set1\")\n\nplot_title &lt;- paste(\"Survival Curve by\", title_label)\n\nplot(\n  model,\n  col = cols,\n  lwd = 2,\n  main = plot_title,\n  xlab = \"Years\",\n  ylab = \"Survival Probability\")\nlegend(\n  \"bottomleft\",\n  legend = levels(iv),\n  col = cols,\n  lty = 1,\n  cex = .9,\n  bty = \"n\")\nabline(h = seq(0,1,.2), lty = \"dashed\", col = \"gray75\")\nabline(lty = \"dashed\", col = \"black\", v = 10)\n  \n  \ncat(\"Model summary with mean and median: \\n\")\nprint(model, print.rmean = TRUE)\n\nlogrank &lt;- survdiff(Surv(time, event) ~ iv, data = data)\nprint(logrank)\n  \n}\n\n\n\n\nDiabetes\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$diabetes, \"Diabetes\")\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n                   n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=Not diabetic 3009    646   13.7    0.0525     NA      NA      NA\niv=Diabetic      254    129   11.8    0.2540     14      13      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n                   N Observed Expected (O-E)^2/E (O-E)^2/V\niv=Not diabetic 3009      646    724.5       8.5       133\niv=Diabetic      254      129     50.5     121.8       133\n\n Chisq= 133  on 1 degrees of freedom, p= &lt;2e-16 \n\n\nAs interpreted before, the survival probability differs quite drastically between these two groups. At 10 years, the survival probability among non-diabetics is about 85%, while the probability among diabetics is 65%.\nThe model summary shows the total number in each group and the number of events (deaths) in each group.\nThe mean survival time is 13.7 years for non-diabetics, compared to 11.8 for diabetics. The median survival time could not be computed for non-diabetics, and was 14 years for diabetics. The median was not computed for non-diabetics because over 50% were still alive by the end of the time period.\nThe Log Rank Mantel-Cox Test shows a resulting p-value of &lt;0.0001, meaning that the null hypothesis, that there is no difference in survival between groups, is rejected.\n\n\nSmoker Status\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$cursmoke, \"Smoker Status\")\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n                         n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=Not current smoker 2142    501   13.6    0.0649     NA      NA      NA\niv=Current smoker     1121    274   13.5    0.0922     NA      NA      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n                         N Observed Expected (O-E)^2/E (O-E)^2/V\niv=Not current smoker 2142      501      510     0.173     0.517\niv=Current smoker     1121      274      265     0.333     0.517\n\n Chisq= 0.5  on 1 degrees of freedom, p= 0.5 \n\n\nThe model results show that the mean survival time was 13.6 among non-smokers and 13.5 among current smokers. These are not very different from each other, and on par with the average survival time of non-diabetics. The median survival times were not able to be calculated for this variable.\nThe Log Rank test shows a p-value of 0.5 indicating we should accept the null hypothesis that there is no difference in survival between the two groups.\nAt 10 years, the survival probability is nearly the same between the two groups, a bit greater than 80%. Once again, similar to non-diabetic suvival probability at the same time.\n\n\nEducation Level\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$educ, \"Education\")\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n   82 observations deleted due to missingness \n                                     n events rmean* se(rmean) median 0.95LCL\niv=0-11 years                     1281    381   13.2    0.0936     NA      NA\niv=HS Diploma/GED                  967    194   13.8    0.0911     NA      NA\niv=Some College/Vocational School  542    108   13.9    0.1188     NA      NA\niv=College degree or more          391     71   14.0    0.1275     NA      NA\n                                  0.95UCL\niv=0-11 years                          NA\niv=HS Diploma/GED                      NA\niv=Some College/Vocational School      NA\niv=College degree or more              NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\nn=3181, 82 observations deleted due to missingness.\n\n                                     N Observed Expected (O-E)^2/E (O-E)^2/V\niv=0-11 years                     1281      381    291.6     27.40     45.74\niv=HS Diploma/GED                  967      194    234.0      6.84     10.14\niv=Some College/Vocational School  542      108    131.9      4.32      5.36\niv=College degree or more          391       71     96.5      6.74      7.91\n\n Chisq= 46.4  on 3 degrees of freedom, p= 5e-10 \n\n\nThis model summary compares each of the four education levels in our variable. The mean survival years for those 0-11 is 13.2, for HS/Diploma/GED it is 13.8, for Some College/Vocational School it is 13.9 and for College degree or more it is 14. These are close to the averages we saw among smokers/nonsmokers, and non-diabetics. However, diabetics have still had the lowest average at 11 years. Once again, the medians could not be calculated for this variable because of the high proportion of groups surviving by the end of the time period.\nThe Log Rank test shows a p-value of &lt;0.0001. This leads us to reject the null and accept the alternative hypothesis that there is a significant difference in survival time between these groups (somewhere).\nThe survival probability at 10 years is 80% for the group 0-11, and around 90% for the other three groups. This is in the range of most groups thus far, aside from diabetics.\n\n\nPrevalence of Coronary Heart Disease\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$prevchd, \"CHD Prevalence\")\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n          n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=No  2903    582   13.8    0.0522     NA      NA      NA\niv=Yes  360    193   11.7    0.2077     14      12      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n          N Observed Expected (O-E)^2/E (O-E)^2/V\niv=No  2903      582    704.1      21.2       237\niv=Yes  360      193     70.9     210.4       237\n\n Chisq= 237  on 1 degrees of freedom, p= &lt;2e-16 \n\n\nThose without coronary heart disease had an average survival time of 13.8 years, while those with CHD had an average of 11.7 years. The median was only calculated for those with CHD, which was at 14 years. These metrics align with results from many other groups. the average survival years for those without CHD is comparable to the same metrics examined among the three highest education levels, smokers and non-smokers, and non-diabetics. Diabetics and those with CHD have similar average survival time.\nThe Log Rank Test shows a p-value of less than 0.0001. This leads us to reject the null and accept the alternative hypothesis that there is a difference in survival times between the two groups.\nLooking at the survival curve, the survival probability of those with CHD at 10 years is about 65%. The survival probability of those without CHD is around 90%. This is a comparable split to diabetics/non-diabetics.\n\n\nSex\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$sex, \"Sex\")\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n             n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=Female 1876    345   13.9    0.0635     NA      NA      NA\niv=Male   1387    430   13.1    0.0894     NA      NA      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n             N Observed Expected (O-E)^2/E (O-E)^2/V\niv=Female 1876      345      458      28.0      70.1\niv=Male   1387      430      317      40.5      70.1\n\n Chisq= 70.1  on 1 degrees of freedom, p= &lt;2e-16 \n\n\nFor the Kaplan-Meier examining sex, the model results show that the average survival time among females was 13.9 compared to male’s 13.1. This is a similar split between the highest and lowest education levels. Overall, this seems to be a significant difference, but not as big of a difference as CHD or diabetes status. The medians for these groups could not be calculated.\nThe Log Rank Test shows a p-value of less than 0.0001, which again leads us to accept the alternative hypothesis that this model shows a significant difference in survival time between the two groups.\nOn the survival curve, it appears that at 10 years, males had 80% survival probability, and females had about 90%. This is a much closer gap, agian comparable to the difference between education level. The gap is narrower among smokers and non-smokers, but larger when diabetes or CHD is examined."
  },
  {
    "objectID": "posts/Survival Analysis/index.html#reflections-on-cox-regression-vs.-kaplan-meier",
    "href": "posts/Survival Analysis/index.html#reflections-on-cox-regression-vs.-kaplan-meier",
    "title": "Survival Analysis in R",
    "section": "Reflections on Cox Regression vs. Kaplan-Meier",
    "text": "Reflections on Cox Regression vs. Kaplan-Meier\nThe cox regression showed that smoker status, diabetes status, education level (college degree or more), CHD status, age, and sex were all statistically significant in the model. The highest increased hazard ratios were from the variables for CHD and diabetes.\nWhen we examine the Kaplan-Meier and Log Rank tests, all categorical variables were significant except for smoker status. This difference was not expected. Being that the cox regression showed it as significant and with a fairly high hazard ratio, I expected to see a bigger difference in survival time. Perhaps this is due to comorbidities associated with this variable. But the two largest hazard ratios in the cox regression, diabetes and CHD, displayed the biggest differences in suvival time, which was expected. Also, variables like education and sex showed smaller but still present difference in line with cox regression results.\nCox regression is obviously necessary whenever you are interested in a continuous variable’s relationship to the outcome. It is also preferred when you have multiple groups in a categorical variables. As we saw in this project, education level was shown as significant using both methods. However, cox regression gave us a greater level of detail of increased risk within groups. The Kaplan-Meier (and Log Rank test) simply told us there was a significant difference somewhere within the groups.\nThere are other advantages to picking a particular method. For instance, if you are more interested in metrics like average survival time, KP delivers that information. If you are looking for information for example in a clinical trial, a cox regression may be preferable due to the hazard ratio it gives you. This may be more practical too if you are interested in multiple factors influencing an outcome. KP is limited to one factor at a time.\nLastly, Kaplan-Meier may be the most reliable method to use if you have data that do not meet the proper assumptions, as KP is a non-parametric test. Cox regression is semi-parametric, meaning there are some assumptions that must be met. In this way, it may be easier to apply KP to ill fitting data. But one method is not “better” than the other, they are simply different techniques that answer slightly different questions."
  },
  {
    "objectID": "posts/Bluets/index.html#introduction",
    "href": "posts/Bluets/index.html#introduction",
    "title": "Twitter Bots",
    "section": "Introduction",
    "text": "Introduction\nBlue is a color that moves me. I love how many forms it can take, the way its shades can channel moods. I recently reread my copy of Maggie Nelson’s Bluets and felt inspired to revisit an older project of mine. Possibly the first R project I put together (that was more fun, and not statistics or graphic related) was my twitter bot, everywordisblue.\nThis was a year or so back when I was just starting to dust off R and commit to learning the language fully. The original account was influenced by many of the silly bots on the website and my personal passion for the color blue. It took a randomly selected noun, pasted the word 'blue' in front of it, and posted it straight to Twitter once a day. While this creation gave me some immediate satisfaction (and some interesting results), I did feel that the account was a bit too simplistic; I always wanted to do more.\nInfinitely more satisfying would be a randomly selected hue of blue, shared daily, completely automated. To do this required editing my original script and, most importantly, web-scraping a data set of blue colors with accompanying hex codes. Follow along and let’s build something fun!"
  },
  {
    "objectID": "posts/Bluets/index.html#the-data",
    "href": "posts/Bluets/index.html#the-data",
    "title": "Twitter Bots",
    "section": "The Data",
    "text": "The Data\nOriginally, I attempted to find an existing data set. Most colors sets I’m familiar with using in R, however, are not as hyper-fixated on a singular color. I quickly found color-names.com, and noticed when you simply search for the word 'blue', the search provides over 89 pages (12 colors on each page), giving over a thousand colors with hex codes. This seemed like an adequate source for this project and a great way to practice web scraping data from R.\n\nUsing ‘rvest’\nTo help us source our data, the library 'rvest' provides everything we need. In order to create a data frame containing the color name and the hex code, we need to:\n\nimport the web search’s html\npull out the two elements from the code (name, hex code)\nthen repeat this process for each of the 89 pages\n\nThe function 'read_html' from rvest makes the first step incredibly easily. For this, we simply pass in the web address as an argument in the function and save the output as a new value called 'page'.\n\n\nCode\nlibrary(rvest)\nlink &lt;- \"https://www.color-name.com/search/blue\"\npage &lt;- read_html(link)\n\n\nNext, we’ll pass 'page' into the function 'html_nodes' and then into 'html_text' to extract the desired string vector. The text passed through 'html_nodes' must be sourced from the webpage you are scraping from. You can use the ‘inspect’ feature in Google Chrome, or the Chrome extension ‘SelectorGadget’ to find the proper tag to use.\n\n\nCode\nname &lt;- page |&gt; html_nodes(\"h2 a\") |&gt; html_text()\nhex &lt;- page |&gt; html_nodes(\".hx\") |&gt; html_text()\n\n\nOnce that is done, we can take both vectors and create a data frame.\n\n\nCode\ncolors &lt;- data.frame(name, hex, stringsAsFactors = FALSE)\n\n\nIn order to collect each page of data, it is easiest to use a for loop. For this we make a couple of changes. First, we will create an empty data frame titled 'colors' to store data in for each iteration of the loop. Because there are 89 pages, we set the for loop to iterate that many times. We store this as 'page_result' in the loop and change the url to match what is displayed on each page number then use 'paste0' to put them together. Lastly, I added 'rbind' to add the new rows to the 'colors' data frame and a print command to keep track of the loop progress.\n\n\nCode\ncolors &lt;- data.frame()\n\nfor (page_result in 1:89){\n  \n  link &lt;- paste0(\"https://www.color-name.com/search/blue/page/\", page_result)\n  \n  page &lt;- read_html(link)\n  \n  name &lt;- page |&gt; html_nodes(\"h2 a\") |&gt; html_text()\n  hex &lt;- page |&gt; html_nodes(\".hx\") |&gt; html_text()\n  \n  colors &lt;- rbind(colors, data.frame(name, hex, stringsAsFactors = FALSE))\n  \n  print(paste(\"Page:\", page_result))\n}\n\n\nAnd as a last step, I decided to clean up the colors a bit. Even though the search used the key word 'blue', I noticed that the last page displayed colors that did not have the word 'blue' in the title. To fix this, I filtered out any color that did not contain the word.\n\n\nCode\nlibrary(dplyr)\nblues &lt;- colors |&gt; filter(grepl('Blue', name))"
  },
  {
    "objectID": "posts/Bluets/index.html#the-script",
    "href": "posts/Bluets/index.html#the-script",
    "title": "Twitter Bots",
    "section": "The Script",
    "text": "The Script\nNow that we have the data, we need to make a script that randomly selects a color, creates a color square, saves it as an image, and posts a tweet. For all of this, we will load 'rtweet' and 'ggplot2'.\n\n\nCode\nlibrary(rtweet)\nlibrary(ggplot2)\n\n\nAfter importing, we need to create the token to interact with Twitter’s API. You can find a deeper dive into this process here. In my example below, I have stored my information as secrets in my Github repository.\n\n\nCode\nblues &lt;- read.csv(\"blues_dataset.csv\")[,-1] # import data \n\neverywordisblue_token &lt;- # Twitter token business\n  rtweet::rtweet_bot(\n   api_key =   Sys.getenv(\"TWITTER_CONSUMER_API_KEY\"),\n    api_secret = Sys.getenv(\"TWITTER_CONSUMER_API_SECRET\"),\n    access_token =    Sys.getenv(\"TWITTER_ACCESS_TOKEN\"),\n    access_secret =  Sys.getenv(\"TWITTER_ACCESS_TOKEN_SECRET\")\n  )\n\n\nNext we can select a single row in our main data frame by calling 'sample_n'. Then to separate the name and the hex code we can save each as an object and index using brackets.\n\n\nCode\nrandom_blue &lt;- sample_n(blues, 1)\n\ntemp &lt;- as.character(random_blue[1])\n\nblue_hex &lt;- as.character(random_blue[2])\n\n\nTo create a square with the randomly selected color, we can create an empty ggplot, add 'theme_void' to make it blank, and use theme to use the selected hex code. For this we use arguments 'plot.background' and 'panel.background'. Then we can use 'ggsave' to save a copy of this as an image and specify the desired path.\n\n\nCode\nblue_square &lt;- ggplot() + theme_void() +\n              theme(plot.background = element_rect(fill = blue_hex),\n              panel.background = element_rect(fill = blue_hex))\n\nggsave(paste0(\"blue_squares/\", temp, \".png\"), blue_square,\n       width = 150, height = 150, units = \"px\")\n\n\nNow that all the pieces are in place, we can assemble the tweet and sent it out! The function 'post_tweet' now requires that the user provides alt text (awesome!) so we will first save that (this will be the same for each tweet sent). We will also save an image path that changes each time the script is run using 'paste0' once again.\nTo send the actual tweet, we pull in each object to the 'post_tweet' and we are done!\n\n\nCode\nalt_text &lt;- \"A random shade of blue, sourced from color-name.com.\"\n\nimage_path &lt;- paste0(\"blue_squares/\", temp, \".png\")\n\nrtweet::post_tweet(status = temp, \n                   media = image_path, \n                   media_alt_text = alt_text,\n                   token = everywordisblue_token)"
  },
  {
    "objectID": "posts/Bluets/index.html#automation-with-github-actions",
    "href": "posts/Bluets/index.html#automation-with-github-actions",
    "title": "Twitter Bots",
    "section": "Automation with Github Actions",
    "text": "Automation with Github Actions\nGithub makes it surprisingly easy to automate scripts with Github Actions! Again for the full length guide on this process I will direct you to Matt Dray’s blog post which taught me how to properly set this bot up.\nEssentially, all that is needed in a yml file that lists the correct instructions on when and what to run. My example yml is below:\n\n\nCode\nname: blue-version-2\n\non:\n  schedule:\n    - cron: '0 0 * * *'  # once every day\n\njobs:\n  blue-post:\n    runs-on: macOS-latest\n    env:\n      TWITTER_CONSUMER_API_KEY: ${{ secrets.TWITTER_CONSUMER_API_KEY }}\n      TWITTER_CONSUMER_API_SECRET: ${{ secrets.TWITTER_CONSUMER_API_SECRET }}\n      TWITTER_ACCESS_TOKEN: ${{ secrets.TWITTER_ACCESS_TOKEN }}\n      TWITTER_ACCESS_TOKEN_SECRET: ${{ secrets.TWITTER_ACCESS_TOKEN_SECRET }}\n    steps:\n      - uses: actions/checkout@v2\n      - uses: r-lib/actions/setup-r@v2\n      - name: Install rtweet package\n        run: Rscript -e 'install.packages(\"rtweet\", dependencies = TRUE)'\n      - name: Install dplyr\n        run: Rscript -e 'install.packages(\"dplyr\", dependencies = TRUE)'\n      - name: Install ggplot2\n        run: Rscript -e 'install.packages(\"ggplot2\", dependencies = TRUE)'\n      - name: Create and post tweet\n        run: Rscript blue-script.R\n\n\nAnd that’s it! If you want to check out the live twitter bot you can follow it here."
  },
  {
    "objectID": "posts/Introducing the PLACES Package/index.html",
    "href": "posts/Introducing the PLACES Package/index.html",
    "title": "Introducing the CDCPLACES Package",
    "section": "",
    "text": "This post was updated on March 19, 2024 to reflect updates introduced in CDCPLACES 1.1.5."
  },
  {
    "objectID": "posts/Introducing the PLACES Package/index.html#introduction",
    "href": "posts/Introducing the PLACES Package/index.html#introduction",
    "title": "Introducing the CDCPLACES Package",
    "section": "Introduction",
    "text": "Introduction\nTo begin, we can install from CRAN, or from github, then load our packages.\n\n\nCode\n# Install from CRAN\n# install.packages(\"CDCPLACES)\n\n# Install from Github\n# devtools::install_github(\"brendensm/CDCPLACES\")\n\nlibrary(CDCPLACES)\nlibrary(dplyr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "posts/Introducing the PLACES Package/index.html#function-get_measures",
    "href": "posts/Introducing the PLACES Package/index.html#function-get_measures",
    "title": "Introducing the CDCPLACES Package",
    "section": "Function: get_measures",
    "text": "Function: get_measures\nOur first functions allows us to easily view what measures we can query, along with a brief definition. If we run get_measures, we must specify a release year. Then we can view the measures in a data frame in the R Studio viewer. If we instead print measures23, the pre-loaded data set, we see a preview.\n\n\nCode\nhead(measures23) %&gt;% tibble()\n\n\n# A tibble: 6 × 6\n  year  measureid short_question_text           measure       categoryid release\n  &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;                         &lt;chr&gt;         &lt;chr&gt;      &lt;chr&gt;  \n1 2021  OBESITY   Obesity                       Obesity amon… HLTHOUT    2023   \n2 2021  STROKE    Stroke                        Stroke among… HLTHOUT    2023   \n3 2021  ARTHRITIS Arthritis                     Arthritis am… HLTHOUT    2023   \n4 2020  SLEEP     Sleep &lt;7 hours                Sleeping les… RISKBEH    2023   \n5 2021  INDEPLIVE Independent Living Disability Independent … DISABLT    2023   \n6 2021  COGNITION Cognitive Disability          Cognitive di… DISABLT    2023   \n\n\nRemember to use the measureid when using the next function."
  },
  {
    "objectID": "posts/Introducing the PLACES Package/index.html#function-get_places",
    "href": "posts/Introducing the PLACES Package/index.html#function-get_places",
    "title": "Introducing the CDCPLACES Package",
    "section": "Function: get_places",
    "text": "Function: get_places\nThis function allows us to easily query data that we specify. In the example below, I will get the measure ACCESS2 (the current lack of health insurance among adults aged 18-64 years) for the state of Arizona. This function allows for multiple of these arguments.\n\n\nCode\naz_access &lt;- get_places(state = \"AZ\", \n                        measure = \"ACCESS2\") \nhead(az_access)\n\n\n# A tibble: 6 × 21\n  year  stateabbr statedesc locationname datasource category   measure          \n  &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;            \n1 2021  AZ        Arizona   Yuma         BRFSS      Prevention Current lack of …\n2 2021  AZ        Arizona   Graham       BRFSS      Prevention Current lack of …\n3 2021  AZ        Arizona   Apache       BRFSS      Prevention Current lack of …\n4 2021  AZ        Arizona   La Paz       BRFSS      Prevention Current lack of …\n5 2021  AZ        Arizona   Coconino     BRFSS      Prevention Current lack of …\n6 2021  AZ        Arizona   Cochise      BRFSS      Prevention Current lack of …\n# ℹ 14 more variables: data_value_unit &lt;chr&gt;, data_value_type &lt;chr&gt;,\n#   data_value &lt;dbl&gt;, low_confidence_limit &lt;dbl&gt;, high_confidence_limit &lt;dbl&gt;,\n#   totalpopulation &lt;chr&gt;, locationid &lt;chr&gt;, categoryid &lt;chr&gt;, measureid &lt;chr&gt;,\n#   datavaluetypeid &lt;chr&gt;, short_question_text &lt;chr&gt;, type &lt;chr&gt;, lon &lt;dbl&gt;,\n#   lat &lt;dbl&gt;\n\n\nIt is also worth noting that by default geography specifying geography is set to “county”. If instead we want to examine census tracts, we could specify the argument. Likewise, release is set to “2023” by default.\nThe argument county can be used to filter results to specific counties. This is extremely useful for examining census level data for specific areas of states. Additionally, geometry can be added to include a shapefile in the query. For further examples of plotting with shapefiles, see this dedicated blog post.\n\n\nCode\ncap_counties &lt;- get_places(geography = \"census\",\n                           state = \"MI\",\n                           measure = \"ACCESS2\",\n                           county = c(\"Ingham\", \"Eaton\", \"Clinton\"),\n                           geometry = TRUE)"
  },
  {
    "objectID": "posts/Introducing the PLACES Package/index.html#use-case",
    "href": "posts/Introducing the PLACES Package/index.html#use-case",
    "title": "Introducing the CDCPLACES Package",
    "section": "Use Case",
    "text": "Use Case\nFrom here, we can start to have fun. It is fairly straight forward to begin exploring data. Here I will first filter out the data so that I can plot the age adjusted rates of lack of health insurance in Arizona.\nNotice that the data provide you with confidence limits, so I have chosen to plot them here with error bars.\n\n\nCode\naz_access %&gt;%\n  filter(datavaluetypeid == \"AgeAdjPrv\") %&gt;%\n  ggplot(aes(data_value, reorder(locationname, data_value))) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(xmin = low_confidence_limit, xmax = high_confidence_limit)) +\n  labs(title = \"Lack of health insurance among adults aged 18-64 years In Arizona Counties\",\n       y = \"\", x = \"Percent\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\nYou can also extend this to multiple states to compare. You can easily query two (or more) state names, and plot them. Arizona seems to have a couple of counties that have a much higher rate compared to others.\n\n\nCode\n# multi state comparison\ntwo &lt;- get_places(state = c(\"AZ\", \"NV\"), \n                  measure = \"ACCESS2\")\n\ntwo %&gt;%\n  filter(datavaluetypeid == \"AgeAdjPrv\") %&gt;%\n  ggplot(aes(data_value, reorder(locationname, data_value), color = stateabbr)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(xmin = low_confidence_limit, xmax = high_confidence_limit)) +\n  labs(title = \n         \"Lack of health insurance among adults aged 18-64 years In Arizona and Nevada\",\n       y = \"Counties\", x = \"Percent\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\nWe can go even further by comparing more states in the region. Here I have taken the average rate by state to easily compare. Texas appears to be far above the average.\n\n\nCode\nmulti &lt;- get_places(state = c(\"AZ\", \"NV\", \"NM\", \"TX\", \"CA\"), measure = \"ACCESS2\") %&gt;%\n  filter(datavaluetypeid == \"AgeAdjPrv\") %&gt;%\n  summarise(.by = \"stateabbr\", mean_val = mean(data_value), mean_low = mean(low_confidence_limit), mean_high = mean(high_confidence_limit))\n\nmulti %&gt;%\n  ggplot(aes(mean_val, reorder(stateabbr, mean_val), color = stateabbr)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(xmin = mean_low, xmax = mean_high)) +\n  labs(title = \"Mean lack of health insurance among adults aged 18-64 years In Southwest States\",\n       y = \"\", x = \"Percent\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "projects/Tidy Tuesday/index.html#section-1",
    "href": "projects/Tidy Tuesday/index.html#section-1",
    "title": "Tidy Tuesday",
    "section": "2023",
    "text": "2023"
  },
  {
    "objectID": "projects/Tidy Tuesday/index.html#section",
    "href": "projects/Tidy Tuesday/index.html#section",
    "title": "Tidy Tuesday",
    "section": "",
    "text": "::: .g-col-12 .g-col-md-6} \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "posts/Introducing the PLACES Package/index.html#function-get_dictionary",
    "href": "posts/Introducing the PLACES Package/index.html#function-get_dictionary",
    "title": "Introducing the CDCPLACES Package",
    "section": "Function: get_dictionary",
    "text": "Function: get_dictionary\nOur first functions allows us to easily view what measures we can query, via ‘measureid’, along with a brief definition of each function. If we run get_dictionary, a data frame is returned. We can view the measures in a data frame in the R Studio with View(). This is the preferred method for exploring the available measures.\nFor our example here, I will print the names of the variables in this dataframe.\n\n\nCode\n# To open a viewer\n# get_dictionary() %&gt;% View()\n\nget_dictionary() %&gt;% names()\n\n\n [1] \"measureid\"                \"measure_full_name\"       \n [3] \"measure_short_name\"       \"categoryid\"              \n [5] \"category_name\"            \"places_release_2023\"     \n [7] \"places_release_2022\"      \"places_release_2021\"     \n [9] \"places_release_2020\"      \"_500_cities_release_2019\"\n[11] \"_500_cities_release_2018\" \"_500_cities_release_2017\"\n[13] \"_500_cities_release_2016\" \"frequency_brfss_year\"    \n\n\nThis data frame is useful for several reasons. It lists the available measures for each year of the CDC PLACES data, along with the data each variable was collected, all in a single place. Remember to use the measureid when querying your data."
  },
  {
    "objectID": "index.html#brenden-smith",
    "href": "index.html#brenden-smith",
    "title": "Brenden Smith",
    "section": "",
    "text": "Hi, I’m Brenden. I am an MPH candidate with interests in health equity, harm reduction, and community engagement. I am a data analyst, community researcher, and R enthusiast.\nIf you would like to see some of my current and past work, you can visit my portfolio page or check out my blog."
  },
  {
    "objectID": "projects/R Shiny Apps/Mental Health and the Pandemic/index.html",
    "href": "projects/R Shiny Apps/Mental Health and the Pandemic/index.html",
    "title": "Mental Health and the Pandemic",
    "section": "",
    "text": "Introduction\nThis project was originally a submission to the National Center for Health Statistics and AcademyHealth sponsored Data Visualization Challenge in Fall of 2022.\nThis web application was my first experience building a Shiny application! I found it fascinating to dive into the mechanics of making a usable, interactive web application for data exploration.\nThis project uses data from the Household Pulse Survey as well as data from the Uniform Data System to understand mental illness during the pandemic years. HHP data shows national trends for varying mental illnesses while the UDS data speaks to the experience of patients accessing care at federally qualified health centers throughout the country. We added this data and compared it with poverty rates across U.S. counties (American Community Survey) and mental health provider shortage levels (Area Health Resources Files).\nMy favorite part of this challenge was getting to create large, interactive maps to explore these data.\nWhile the application could be embedded here, it is best viewed in its own window. You can access the app and the full data here."
  },
  {
    "objectID": "projects/shiny.html",
    "href": "projects/shiny.html",
    "title": "R Shiny Apps",
    "section": "",
    "text": "Sugar Smart Coalition Lansing - Nutrition Calculator\n\n\nCalculator\n\n\n\nBrenden Smith\n\n\nJan 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMental Health and the Pandemic\n\n\nNCHS/AcademyHealth Data Visualization Challenge Submission\n\n\n\nBrenden Smith\n\n\nNov 14, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/R Shiny Apps/index.html#mental-health-and-the-pandemic",
    "href": "projects/R Shiny Apps/index.html#mental-health-and-the-pandemic",
    "title": "R Shiny Apps",
    "section": "Mental Health and the Pandemic",
    "text": "Mental Health and the Pandemic\nThis project was originally a submission to the National Center for Health Statistics and AcademyHealth sponsored Data Visualization Challenge in Fall of 2022.\nThis web application was my first experience building a Shiny application! I found it fascinating to dive into the mechanics of making a usable, interactive web application for data exploration.\nThis project uses data from the Household Pulse Survey as well as data from the Uniform Data System to understand mental illness during the pandemic years. HHP data shows national trends for varying mental illnesses while the UDS data speaks to the experience of patients accessing care at federally qualified health centers throughout the country. We added this data and compared it with poverty rates across U.S. counties (American Community Survey) and mental health provider shortage levels (Area Health Resources Files).\nMy favorite part of this challenge was getting to create large, interactive maps to explore these data.\nWhile the application could be embedded here, it is best viewed in its own window. You can access the app and the full data here."
  },
  {
    "objectID": "projects/R Shiny Apps/index.html#cdcplaces-data-explorer",
    "href": "projects/R Shiny Apps/index.html#cdcplaces-data-explorer",
    "title": "R Shiny Apps",
    "section": "CDCPLACES Data Explorer",
    "text": "CDCPLACES Data Explorer"
  },
  {
    "objectID": "posts/Shapefiles in CDCPLACES/index.html",
    "href": "posts/Shapefiles in CDCPLACES/index.html",
    "title": "What’s New in CDCPLACES 1.1.5",
    "section": "",
    "text": "An earlier version of this blog post was published on February 6, 2024 and described the new features in the development version of this package. This update shows all of the new features of the package as of March 16, 2024."
  },
  {
    "objectID": "posts/Shapefiles in CDCPLACES/index.html#introduction",
    "href": "posts/Shapefiles in CDCPLACES/index.html#introduction",
    "title": "What’s New in CDCPLACES 1.1.5",
    "section": "Introduction",
    "text": "Introduction\nCDCPLACES version 1.1.5 is now available on CRAN. Users can now request an sf data frame to allow for simple, streamlined mapping of PLACES data. To use this new feature, be sure to install the latest version from CRAN or GitHub.\n\n\nCode\n# Install the latest development version\n# devtools::install_github(\"brendensm/CDCPLACES\")\n\n# Or from CRAN\n# install.packages(\"CDCPLACES\")\n\nlibrary(CDCPLACES)\nlibrary(ggplot2)\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/Shapefiles in CDCPLACES/index.html#new-arguement-geometry",
    "href": "posts/Shapefiles in CDCPLACES/index.html#new-arguement-geometry",
    "title": "Shapefiles in CDCPLACES 1.1.5",
    "section": "New arguement geometry",
    "text": "New arguement geometry\n\n\nCode\nmi &lt;- get_places(state = \"MI\", measure = \"SLEEP\", geometry = TRUE)\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |                                                                      |   1%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |==                                                                    |   4%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |=======                                                               |  11%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  12%\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |============                                                          |  18%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |==============                                                        |  21%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |===================                                                   |  28%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  29%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |=====================                                                 |  31%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |=========================                                             |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |==========================                                            |  38%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |============================                                          |  41%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |===============================                                       |  45%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |=================================                                     |  48%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |===================================                                   |  51%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |=======================================                               |  55%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |========================================                              |  56%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |========================================                              |  58%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |==========================================                            |  61%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |=============================================                         |  65%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  66%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |===============================================                       |  68%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |=================================================                     |  71%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=====================================================                 |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |======================================================                |  78%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |========================================================              |  81%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==========================================================            |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |=============================================================         |  88%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===============================================================       |  89%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |===============================================================       |  91%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |====================================================================  |  98%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================|  99%\n  |                                                                            \n  |======================================================================| 100%\n\n\nCode\nmi |&gt; \n  filter(datavaluetypeid == \"AgeAdjPrv\") |&gt; \n  ggplot(aes(fill = data_value)) +\n  geom_sf() +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  theme_minimal() +\n  labs(title = mi$measure) +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\nCode\nvt &lt;- get_places(geo = \"census\", state = c(\"VT\"), measure = \"SLEEP\", geometry = TRUE)\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |===============================================================       |  89%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |======================================================================| 100%\n\n\nCode\nvt |&gt; \n  ggplot(aes(fill = data_value)) +\n  geom_sf(color = \"grey30\") +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  theme_minimal() +\n  labs(title = vt$measure) +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "posts/Shapefiles in CDCPLACES/index.html#acknowledgements",
    "href": "posts/Shapefiles in CDCPLACES/index.html#acknowledgements",
    "title": "What’s New in CDCPLACES 1.1.5",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese features would not be possible without the excellent work of Kyle Walker’s package tigris. The contributions he has made to the R community have been incredibly inspiring to me. His other package, tidycensus was the inspiration for this entire pacakge. To see his work visit his website here."
  },
  {
    "objectID": "posts/Shapefiles in CDCPLACES/index.html#new-argument-geometry",
    "href": "posts/Shapefiles in CDCPLACES/index.html#new-argument-geometry",
    "title": "What’s New in CDCPLACES 1.1.5",
    "section": "New argument geometry",
    "text": "New argument geometry\nFirst we need to query our data. To include our shape file, we need to specify the argument geometry as “TRUE”. For our first example we will look at the percentage of adults sleeping less than 7 hours in Michigan Counties.\n\n\nCode\nmi &lt;- get_places(state = \"MI\", \n                 measure = \"SLEEP\", \n                 geometry = TRUE)\n\n\nNow we can take this dataset and immediately plot the spatial data with ggplot2. I will also add a nicer looking color palette and the percentage scale in scale_fill_viridis_c, as well as a title with the function labs.\n\n\nCode\nmi |&gt; \n  filter(datavaluetypeid == \"AgeAdjPrv\") |&gt; \n  ggplot(aes(fill = data_value)) +\n  geom_sf() +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  theme_void() +\n  labs(title = mi$measure) +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\nWe can do the same for census level data. This is as simple as specifying our geography to “census”.\n\n\nCode\nvt &lt;- get_places(geography = \"census\", \n                 state = \"VT\", \n                 measure = \"SLEEP\", \n                 geometry = TRUE)\n\n\nThen we can map it just the same.\n\n\nCode\nvt |&gt; \n  ggplot(aes(fill = data_value)) +\n  geom_sf() +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  theme_void() +\n  labs(title = vt$measure) +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "posts/Shapefiles in CDCPLACES/index.html#query-by-county",
    "href": "posts/Shapefiles in CDCPLACES/index.html#query-by-county",
    "title": "What’s New in CDCPLACES 1.1.5",
    "section": "Query by County",
    "text": "Query by County\nThis update also allows for the user to query specific counties using the argument county. In the example below, we can specify the state and counties we want to plot with simple syntax.\n\n\nCode\ncap_county &lt;- get_places(geography = \"census\", \n                         state = \"MI\", \n                         measure = \"ACCESS2\", \n                         county = c(\"Ingham\", \"Eaton\", \"Clinton\"), \n                         geometry = TRUE)\n\n\nOnce this is done, we can plot our data.\n\n\nCode\ncap_county |&gt; \n  ggplot(aes(fill = data_value)) +\n  geom_sf() +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  theme_void() +\n  labs(title = cap_county$measure) +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "posts/Text in R/index.html",
    "href": "posts/Text in R/index.html",
    "title": "I Made R Text For Me",
    "section": "",
    "text": "Up front, I have problems with procrastination. The last few years in graduate school have made me prioritize certain things MUCH better. However, in my personal life, I still struggle. I continue to put off things that I would rather do later. A prime example of this is my role as utility-bill-payer in my current living situation.\nIt is my duty to pay our house’s gas, internet, trash, and electric/water bills every month. I am reliable enough for this (especially with the convenience of automatic payments). My struggle is the monthly task of rounding up these payments, calculating the totals owed by my respective roommates, and the herculean task of texting them the breakdown for the month. Lately, I have been contemplating fun, useful projects to work on using the beauty of programming languages and I realized this is the perfect thing to do.\nThe plan? Make this process as easy as possible for me. With a little trial and error, I’ve done it.\nThis project consists of:\n\nA spreadsheet to store the monthly breakdown of utility payments (unfortunately, this still has to be done by hand).\nAn R script to pull this spreadsheet in and send a custom text message that uses the most recent month’s total and roommate share amount (along with a breakdown of each bill amount).\nA method to automatically run this process without any reliability on my behalf (insert cron jobs)."
  },
  {
    "objectID": "posts/Text in R/index.html#introduction",
    "href": "posts/Text in R/index.html#introduction",
    "title": "I Made R Text For Me",
    "section": "",
    "text": "Up front, I have problems with procrastination. The last few years in graduate school have made me prioritize certain things MUCH better. However, in my personal life, I still struggle. I continue to put off things that I would rather do later. A prime example of this is my role as utility-bill-payer in my current living situation.\nIt is my duty to pay our house’s gas, internet, trash, and electric/water bills every month. I am reliable enough for this (especially with the convenience of automatic payments). My struggle is the monthly task of rounding up these payments, calculating the totals owed by my respective roommates, and the herculean task of texting them the breakdown for the month. Lately, I have been contemplating fun, useful projects to work on using the beauty of programming languages and I realized this is the perfect thing to do.\nThe plan? Make this process as easy as possible for me. With a little trial and error, I’ve done it.\nThis project consists of:\n\nA spreadsheet to store the monthly breakdown of utility payments (unfortunately, this still has to be done by hand).\nAn R script to pull this spreadsheet in and send a custom text message that uses the most recent month’s total and roommate share amount (along with a breakdown of each bill amount).\nA method to automatically run this process without any reliability on my behalf (insert cron jobs)."
  },
  {
    "objectID": "posts/Text in R/index.html#the-spreadsheet",
    "href": "posts/Text in R/index.html#the-spreadsheet",
    "title": "I Made R Text For Me",
    "section": "The Spreadsheet",
    "text": "The Spreadsheet\nThis was a task I already had mostly completed. At the beginning of this year, I created a very basic spreadsheet in Google Sheets to track my utility bills. One table consists of the data in a tidy format, including columns for the month, bill type, amount, and date paid. A second table creates a sum from the first table giving the date to notify (the first of the month after the month in which the bill was paid), the total amount, and the amount owed by the roommate (one-third split on the total).\nBecause each bill comes from a different place and my email isn’t easily accessible to a programming language, I still have to update this spreadsheet by hand whenever I am notified of a payment. And for my purposes, I was ok with this!"
  },
  {
    "objectID": "posts/Text in R/index.html#r-script",
    "href": "posts/Text in R/index.html#r-script",
    "title": "I Made R Text For Me",
    "section": "R Script",
    "text": "R Script\nThe script for this project has three main tasks:\n\nImport the data from Google Sheets.\nCreate the text of the message.\nSend the text message.\n\n\nGetting the Data\nFirst, we can call the libraries we will need.\n\n\nCode\nlibrary(googlesheets4)\nlibrary(dplyr)\n\n\nThe package googlesheets4 made this project incredibly easy.\nYou can connect to your Google account using gs4_auth.\n\n\nCode\ngs4_auth(email = \"your email here\")\n\n\nThen, you can import your sheet.\n\n\nCode\ndata &lt;- read_sheet(\"your_url_here\")\n\n\nTo demonstrate what my data looked like, I will create a demo data set to work with in this example.\n\n\nCode\nmonth &lt;- c(\"Feb\", \"Feb\", \"Feb\", \"Mar\", \"Mar\", \"Mar\")\n\nbill_type &lt;- c(\"Gas\", \"Water\", \"Internet\", \"Gas\", \"Water\", \"Internet\")\n\namount &lt;- c(50, 62, 25, 55, 70, 25)\n\ndue_date &lt;- c(\"2/1/2024\", \"2/4/2024\", \"2/5/2024\", \n              \"3/1/2024\", \"3/5/2024\", \"3/6/2024\")\n\ntable1 &lt;- data.frame(month, bill_type, amount, due_date) |&gt; \n  mutate(due_date = lubridate::mdy(due_date))\n\ntable1\n\n\n  month bill_type amount   due_date\n1   Feb       Gas     50 2024-02-01\n2   Feb     Water     62 2024-02-04\n3   Feb  Internet     25 2024-02-05\n4   Mar       Gas     55 2024-03-01\n5   Mar     Water     70 2024-03-05\n6   Mar  Internet     25 2024-03-06\n\n\nCode\ntable2.1&lt;- table1 |&gt; \n  summarise(.by = month,\n            total = sum(amount),\n            third = total/3) \n\nnotify &lt;- c(\"3/1/2024\", \"4/1/2024\")\n\ntable2.2 &lt;- data.frame(notify) |&gt; \n  mutate(notify = lubridate::mdy(notify))\n\ntable2 &lt;- cbind(table2.1, table2.2)\ntable2\n\n\n  month total    third     notify\n1   Feb   137 45.66667 2024-03-01\n2   Mar   150 50.00000 2024-04-01\n\n\n\n\nCreating the Message\nBecause my real data has all of the month’s data in it, we need to filter to get the right amounts to send in our text. We can use Sys.Date to get the current date, and lubridate::month to make the date a numeric value representing the month.\nThen we can do the same for our tables to filter by. Remember I will have this script executing at the first of every month to report what the costs were for the previous month.\n\n\nCode\n# current_month &lt;- lubridate::month(Sys.Date())\ncurrent_month &lt;- 4 # for our example\n\nfiltered_sum &lt;- table2 |&gt; \n  mutate(notify = lubridate::month(notify)) |&gt; \n  filter(notify == current_month)\n\nmonthly_total &lt;- filtered_sum$total\n\nthird &lt;- filtered_sum$third\n\nbreakdown &lt;- table1 |&gt; \n  mutate(month_num = lubridate::month(due_date)) \n\nbreakdown_amounts &lt;- breakdown |&gt; \n  filter(month_num == (current_month - 1)) |&gt; \n  select(bill_type, amount)\n\n\nNow that we have the amounts we need, we can construct a message.\n\n\nCode\n message &lt;- paste(\"The total of our utility bill for the month of\", \n                  filtered_sum$month, \"is:\", monthly_total, \n                  \"\\nA third of this total is:\", round(third, 2), \n                   \"\\n\\nHere is a breakdown of the bill:\",\n                   paste0(\"\\n\", breakdown_amounts[1,1], \": \",\n                     breakdown_amounts[1,2], \"\\n\",\n                     breakdown_amounts[2,1], \": \",\n                     breakdown_amounts[2,2], \"\\n\",\n                     breakdown_amounts[3,1], \": \",\n                     breakdown_amounts[3,2]\n                   )\n )\n\ncat(message)\n\n\nThe total of our utility bill for the month of Mar is: 150 \nA third of this total is: 50 \n\nHere is a breakdown of the bill: \nGas: 55\nWater: 70\nInternet: 25\n\n\n\n\nSending the Message\nNext, we text.\nThe method I am using is only for iMessage devices, and is really only possible from a Mac. This method is taken from a very helpful Stackoverflow post. There is probably a workaround for other devices and sending through SMS, but that is not the focus of this post.\nWe can send our text with an Apple Script. Here is a function to do just that. This is slightly adapted from the Stackoverflow answer and allows for separate texts to multiple recipients.\n\n\nCode\nsend_text &lt;- function(message, buddy){\n  \n  for(i in buddy){\n    system(paste('osascript -e \\'tell application \"Messages\"\\' -e \\'send \"', message, '\" to buddy', i,  'of (service 1 whose service type is iMessage)\\' -e \\'end tell\\''))\n  }\n  \n}\n\n\nThen we can simply plug in the rest. But be warned: running this command will send a text! Be careful when testing this out.\n\n\nCode\nbuddies &lt;- c(\"\\\"phonenumber1\\\"\", \"\\\"phonenumber2\\\"\")\n\nsend_text(message, buddies)"
  },
  {
    "objectID": "posts/Text in R/index.html#cron-job",
    "href": "posts/Text in R/index.html#cron-job",
    "title": "I Made R Text For Me",
    "section": "cron Job",
    "text": "cron Job"
  },
  {
    "objectID": "posts/Text in R/index.html#other-considerations",
    "href": "posts/Text in R/index.html#other-considerations",
    "title": "I Made R Text For Me",
    "section": "Other Considerations",
    "text": "Other Considerations\nLastly, I want to note a small consideration when setting up an automated process like this. The cron job will run in this form only if the computer is awake during the scheduled time.\nTo work around this, you can utilize the battery options in your Mac’s system preferences. I have scheduled my computer to wake up every day at 9 AM for about five minutes. This was the easiest work around for me. However, I am certain there are other options to achieve the same goal. One option may be to use alternative scheduling tools like cronwake or anacron."
  },
  {
    "objectID": "posts/Text in R/index.html#the-cron-job",
    "href": "posts/Text in R/index.html#the-cron-job",
    "title": "I Made R Text For Me",
    "section": "The Cron Job",
    "text": "The Cron Job\nNow that the hard part is over, we can simply create a cron job to run this script directly from the command line on the first of every month.\nImportant: make sure the following is at the top of your saved R script:\n\n\nCode\n#!/usr/local/bin/Rscript\n\n\nTo open your cron tab, in the terminal type the following command:\n\n\nCode\nexport VISUAL=nano; crontab -e\n\n\nAs an added tip, you can save this command as an alias in your .zshrc file to make it easier to quickly access.\nOnce the cron tab is open, you have to set up the job and specify how often you want it to run. The following runs on the first of every month at 9 AM. The command navigates to my home directory, and then executes my R script which I have named “utes_notif.R”.\n\n\nCode\n0 9 1 * * cd ~; ./Desktop/R/utility_notification/utes_notif.R"
  },
  {
    "objectID": "blog/HM878: Helper Functions/index.html",
    "href": "blog/HM878: Helper Functions/index.html",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "This vignette demonstrates how to use the functions included in this package so far. If you have not yet, install the package with the following code: devtools::install_github(\"brendensm/hm878\"). If you do not have the package devtools, be sure to install that first install.packages(\"devtools\").\nTo start, we load the package\n\nlibrary(hm878)\n\nLet’s assume we are running a binomial logistic regression using the data from mtcars, a built-in data set included with R. We will use vs (engine type as V-shaped or straight) as the dependent variable, and cyl (number of cylinders) as the independent variable. We will store our models for block 1 and block 2.\n\nmb1 &lt;- glm(vs ~ 1, data = mtcars, family = \"binomial\")\nmb2 &lt;- glm(vs ~ cyl, data = mtcars, family = \"binomial\")\n\n\n\nTo assess the fit of our models, we may want to use the function chi_log. To use it, simply type in the name of your model as the first argument, followed by the data set that the model uses. Optionally, you can provide labels for each model using the third argument. Here I will label each block.\n\nchi_log(mb1, mtcars, \"Block 1\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 1:  32 \n Degrees of freedom for Block 1:  31 \n P-value for Block 1:  0.416744 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\nchi_log(mb2, mtcars, \"Block 2\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 2:  27.42 \n Degrees of freedom for Block 2:  30 \n P-value for Block 2:  0.6013516 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\n\nThe function gives us the chi-squared statistic, degrees of freedom, and a p-value. It also reminds us of the null and alternative hypotheses. Both models appear to be a good fit.\n\n\n\nWe may want to also check the accuracy of our models. To do this, we can use predict_percent. To use this function, enter the name of the model in the first argument, followed by the dependent variable we used in the model. For this, we must use the data$variable format. In the example below, we use the variable vs from the data set mtcars. Once again, we can label the output with a string as the optional third argument.\n\npredict_percent(mb1, mtcars$vs, \"Block 1\")\n\n\nAccuracy for Block 1: 56.25%\n\npredict_percent(mb2, mtcars$vs, \"Block 2\")\n\n\nAccuracy for Block 2: 84.38%\n\n\n\n\n\nTo calculate odds ratios for the models, simply pass the model through the function or.\n\nor(mb1)\n\n            Odds_Ratio  CI_Lower CI_Upper  p_values\n(Intercept)  0.7777778 0.3801366 1.558936 0.4806496\n\nor(mb2)\n\n              Odds_Ratio    CI_Lower     CI_Upper    p_values\n(Intercept) 10873.447296 95.35600799 6.507716e+07 0.002692584\ncyl             0.204474  0.04827075 4.455527e-01 0.001917098\n\n\nThe output results in a data frame with the odds ratios, confidence intervals, and p-values.\n\n\n\nIf you want to revise and adjust your model, it can be helpful to limit outliers. To find upper and lower fences quickly, use the function fences. To do this, pass the continuous variable you are interested in examining through the function. Once again, use the format data$variable.\n\nfences(mtcars$cyl)\n\n    lower_fence upper_fence\ncyl          -2          14\n\nfences(mtcars$cyl)$Upper\n\nNULL\n\nfences(mtcars$cyl)$Lower\n\nNULL\n\n\n\n\n\nLastly, when you are putting together multiple models, it can be helpful to view them all at the same time, next to one another. This is particularly helpful if you have more than two models you are comparing. For this function, pass through however many models you have to compare, and optionally label each one, using a vector of strings for each model. To demonstrate, I will add on another model mb3 that will have another continuous independent variable.\n\nmb3 &lt;- glm(vs ~ cyl + wt, data = mtcars, family = \"binomial\")\n\ncompare_models(mb1, mb2, mb3, labels = c(\"Model 1 Block 1\", \"Model 1 Block 2\", \"Model Block 3\"))\n\n$`Model 1 Block 1`\n\nCall:  glm(formula = vs ~ 1, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)  \n    -0.2513  \n\nDegrees of Freedom: 31 Total (i.e. Null);  31 Residual\nNull Deviance:      43.86 \nResidual Deviance: 43.86    AIC: 45.86\n\n$`Model 1 Block 2`\n\nCall:  glm(formula = vs ~ cyl, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl  \n      9.294       -1.587  \n\nDegrees of Freedom: 31 Total (i.e. Null);  30 Residual\nNull Deviance:      43.86 \nResidual Deviance: 17.96    AIC: 21.96\n\n$`Model Block 3`\n\nCall:  glm(formula = vs ~ cyl + wt, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl           wt  \n     10.619       -2.931        2.100  \n\nDegrees of Freedom: 31 Total (i.e. Null);  29 Residual\nNull Deviance:      43.86 \nResidual Deviance: 15.55    AIC: 21.55\n\n\n\n\n\n\ndeviance_aic(mb1, mb2, mb3)\n\nmb1 \nResidual Deviance: 43.86 \nNull Deviance: 43.86 \nAIC: 45.86 \n\nmb2 \nResidual Deviance: 17.96 \nNull Deviance: 43.86 \nAIC: 21.96 \n\nmb3 \nResidual Deviance: 15.55 \nNull Deviance: 43.86 \nAIC: 21.55"
  },
  {
    "objectID": "blog/HM878: Helper Functions/index.html#testing-goodness-of-fit-with-chi_log",
    "href": "blog/HM878: Helper Functions/index.html#testing-goodness-of-fit-with-chi_log",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "To assess the fit of our models, we may want to use the function chi_log. To use it, simply type in the name of your model as the first argument, followed by the data set that the model uses. Optionally, you can provide labels for each model using the third argument. Here I will label each block.\n\nchi_log(mb1, mtcars, \"Block 1\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 1:  32 \n Degrees of freedom for Block 1:  31 \n P-value for Block 1:  0.416744 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\nchi_log(mb2, mtcars, \"Block 2\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 2:  27.42 \n Degrees of freedom for Block 2:  30 \n P-value for Block 2:  0.6013516 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\n\nThe function gives us the chi-squared statistic, degrees of freedom, and a p-value. It also reminds us of the null and alternative hypotheses. Both models appear to be a good fit."
  },
  {
    "objectID": "blog/HM878: Helper Functions/index.html#accuracy-percentage-with-predict_percent",
    "href": "blog/HM878: Helper Functions/index.html#accuracy-percentage-with-predict_percent",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "We may want to also check the accuracy of our models. To do this, we can use predict_percent. To use this function, enter the name of the model in the first argument, followed by the dependent variable we used in the model. For this, we must use the data$variable format. In the example below, we use the variable vs from the data set mtcars. Once again, we can label the output with a string as the optional third argument.\n\npredict_percent(mb1, mtcars$vs, \"Block 1\")\n\n\nAccuracy for Block 1: 56.25%\n\npredict_percent(mb2, mtcars$vs, \"Block 2\")\n\n\nAccuracy for Block 2: 84.38%"
  },
  {
    "objectID": "blog/HM878: Helper Functions/index.html#calculating-odds-ratios-with-or",
    "href": "blog/HM878: Helper Functions/index.html#calculating-odds-ratios-with-or",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "To calculate odds ratios for the models, simply pass the model through the function or.\n\nor(mb1)\n\n            Odds_Ratio  CI_Lower CI_Upper  p_values\n(Intercept)  0.7777778 0.3801366 1.558936 0.4806496\n\nor(mb2)\n\n              Odds_Ratio    CI_Lower     CI_Upper    p_values\n(Intercept) 10873.447296 95.35600799 6.507716e+07 0.002692584\ncyl             0.204474  0.04827075 4.455527e-01 0.001917098\n\n\nThe output results in a data frame with the odds ratios, confidence intervals, and p-values."
  },
  {
    "objectID": "blog/HM878: Helper Functions/index.html#upper-and-lower-fences-with-fences",
    "href": "blog/HM878: Helper Functions/index.html#upper-and-lower-fences-with-fences",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "If you want to revise and adjust your model, it can be helpful to limit outliers. To find upper and lower fences quickly, use the function fences. To do this, pass the continuous variable you are interested in examining through the function. Once again, use the format data$variable.\n\nfences(mtcars$cyl)\n\n    lower_fence upper_fence\ncyl          -2          14\n\nfences(mtcars$cyl)$Upper\n\nNULL\n\nfences(mtcars$cyl)$Lower\n\nNULL"
  },
  {
    "objectID": "blog/HM878: Helper Functions/index.html#comparing-model-results-with-compare_models",
    "href": "blog/HM878: Helper Functions/index.html#comparing-model-results-with-compare_models",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "Lastly, when you are putting together multiple models, it can be helpful to view them all at the same time, next to one another. This is particularly helpful if you have more than two models you are comparing. For this function, pass through however many models you have to compare, and optionally label each one, using a vector of strings for each model. To demonstrate, I will add on another model mb3 that will have another continuous independent variable.\n\nmb3 &lt;- glm(vs ~ cyl + wt, data = mtcars, family = \"binomial\")\n\ncompare_models(mb1, mb2, mb3, labels = c(\"Model 1 Block 1\", \"Model 1 Block 2\", \"Model Block 3\"))\n\n$`Model 1 Block 1`\n\nCall:  glm(formula = vs ~ 1, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)  \n    -0.2513  \n\nDegrees of Freedom: 31 Total (i.e. Null);  31 Residual\nNull Deviance:      43.86 \nResidual Deviance: 43.86    AIC: 45.86\n\n$`Model 1 Block 2`\n\nCall:  glm(formula = vs ~ cyl, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl  \n      9.294       -1.587  \n\nDegrees of Freedom: 31 Total (i.e. Null);  30 Residual\nNull Deviance:      43.86 \nResidual Deviance: 17.96    AIC: 21.96\n\n$`Model Block 3`\n\nCall:  glm(formula = vs ~ cyl + wt, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl           wt  \n     10.619       -2.931        2.100  \n\nDegrees of Freedom: 31 Total (i.e. Null);  29 Residual\nNull Deviance:      43.86 \nResidual Deviance: 15.55    AIC: 21.55"
  },
  {
    "objectID": "blog/HM878: Helper Functions/index.html#deviance_aic-pull-the-deviances-and-aics-from-model-summarys",
    "href": "blog/HM878: Helper Functions/index.html#deviance_aic-pull-the-deviances-and-aics-from-model-summarys",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "deviance_aic(mb1, mb2, mb3)\n\nmb1 \nResidual Deviance: 43.86 \nNull Deviance: 43.86 \nAIC: 45.86 \n\nmb2 \nResidual Deviance: 17.96 \nNull Deviance: 43.86 \nAIC: 21.96 \n\nmb3 \nResidual Deviance: 15.55 \nNull Deviance: 43.86 \nAIC: 21.55"
  },
  {
    "objectID": "blog/opioid plotting practice/index.html",
    "href": "blog/opioid plotting practice/index.html",
    "title": "Opioid Plotting Practice",
    "section": "",
    "text": "Over the summer, I took a course on public health surveillance. As a culminating project, we were tasked with creating original data visualizations for a fact sheet on a topic of our choosing. I chose to examine local opioid overdose and mortality data for my project.\nThis is a topic that is near to me. The opioid crisis has impacted many communities across the country. At this point, the topic is well known to most people. Despite awareness, overdoses are still rising.\nIn the following post, I will demonstrate how easily you can spice up basic ggplot graphics. In particular we will look at:\n\na basic ggplot2 line chart\nggthemes we can use to make a more professional looking figure\nand a brief glimpse at plotly (because interactive graphs are so cool!)"
  },
  {
    "objectID": "blog/opioid plotting practice/index.html#introduction",
    "href": "blog/opioid plotting practice/index.html#introduction",
    "title": "Opioid Plotting Practice",
    "section": "",
    "text": "Over the summer, I took a course on public health surveillance. As a culminating project, we were tasked with creating original data visualizations for a fact sheet on a topic of our choosing. I chose to examine local opioid overdose and mortality data for my project.\nThis is a topic that is near to me. The opioid crisis has impacted many communities across the country. At this point, the topic is well known to most people. Despite awareness, overdoses are still rising.\nIn the following post, I will demonstrate how easily you can spice up basic ggplot graphics. In particular we will look at:\n\na basic ggplot2 line chart\nggthemes we can use to make a more professional looking figure\nand a brief glimpse at plotly (because interactive graphs are so cool!)"
  },
  {
    "objectID": "blog/opioid plotting practice/index.html#data-prep",
    "href": "blog/opioid plotting practice/index.html#data-prep",
    "title": "Opioid Plotting Practice",
    "section": "Data Prep",
    "text": "Data Prep\nTo begin, we will load in our libraries. Be sure to install them if you haven’t already.\n\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(readxl)\nlibrary(plotly)\n\nNext, we will read in our data using readxl. The data I am using comes from the Michigan Substance Use Disorder Data Repository (SUDDR). You can download the data yourself here. Keep in mind that the numbers we are working with in this example are raw counts of opioid overdose deaths by county, NOT rates. Therefore, we should not compare these counties against each other without considering population size differences. I’m interested in looking at changes over time with this dataset.\nBecause I’m focusing on the three counties in my area, I’m going to create a vector with the names of the capital area counties. This will make subsetting the data a little easier.\n\nopdeaths &lt;- read_xlsx(\"Opioid Overdose Deaths.xlsx\")\n\ncounties &lt;- c(\"Ingham\", \"Eaton\", \"Clinton\")"
  },
  {
    "objectID": "blog/opioid plotting practice/index.html#time-to-plot",
    "href": "blog/opioid plotting practice/index.html#time-to-plot",
    "title": "Opioid Plotting Practice",
    "section": "Time to Plot!",
    "text": "Time to Plot!\nFrom here, we can start our first plot. I will select my target counties using the filter() function that comes from the dplyr package. Be sure to specify which aesthetics you want to plot on the respective axes. Here we are putting the variable Year on the x-axis and Opioid Overdose Deaths on the y.\n\nopdeaths %&gt;%\n  filter(County %in% counties) %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line()\n\n\n\n\nOh no! What happened? We didn’t tell ggplot which lines we wanted to see. It is important that within the layer geom_line() we specify that we want to plot different lines based on our county variable. To do this, we simply add an aes() layer and assign color to County.\n\nopdeaths %&gt;%\n  filter(County %in% counties) %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(aes(color = County))\n\n\n\n\nThat looks a lot better! But we can do more. The lines look a bit skinny to me. I would like them to stand out more. It also might help to adjust the opacity of the lines. This can make points that cross over easier to read. To make these changes, we can specify linewidth and alpha in geom_line() outside of the aes() argument.\nI think it would be great to add points to our plot, too. Like the geom_line() layer, I want these to be large enough and overlap easily. I will pass through similar arguments in the geom_point() layer, also specifying the color.\n\nopdeaths %&gt;%\n  filter(County %in% counties)  %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(linewidth = 1, alpha = 0.8, aes(color = County)) +\n  geom_point(size = 2, alpha = 0.8, aes(color = County))\n\n\n\n\nLastly, I want to add labels and theme to really polish up our plot. This is surprisingly easy! To add our labels, we add another layer called labs(). Here we can add a proper title, and more accurate labels for the axes.\nAdding a theme is even easier. We can quickly add on a layer and pick a theme that we like. For my example, I’m using the fivethirtyeight theme that comes from ggthemes. Be sure to check out the other options available in this package.\nAfter our theme_fivethrityeight() layer, I’m adding a general theme() layer to specify that I want all my main title and axes titles to be shown. I am also adjusting the text size to make the title a bit more readable.\n\nopdeaths %&gt;%\n  filter(County %in% counties)  %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(linewidth = 1, alpha = 0.8, aes(color = County)) +\n  geom_point(size = 2, alpha = 0.8, aes(color = County)) +\n  labs(title = \"Opioid Overdose Deaths in Michigan's Capital Area \\nCounties, 1999 – 2020\",\n       x = \"Year\",\n       y = \"Number of Deaths\") +\n  theme_fivethirtyeight() +\n  theme(plot.title = element_text(size = 16),\n        plot.title.position = \"plot\",\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size = 11),\n        axis.title.y = element_text(vjust = +3),\n        axis.title.x = element_text(vjust = -0.75),\n        text = element_text(family = \"Georgia\"),\n        plot.margin = unit(c(1, 1, 1, 1), \"lines\"))\n\n\n\n\nAnd just like that, we have a very nice looking line chart!"
  },
  {
    "objectID": "blog/opioid plotting practice/index.html#a-glimpse-of-plotly",
    "href": "blog/opioid plotting practice/index.html#a-glimpse-of-plotly",
    "title": "Opioid Plotting Practice",
    "section": "A Glimpse of Plotly",
    "text": "A Glimpse of Plotly\nNext I want to briefly show how easy it is to take a basic ggplot figure and make it interactive with the amazing package plotly. If I save the figure we created before as an object, we can pass it through the function ggplotly(), and as a result, we get a chart where we can zoom in and hover over points to gain more insight. I will demonstrate this below.\n\np1 &lt;- opdeaths %&gt;%\n  filter(County %in% counties)  %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(linewidth = 1, alpha = 0.8, aes(color = County)) +\n  geom_point(size = 2, alpha = 0.8, aes(color = County)) +\n  labs(title = \"Opioid Overdose Deaths in Michigan's Capital Area Counties, 1999 – 2020\",\n       x = \"Year\",\n       y = \"Number of Deaths\") +\n  theme_fivethirtyeight() +\n  theme(plot.title = element_text(size = 16),\n        plot.title.position = \"plot\",\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size = 11),\n        axis.title.y = element_text(vjust = +3),\n        axis.title.x = element_text(vjust = -0.75),\n        text = element_text(family = \"Georgia\"),\n        plot.margin = unit(c(1, 1, 1, 1), \"lines\"))\n\nggplotly(p1)\n\n\n\n\n\nIt’s amazing how quickly you can produce interactive charts with R! The output from this function in an html widget. So it can easily be viewed on a website or a local html file. This makes it ideal for sharing graphics quickly among coworkers.\nFor my project, I created a few more graphics with the same color palette and arranged them on a pdf for easy distribution. If you want to view the finished product you can find that here.\nI hope you found this post helpful. Next time I want to focus more on plotly demonstrating its capabilities with spatial data analysis. Until next time!"
  },
  {
    "objectID": "blog/Text in R/index.html",
    "href": "blog/Text in R/index.html",
    "title": "I Made R Text For Me",
    "section": "",
    "text": "Up front, I have problems with procrastination. The last few years in graduate school have made me prioritize certain things MUCH better. However, in my personal life, I still struggle. I continue to put off things that I would rather do later. A prime example of this is my role as utility-bill-payer in my current living situation.\nIt is my duty to pay our house’s gas, internet, trash, and electric/water bills every month. I am reliable enough for this (especially with the convenience of automatic payments). My struggle is the monthly task of rounding up these payments, calculating the totals owed by my respective roommates, and the herculean task of texting them the breakdown for the month. Lately, I have been contemplating fun, useful projects to work on using the beauty of programming languages and I realized this is the perfect thing to do.\nThe plan? Make this process as easy as possible for me. With a little trial and error, I’ve done it.\nThis project consists of:\n\nA spreadsheet to store the monthly breakdown of utility payments (unfortunately, this still has to be done by hand).\nAn R script to pull this spreadsheet in and send a custom text message that uses the most recent month’s total and roommate share amount (along with a breakdown of each bill amount).\nA method to automatically run this process without any reliability on my behalf (insert cron jobs)."
  },
  {
    "objectID": "blog/Text in R/index.html#introduction",
    "href": "blog/Text in R/index.html#introduction",
    "title": "I Made R Text For Me",
    "section": "",
    "text": "Up front, I have problems with procrastination. The last few years in graduate school have made me prioritize certain things MUCH better. However, in my personal life, I still struggle. I continue to put off things that I would rather do later. A prime example of this is my role as utility-bill-payer in my current living situation.\nIt is my duty to pay our house’s gas, internet, trash, and electric/water bills every month. I am reliable enough for this (especially with the convenience of automatic payments). My struggle is the monthly task of rounding up these payments, calculating the totals owed by my respective roommates, and the herculean task of texting them the breakdown for the month. Lately, I have been contemplating fun, useful projects to work on using the beauty of programming languages and I realized this is the perfect thing to do.\nThe plan? Make this process as easy as possible for me. With a little trial and error, I’ve done it.\nThis project consists of:\n\nA spreadsheet to store the monthly breakdown of utility payments (unfortunately, this still has to be done by hand).\nAn R script to pull this spreadsheet in and send a custom text message that uses the most recent month’s total and roommate share amount (along with a breakdown of each bill amount).\nA method to automatically run this process without any reliability on my behalf (insert cron jobs)."
  },
  {
    "objectID": "blog/Text in R/index.html#the-spreadsheet",
    "href": "blog/Text in R/index.html#the-spreadsheet",
    "title": "I Made R Text For Me",
    "section": "The Spreadsheet",
    "text": "The Spreadsheet\nThis was a task I already had mostly completed. At the beginning of this year, I created a very basic spreadsheet in Google Sheets to track my utility bills. One table consists of the data in a tidy format, including columns for the month, bill type, amount, and date paid. A second table creates a sum from the first table giving the date to notify (the first of the month after the month in which the bill was paid), the total amount, and the amount owed by the roommate (one-third split on the total).\nBecause each bill comes from a different place and my email isn’t easily accessible to a programming language, I still have to update this spreadsheet by hand whenever I am notified of a payment. And for my purposes, I was ok with this!"
  },
  {
    "objectID": "blog/Text in R/index.html#r-script",
    "href": "blog/Text in R/index.html#r-script",
    "title": "I Made R Text For Me",
    "section": "R Script",
    "text": "R Script\nThe script for this project has three main tasks:\n\nImport the data from Google Sheets.\nCreate the text of the message.\nSend the text message.\n\n\nGetting the Data\nFirst, we can call the libraries we will need.\n\n\nCode\nlibrary(googlesheets4)\nlibrary(dplyr)\n\n\nThe package googlesheets4 made this project incredibly easy.\nYou can connect to your Google account using gs4_auth.\n\n\nCode\ngs4_auth(email = \"your email here\")\n\n\nThen, you can import your sheet.\n\n\nCode\ndata &lt;- read_sheet(\"your_url_here\")\n\n\nTo demonstrate what my data looked like, I will create a demo data set to work with in this example.\n\n\nCode\nmonth &lt;- c(\"Feb\", \"Feb\", \"Feb\", \"Mar\", \"Mar\", \"Mar\")\n\nbill_type &lt;- c(\"Gas\", \"Water\", \"Internet\", \"Gas\", \"Water\", \"Internet\")\n\namount &lt;- c(50, 62, 25, 55, 70, 25)\n\ndue_date &lt;- c(\"2/1/2024\", \"2/4/2024\", \"2/5/2024\", \n              \"3/1/2024\", \"3/5/2024\", \"3/6/2024\")\n\ntable1 &lt;- data.frame(month, bill_type, amount, due_date) |&gt; \n  mutate(due_date = lubridate::mdy(due_date))\n\ntable1\n\n\n  month bill_type amount   due_date\n1   Feb       Gas     50 2024-02-01\n2   Feb     Water     62 2024-02-04\n3   Feb  Internet     25 2024-02-05\n4   Mar       Gas     55 2024-03-01\n5   Mar     Water     70 2024-03-05\n6   Mar  Internet     25 2024-03-06\n\n\nCode\ntable2.1&lt;- table1 |&gt; \n  summarise(.by = month,\n            total = sum(amount),\n            third = total/3) \n\nnotify &lt;- c(\"3/1/2024\", \"4/1/2024\")\n\ntable2.2 &lt;- data.frame(notify) |&gt; \n  mutate(notify = lubridate::mdy(notify))\n\ntable2 &lt;- cbind(table2.1, table2.2)\ntable2\n\n\n  month total    third     notify\n1   Feb   137 45.66667 2024-03-01\n2   Mar   150 50.00000 2024-04-01\n\n\n\n\nCreating the Message\nBecause my real data has all of the month’s data in it, we need to filter to get the right amounts to send in our text. We can use Sys.Date to get the current date, and lubridate::month to make the date a numeric value representing the month.\nThen we can do the same for our tables to filter by. Remember I will have this script executing at the first of every month to report what the costs were for the previous month.\n\n\nCode\n# current_month &lt;- lubridate::month(Sys.Date())\ncurrent_month &lt;- 4 # for our example\n\nfiltered_sum &lt;- table2 |&gt; \n  mutate(notify = lubridate::month(notify)) |&gt; \n  filter(notify == current_month)\n\nmonthly_total &lt;- filtered_sum$total\n\nthird &lt;- filtered_sum$third\n\nbreakdown &lt;- table1 |&gt; \n  mutate(month_num = lubridate::month(due_date)) \n\nbreakdown_amounts &lt;- breakdown |&gt; \n  filter(month_num == (current_month - 1)) |&gt; \n  select(bill_type, amount)\n\n\nNow that we have the amounts we need, we can construct a message.\n\n\nCode\n message &lt;- paste(\"The total of our utility bill for the month of\", \n                  filtered_sum$month, \"is:\", monthly_total, \n                  \"\\nA third of this total is:\", round(third, 2), \n                   \"\\n\\nHere is a breakdown of the bill:\",\n                   paste0(\"\\n\", breakdown_amounts[1,1], \": \",\n                     breakdown_amounts[1,2], \"\\n\",\n                     breakdown_amounts[2,1], \": \",\n                     breakdown_amounts[2,2], \"\\n\",\n                     breakdown_amounts[3,1], \": \",\n                     breakdown_amounts[3,2]\n                   )\n )\n\ncat(message)\n\n\nThe total of our utility bill for the month of Mar is: 150 \nA third of this total is: 50 \n\nHere is a breakdown of the bill: \nGas: 55\nWater: 70\nInternet: 25\n\n\n\n\nSending the Message\nNext, we text.\nThe method I am using is only for iMessage devices, and is really only possible from a Mac. This method is taken from a very helpful Stackoverflow post. There is probably a workaround for other devices and sending through SMS, but that is not the focus of this post.\nWe can send our text with an Apple Script. Here is a function to do just that. This is slightly adapted from the Stackoverflow answer and allows for separate texts to multiple recipients.\n\n\nCode\nsend_text &lt;- function(message, buddy){\n  \n  for(i in buddy){\n    system(paste('osascript -e \\'tell application \"Messages\"\\' -e \\'send \"', message, '\" to buddy', i,  'of (service 1 whose service type is iMessage)\\' -e \\'end tell\\''))\n  }\n  \n}\n\n\nThen we can simply plug in the rest. But be warned: running this command will send a text! Be careful when testing this out.\n\n\nCode\nbuddies &lt;- c(\"\\\"phonenumber1\\\"\", \"\\\"phonenumber2\\\"\")\n\nsend_text(message, buddies)"
  },
  {
    "objectID": "blog/Text in R/index.html#the-cron-job",
    "href": "blog/Text in R/index.html#the-cron-job",
    "title": "I Made R Text For Me",
    "section": "The Cron Job",
    "text": "The Cron Job\nNow that the hard part is over, we can simply create a cron job to run this script directly from the command line on the first of every month.\nImportant: make sure the following is at the top of your saved R script:\n\n\nCode\n#!/usr/local/bin/Rscript\n\n\nTo open your cron tab, in the terminal type the following command:\n\n\nCode\nexport VISUAL=nano; crontab -e\n\n\nAs an added tip, you can save this command as an alias in your .zshrc file to make it easier to quickly access.\nOnce the cron tab is open, you have to set up the job and specify how often you want it to run. The following runs on the first of every month at 9 AM. The command navigates to my home directory, and then executes my R script which I have named “utes_notif.R”.\n\n\nCode\n0 9 1 * * cd ~; ./Desktop/R/utility_notification/utes_notif.R"
  },
  {
    "objectID": "blog/Text in R/index.html#other-considerations",
    "href": "blog/Text in R/index.html#other-considerations",
    "title": "I Made R Text For Me",
    "section": "Other Considerations",
    "text": "Other Considerations\nLastly, I want to note a small consideration when setting up an automated process like this. The cron job will run in this form only if the computer is awake during the scheduled time.\nTo work around this, you can utilize the battery options in your Mac’s system preferences. I have scheduled my computer to wake up every day at 9 AM for about five minutes. This was the easiest work around for me. However, I am certain there are other options to achieve the same goal. One option may be to use alternative scheduling tools like cronwake or anacron."
  },
  {
    "objectID": "blog/Introducing the PLACES Package/index.html",
    "href": "blog/Introducing the PLACES Package/index.html",
    "title": "Introducing the CDCPLACES Package",
    "section": "",
    "text": "This post was updated on March 19, 2024 to reflect updates introduced in CDCPLACES 1.1.5."
  },
  {
    "objectID": "blog/Introducing the PLACES Package/index.html#introduction",
    "href": "blog/Introducing the PLACES Package/index.html#introduction",
    "title": "Introducing the CDCPLACES Package",
    "section": "Introduction",
    "text": "Introduction\nTo begin, we can install from CRAN, or from github, then load our packages.\n\n\nCode\n# Install from CRAN\n# install.packages(\"CDCPLACES)\n\n# Install from Github\n# devtools::install_github(\"brendensm/CDCPLACES\")\n\nlibrary(CDCPLACES)\nlibrary(dplyr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "blog/Introducing the PLACES Package/index.html#function-get_dictionary",
    "href": "blog/Introducing the PLACES Package/index.html#function-get_dictionary",
    "title": "Introducing the CDCPLACES Package",
    "section": "Function: get_dictionary",
    "text": "Function: get_dictionary\nOur first functions allows us to easily view what measures we can query, via ‘measureid’, along with a brief definition of each function. If we run get_dictionary, a data frame is returned. We can view the measures in a data frame in the R Studio with View(). This is the preferred method for exploring the available measures.\nFor our example here, I will print the names of the variables in this dataframe.\n\n\nCode\n# To open a viewer\n# get_dictionary() %&gt;% View()\n\nget_dictionary() %&gt;% names()\n\n\n [1] \"measureid\"                \"measure_full_name\"       \n [3] \"measure_short_name\"       \"categoryid\"              \n [5] \"category_name\"            \"places_release_2023\"     \n [7] \"places_release_2022\"      \"places_release_2021\"     \n [9] \"places_release_2020\"      \"_500_cities_release_2019\"\n[11] \"_500_cities_release_2018\" \"_500_cities_release_2017\"\n[13] \"_500_cities_release_2016\" \"frequency_brfss_year\"    \n\n\nThis data frame is useful for several reasons. It lists the available measures for each year of the CDC PLACES data, along with the data each variable was collected, all in a single place. Remember to use the measureid when querying your data."
  },
  {
    "objectID": "blog/Introducing the PLACES Package/index.html#function-get_places",
    "href": "blog/Introducing the PLACES Package/index.html#function-get_places",
    "title": "Introducing the CDCPLACES Package",
    "section": "Function: get_places",
    "text": "Function: get_places\nThis function allows us to easily query data that we specify. In the example below, I will get the measure ACCESS2 (the current lack of health insurance among adults aged 18-64 years) for the state of Arizona. This function allows for multiple of these arguments.\n\n\nCode\naz_access &lt;- get_places(state = \"AZ\", \n                        measure = \"ACCESS2\") \nhead(az_access)\n\n\n# A tibble: 6 × 21\n  year  stateabbr statedesc locationname datasource category   measure          \n  &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;            \n1 2021  AZ        Arizona   Yuma         BRFSS      Prevention Current lack of …\n2 2021  AZ        Arizona   Graham       BRFSS      Prevention Current lack of …\n3 2021  AZ        Arizona   Apache       BRFSS      Prevention Current lack of …\n4 2021  AZ        Arizona   La Paz       BRFSS      Prevention Current lack of …\n5 2021  AZ        Arizona   Coconino     BRFSS      Prevention Current lack of …\n6 2021  AZ        Arizona   Cochise      BRFSS      Prevention Current lack of …\n# ℹ 14 more variables: data_value_unit &lt;chr&gt;, data_value_type &lt;chr&gt;,\n#   data_value &lt;dbl&gt;, low_confidence_limit &lt;dbl&gt;, high_confidence_limit &lt;dbl&gt;,\n#   totalpopulation &lt;chr&gt;, locationid &lt;chr&gt;, categoryid &lt;chr&gt;, measureid &lt;chr&gt;,\n#   datavaluetypeid &lt;chr&gt;, short_question_text &lt;chr&gt;, type &lt;chr&gt;, lon &lt;dbl&gt;,\n#   lat &lt;dbl&gt;\n\n\nIt is also worth noting that by default geography specifying geography is set to “county”. If instead we want to examine census tracts, we could specify the argument. Likewise, release is set to “2023” by default.\nThe argument county can be used to filter results to specific counties. This is extremely useful for examining census level data for specific areas of states. Additionally, geometry can be added to include a shapefile in the query. For further examples of plotting with shapefiles, see this dedicated blog post.\n\n\nCode\ncap_counties &lt;- get_places(geography = \"census\",\n                           state = \"MI\",\n                           measure = \"ACCESS2\",\n                           county = c(\"Ingham\", \"Eaton\", \"Clinton\"),\n                           geometry = TRUE)"
  },
  {
    "objectID": "blog/Introducing the PLACES Package/index.html#use-case",
    "href": "blog/Introducing the PLACES Package/index.html#use-case",
    "title": "Introducing the CDCPLACES Package",
    "section": "Use Case",
    "text": "Use Case\nFrom here, we can start to have fun. It is fairly straight forward to begin exploring data. Here I will first filter out the data so that I can plot the age adjusted rates of lack of health insurance in Arizona.\nNotice that the data provide you with confidence limits, so I have chosen to plot them here with error bars.\n\n\nCode\naz_access %&gt;%\n  filter(datavaluetypeid == \"AgeAdjPrv\") %&gt;%\n  ggplot(aes(data_value, reorder(locationname, data_value))) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(xmin = low_confidence_limit, xmax = high_confidence_limit)) +\n  labs(title = \"Lack of health insurance among adults aged 18-64 years In Arizona Counties\",\n       y = \"\", x = \"Percent\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\nYou can also extend this to multiple states to compare. You can easily query two (or more) state names, and plot them. Arizona seems to have a couple of counties that have a much higher rate compared to others.\n\n\nCode\n# multi state comparison\ntwo &lt;- get_places(state = c(\"AZ\", \"NV\"), \n                  measure = \"ACCESS2\")\n\ntwo %&gt;%\n  filter(datavaluetypeid == \"AgeAdjPrv\") %&gt;%\n  ggplot(aes(data_value, reorder(locationname, data_value), color = stateabbr)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(xmin = low_confidence_limit, xmax = high_confidence_limit)) +\n  labs(title = \n         \"Lack of health insurance among adults aged 18-64 years In Arizona and Nevada\",\n       y = \"Counties\", x = \"Percent\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\nWe can go even further by comparing more states in the region. Here I have taken the average rate by state to easily compare. Texas appears to be far above the average.\n\n\nCode\nmulti &lt;- get_places(state = c(\"AZ\", \"NV\", \"NM\", \"TX\", \"CA\"), measure = \"ACCESS2\") %&gt;%\n  filter(datavaluetypeid == \"AgeAdjPrv\") %&gt;%\n  summarise(.by = \"stateabbr\", mean_val = mean(data_value), mean_low = mean(low_confidence_limit), mean_high = mean(high_confidence_limit))\n\nmulti %&gt;%\n  ggplot(aes(mean_val, reorder(stateabbr, mean_val), color = stateabbr)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(xmin = mean_low, xmax = mean_high)) +\n  labs(title = \"Mean lack of health insurance among adults aged 18-64 years In Southwest States\",\n       y = \"\", x = \"Percent\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "blog/Bluets/index.html",
    "href": "blog/Bluets/index.html",
    "title": "Twitter Bots",
    "section": "",
    "text": "Update: Since a certain someone took over the bird app, this bot is no longer functional. Unfortunately, it is not worth paying $100/month to post random shades of blue. What an injustice."
  },
  {
    "objectID": "blog/Bluets/index.html#introduction",
    "href": "blog/Bluets/index.html#introduction",
    "title": "Twitter Bots",
    "section": "Introduction",
    "text": "Introduction\nBlue is a color that moves me. I love how many forms it can take, the way its shades can channel moods. I recently reread my copy of Maggie Nelson’s Bluets and felt inspired to revisit an older project of mine. Possibly the first R project I put together (that was more fun, and not statistics or graphic related) was my twitter bot, everywordisblue.\nThis was a year or so back when I was just starting to dust off R and commit to learning the language fully. The original account was influenced by many of the silly bots on the website and my personal passion for the color blue. It took a randomly selected noun, pasted the word 'blue' in front of it, and posted it straight to Twitter once a day. While this creation gave me some immediate satisfaction (and some interesting results), I did feel that the account was a bit too simplistic; I always wanted to do more.\nInfinitely more satisfying would be a randomly selected hue of blue, shared daily, completely automated. To do this required editing my original script and, most importantly, web-scraping a data set of blue colors with accompanying hex codes. Follow along and let’s build something fun!"
  },
  {
    "objectID": "blog/Bluets/index.html#the-data",
    "href": "blog/Bluets/index.html#the-data",
    "title": "Twitter Bots",
    "section": "The Data",
    "text": "The Data\nOriginally, I attempted to find an existing data set. Most colors sets I’m familiar with using in R, however, are not as hyper-fixated on a singular color. I quickly found color-names.com, and noticed when you simply search for the word 'blue', the search provides over 89 pages (12 colors on each page), giving over a thousand colors with hex codes. This seemed like an adequate source for this project and a great way to practice web scraping data from R.\n\nUsing ‘rvest’\nTo help us source our data, the library 'rvest' provides everything we need. In order to create a data frame containing the color name and the hex code, we need to:\n\nimport the web search’s html\npull out the two elements from the code (name, hex code)\nthen repeat this process for each of the 89 pages\n\nThe function 'read_html' from rvest makes the first step incredibly easily. For this, we simply pass in the web address as an argument in the function and save the output as a new value called 'page'.\n\n\nCode\nlibrary(rvest)\nlink &lt;- \"https://www.color-name.com/search/blue\"\npage &lt;- read_html(link)\n\n\nNext, we’ll pass 'page' into the function 'html_nodes' and then into 'html_text' to extract the desired string vector. The text passed through 'html_nodes' must be sourced from the webpage you are scraping from. You can use the ‘inspect’ feature in Google Chrome, or the Chrome extension ‘SelectorGadget’ to find the proper tag to use.\n\n\nCode\nname &lt;- page |&gt; html_nodes(\"h2 a\") |&gt; html_text()\nhex &lt;- page |&gt; html_nodes(\".hx\") |&gt; html_text()\n\n\nOnce that is done, we can take both vectors and create a data frame.\n\n\nCode\ncolors &lt;- data.frame(name, hex, stringsAsFactors = FALSE)\n\n\nIn order to collect each page of data, it is easiest to use a for loop. For this we make a couple of changes. First, we will create an empty data frame titled 'colors' to store data in for each iteration of the loop. Because there are 89 pages, we set the for loop to iterate that many times. We store this as 'page_result' in the loop and change the url to match what is displayed on each page number then use 'paste0' to put them together. Lastly, I added 'rbind' to add the new rows to the 'colors' data frame and a print command to keep track of the loop progress.\n\n\nCode\ncolors &lt;- data.frame()\n\nfor (page_result in 1:89){\n  \n  link &lt;- paste0(\"https://www.color-name.com/search/blue/page/\", page_result)\n  \n  page &lt;- read_html(link)\n  \n  name &lt;- page |&gt; html_nodes(\"h2 a\") |&gt; html_text()\n  hex &lt;- page |&gt; html_nodes(\".hx\") |&gt; html_text()\n  \n  colors &lt;- rbind(colors, data.frame(name, hex, stringsAsFactors = FALSE))\n  \n  print(paste(\"Page:\", page_result))\n}\n\n\nAnd as a last step, I decided to clean up the colors a bit. Even though the search used the key word 'blue', I noticed that the last page displayed colors that did not have the word 'blue' in the title. To fix this, I filtered out any color that did not contain the word.\n\n\nCode\nlibrary(dplyr)\nblues &lt;- colors |&gt; filter(grepl('Blue', name))"
  },
  {
    "objectID": "blog/Bluets/index.html#the-script",
    "href": "blog/Bluets/index.html#the-script",
    "title": "Twitter Bots",
    "section": "The Script",
    "text": "The Script\nNow that we have the data, we need to make a script that randomly selects a color, creates a color square, saves it as an image, and posts a tweet. For all of this, we will load 'rtweet' and 'ggplot2'.\n\n\nCode\nlibrary(rtweet)\nlibrary(ggplot2)\n\n\nAfter importing, we need to create the token to interact with Twitter’s API. You can find a deeper dive into this process here. In my example below, I have stored my information as secrets in my Github repository.\n\n\nCode\nblues &lt;- read.csv(\"blues_dataset.csv\")[,-1] # import data \n\neverywordisblue_token &lt;- # Twitter token business\n  rtweet::rtweet_bot(\n   api_key =   Sys.getenv(\"TWITTER_CONSUMER_API_KEY\"),\n    api_secret = Sys.getenv(\"TWITTER_CONSUMER_API_SECRET\"),\n    access_token =    Sys.getenv(\"TWITTER_ACCESS_TOKEN\"),\n    access_secret =  Sys.getenv(\"TWITTER_ACCESS_TOKEN_SECRET\")\n  )\n\n\nNext we can select a single row in our main data frame by calling 'sample_n'. Then to separate the name and the hex code we can save each as an object and index using brackets.\n\n\nCode\nrandom_blue &lt;- sample_n(blues, 1)\n\ntemp &lt;- as.character(random_blue[1])\n\nblue_hex &lt;- as.character(random_blue[2])\n\n\nTo create a square with the randomly selected color, we can create an empty ggplot, add 'theme_void' to make it blank, and use theme to use the selected hex code. For this we use arguments 'plot.background' and 'panel.background'. Then we can use 'ggsave' to save a copy of this as an image and specify the desired path.\n\n\nCode\nblue_square &lt;- ggplot() + theme_void() +\n              theme(plot.background = element_rect(fill = blue_hex),\n              panel.background = element_rect(fill = blue_hex))\n\nggsave(paste0(\"blue_squares/\", temp, \".png\"), blue_square,\n       width = 150, height = 150, units = \"px\")\n\n\nNow that all the pieces are in place, we can assemble the tweet and sent it out! The function 'post_tweet' now requires that the user provides alt text (awesome!) so we will first save that (this will be the same for each tweet sent). We will also save an image path that changes each time the script is run using 'paste0' once again.\nTo send the actual tweet, we pull in each object to the 'post_tweet' and we are done!\n\n\nCode\nalt_text &lt;- \"A random shade of blue, sourced from color-name.com.\"\n\nimage_path &lt;- paste0(\"blue_squares/\", temp, \".png\")\n\nrtweet::post_tweet(status = temp, \n                   media = image_path, \n                   media_alt_text = alt_text,\n                   token = everywordisblue_token)"
  },
  {
    "objectID": "blog/Bluets/index.html#automation-with-github-actions",
    "href": "blog/Bluets/index.html#automation-with-github-actions",
    "title": "Twitter Bots",
    "section": "Automation with Github Actions",
    "text": "Automation with Github Actions\nGithub makes it surprisingly easy to automate scripts with Github Actions! Again for the full length guide on this process I will direct you to Matt Dray’s blog post which taught me how to properly set this bot up.\nEssentially, all that is needed in a yml file that lists the correct instructions on when and what to run. My example yml is below:\n\n\nCode\nname: blue-version-2\n\non:\n  schedule:\n    - cron: '0 0 * * *'  # once every day\n\njobs:\n  blue-post:\n    runs-on: macOS-latest\n    env:\n      TWITTER_CONSUMER_API_KEY: ${{ secrets.TWITTER_CONSUMER_API_KEY }}\n      TWITTER_CONSUMER_API_SECRET: ${{ secrets.TWITTER_CONSUMER_API_SECRET }}\n      TWITTER_ACCESS_TOKEN: ${{ secrets.TWITTER_ACCESS_TOKEN }}\n      TWITTER_ACCESS_TOKEN_SECRET: ${{ secrets.TWITTER_ACCESS_TOKEN_SECRET }}\n    steps:\n      - uses: actions/checkout@v2\n      - uses: r-lib/actions/setup-r@v2\n      - name: Install rtweet package\n        run: Rscript -e 'install.packages(\"rtweet\", dependencies = TRUE)'\n      - name: Install dplyr\n        run: Rscript -e 'install.packages(\"dplyr\", dependencies = TRUE)'\n      - name: Install ggplot2\n        run: Rscript -e 'install.packages(\"ggplot2\", dependencies = TRUE)'\n      - name: Create and post tweet\n        run: Rscript blue-script.R\n\n\nAnd that’s it! If you want to check out the live twitter bot you can follow it here."
  },
  {
    "objectID": "blog/Intro to Bash Scripting/index.html",
    "href": "blog/Intro to Bash Scripting/index.html",
    "title": "Intro to Bash Scripting",
    "section": "",
    "text": "And I thought R gave me super powers…"
  },
  {
    "objectID": "blog/Intro to Bash Scripting/index.html#introduction",
    "href": "blog/Intro to Bash Scripting/index.html#introduction",
    "title": "Intro to Bash Scripting",
    "section": "Introduction",
    "text": "Introduction\nRecently, I’ve been having fun with Linux. I really didn’t know much about Linux or how it was different from MacOS or Windows. All I really knew was that very smart people use it and many computers depend on it!\nBy recommendation of a friend, I tried loading Pop!_OS on an old Macbook Air I had laying around. I quickly learned how lightweight many distributions of Linux are, and how customizable they can be.\nFor anyone familiar with Linux you know that, even when you are just setting up a computer with the OS, you have to start using a bit of the command line. I had used this before learning some helpful functions with git, but nothing has exposed me to the command line and Bash more than this endeavor.\nI have been inspired by this exposure and want to start learning more about the functionality of Bash. As a part of this, I wanted to try creating a Bash script of my own that I could implement into my current workflows."
  },
  {
    "objectID": "blog/Intro to Bash Scripting/index.html#the-idea",
    "href": "blog/Intro to Bash Scripting/index.html#the-idea",
    "title": "Intro to Bash Scripting",
    "section": "The Idea",
    "text": "The Idea\nI work primarily in R. And I love a good R Project. One of my usual habits for creating a project include adding sub folders and a starting script. I realized Bash is really good for doing this! So with some basic commands, I wanted to create a single executable script that makes a new R project, default sub folders, and a starting script."
  },
  {
    "objectID": "blog/Intro to Bash Scripting/index.html#writing-the-script",
    "href": "blog/Intro to Bash Scripting/index.html#writing-the-script",
    "title": "Intro to Bash Scripting",
    "section": "Writing the Script",
    "text": "Writing the Script\nFor the script I wanted several tasks accomplished:\n\nCreated an R project file within a contained folder\nSeveral sub-directories within that folder (data-raw, data, ref, output)\nA blank R script file\n\nTo start, I had the script ask for the name of the project. This was done by using echo to print the prompt, then read takes in the name of the project.\n\n\nCode\n#!/bin/bash\n\necho \"Please enter your project title: \"\n\nread name\n\n\nNext, I had to make the script navigate to the folder I want my projects in (for me, this is a folder on my desktop called ‘R’). Then, I had a directory made with sub-folders using mkdir -p. Here we use $name to use the variable stored as the name of the project. Within the {} are the names of the sub-folder I most commonly use. This could be anything you like though! Lastly, touch creates the blank R script.\n\n\nCode\ncd Desktop/R\n\nmkdir -p $name/{data-raw,data,ref,output}\n\ncd $name\n\ntouch script.R\n\n\nNext, we have an extra step that allows RStudio to open our new project properly. When I first tried this script out, I created a blank file with the .Rproj extension to set up the project. This immediately gave me problems when I tried to open the project. Specifically, I recall an issue with the version being unspecified.\nAfter a bit a research, I discovered that files with .Rproj are nothing really but a .txt file. I opened one of my existing R projects with a text editor and copied the contents exactly into the code chunk below. I wrote this text into the new R project. After some trial and error, I can confirm this method works!\n\n\nCode\n\necho -e 'Version: 1.0\n\nRestoreWorkspace: Default\nSaveWorkspace: Default\nAlwaysSaveHistory: Default\n\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 2\nEncoding: UTF-8\n\nRnwWeave: Sweave\nLaTex: pdfLaTeX' &gt;&gt; $name.Rproj\n\n\nThe last few lines of code echo some responses to the terminal and launch the new R project.\n\n\nCode\necho \"Project $name has been created.\"\necho \"It is stored in the R directory.\"\necho \"Opening project now...\"\n\nopen $name.Rproj"
  },
  {
    "objectID": "blog/Intro to Bash Scripting/index.html#making-it-accessible",
    "href": "blog/Intro to Bash Scripting/index.html#making-it-accessible",
    "title": "Intro to Bash Scripting",
    "section": "Making it Accessible",
    "text": "Making it Accessible\nFor me, personally, I like to be able to execute my scripts without worrying where I am in the terminal. Once my script was working properly, I moved it to the /usr/local/bin folder.\n\n\nCode\nmv setupr /usr/local/bin\n\n\nAnd that’s it! You can find the full script code below. I hope this is helpful! It was certainly useful to me to learn more about bash and make a useful script to help me set up projects."
  },
  {
    "objectID": "blog/Intro to Bash Scripting/index.html#full-script-code",
    "href": "blog/Intro to Bash Scripting/index.html#full-script-code",
    "title": "Intro to Bash Scripting",
    "section": "Full Script Code",
    "text": "Full Script Code\n\n\nCode\n#!/bin/bash\n\necho \"Please enter your project title: \"\n\nread name\n\ncd Desktop/R\n\nmkdir -p $name/{data-raw,data,ref,output}\n\ncd $name\n\ntouch script.R\n\necho -e 'Version: 1.0\n\nRestoreWorkspace: Default\nSaveWorkspace: Default\nAlwaysSaveHistory: Default\n\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 2\nEncoding: UTF-8\n\nRnwWeave: Sweave\nLaTex: pdfLaTeX' &gt;&gt; $name.Rproj\n\necho \"Project $name has been created.\"\necho \"It is stored in the R directory.\"\necho \"Opening project now...\"\n\nopen $name.Rproj"
  },
  {
    "objectID": "blog/Survival Analysis/index.html",
    "href": "blog/Survival Analysis/index.html",
    "title": "Survival Analysis in R",
    "section": "",
    "text": "At first I was afraid, I was petrified…"
  },
  {
    "objectID": "blog/Survival Analysis/index.html#introduction",
    "href": "blog/Survival Analysis/index.html#introduction",
    "title": "Survival Analysis in R",
    "section": "Introduction",
    "text": "Introduction\nIn this blog post, I’ll be exploring some basic survival analysis in R. Survival analysis focuses on describing the occurrence of an event (in this example death) in a set time frame. Survival analysis is often used in clinical research and cancer epidemiology. For more reading, I recommend visiting The Epidemiologist R Handbook page on survival analysis, as well as their listed resources. The following blog post was adapted from my biostatistics coursework and features data used in that course. We will create Kaplan-Meier plots and go through Cox Hazard Regression."
  },
  {
    "objectID": "blog/Survival Analysis/index.html#packages-and-data",
    "href": "blog/Survival Analysis/index.html#packages-and-data",
    "title": "Survival Analysis in R",
    "section": "Packages and Data",
    "text": "Packages and Data\nFor this blog post, I will use the packages have, dplyr, survival.\n\n\nCode\n# Load in libraries\nlibrary(dplyr)\nlibrary(readr)\nlibrary(survival)\nlibrary(sjPlot)\n\n\nNext, we will load the data.\n\n\nCode\nsd &lt;- read_csv(\"data/HM 878 730 Clements - Survival Analysis R Data.csv\") %&gt;% \n  mutate(\n    #death = factor(death, levels = c(0, 1),\n                 #  labels = c(\"Living\", \"Died\")),\n    cursmoke = factor(cursmoke, levels = c(0, 1), \n                      labels = c(\"Not current smoker\", \"Current smoker\")),\n    diabetes = factor(diabetes, levels = c(0, 1),\n                      labels = c(\"Not diabetic\", \"Diabetic\")),\n    educ = factor(educ, levels = c(1, 2, 3, 4),\n                  labels = c(\"0-11 years\", \"HS Diploma/GED\", \n                             \"Some College/Vocational School\",\n                             \"College degree or more\")),\n    prevchd = factor(prevchd, levels = c(0, 1),\n                    labels = c(\"No\", \"Yes\")),\n    sex = factor(sex, levels = c(0, 1),\n                 labels = c(\"Female\", \"Male\"))\n  )"
  },
  {
    "objectID": "blog/Survival Analysis/index.html#cox-regression",
    "href": "blog/Survival Analysis/index.html#cox-regression",
    "title": "Survival Analysis in R",
    "section": "Cox Regression",
    "text": "Cox Regression\n\nHazard Ratios\n\n\nCode\ncm &lt;- coxph(Surv(TimeDeathYears, death) ~ cursmoke + diabetes +\n              educ + prevchd + age + bmi + sex, data = sd)\n\nsummary(cm)\n\n\nCall:\ncoxph(formula = Surv(TimeDeathYears, death) ~ cursmoke + diabetes + \n    educ + prevchd + age + bmi + sex, data = sd)\n\n  n= 3165, number of events= 746 \n   (98 observations deleted due to missingness)\n\n                                        coef exp(coef)  se(coef)      z\ncursmokeCurrent smoker              0.432597  1.541256  0.081165  5.330\ndiabetesDiabetic                    0.741622  2.099338  0.100251  7.398\neducHS Diploma/GED                 -0.007861  0.992169  0.092149 -0.085\neducSome College/Vocational School -0.158231  0.853652  0.111205 -1.423\neducCollege degree or more         -0.454487  0.634773  0.131159 -3.465\nprevchdYes                          0.790013  2.203425  0.086862  9.095\nage                                 0.092917  1.097370  0.005068 18.333\nbmi                                -0.012792  0.987290  0.009667 -1.323\nsexMale                             0.672732  1.959583  0.075393  8.923\n                                   Pr(&gt;|z|)    \ncursmokeCurrent smoker             9.83e-08 ***\ndiabetesDiabetic                   1.39e-13 ***\neducHS Diploma/GED                  0.93201    \neducSome College/Vocational School  0.15477    \neducCollege degree or more          0.00053 ***\nprevchdYes                          &lt; 2e-16 ***\nage                                 &lt; 2e-16 ***\nbmi                                 0.18575    \nsexMale                             &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                                   exp(coef) exp(-coef) lower .95 upper .95\ncursmokeCurrent smoker                1.5413     0.6488    1.3146    1.8070\ndiabetesDiabetic                      2.0993     0.4763    1.7248    2.5551\neducHS Diploma/GED                    0.9922     1.0079    0.8282    1.1886\neducSome College/Vocational School    0.8537     1.1714    0.6865    1.0615\neducCollege degree or more            0.6348     1.5754    0.4909    0.8208\nprevchdYes                            2.2034     0.4538    1.8585    2.6124\nage                                   1.0974     0.9113    1.0865    1.1083\nbmi                                   0.9873     1.0129    0.9688    1.0062\nsexMale                               1.9596     0.5103    1.6904    2.2716\n\nConcordance= 0.761  (se = 0.009 )\nLikelihood ratio test= 688.4  on 9 df,   p=&lt;2e-16\nWald test            = 686.8  on 9 df,   p=&lt;2e-16\nScore (logrank) test = 783.3  on 9 df,   p=&lt;2e-16\n\n\nCode\nsjPlot::tab_model(cm)\n\n\n\n\n\n\n\n\n\n\n\n \nSurv(Time Death\nYears,death)\n\n\nPredictors\nEstimates\nCI\np\n\n\ncursmoke [Current smoker]\n1.54\n1.31 – 1.81\n&lt;0.001\n\n\ndiabetes [Diabetic]\n2.10\n1.72 – 2.56\n&lt;0.001\n\n\neduc [HS Diploma/GED]\n0.99\n0.83 – 1.19\n0.932\n\n\neduc [Some\nCollege/Vocational\nSchool]\n0.85\n0.69 – 1.06\n0.155\n\n\neduc [College degree or\nmore]\n0.63\n0.49 – 0.82\n0.001\n\n\nprevchd [Yes]\n2.20\n1.86 – 2.61\n&lt;0.001\n\n\nage\n1.10\n1.09 – 1.11\n&lt;0.001\n\n\nbmi\n0.99\n0.97 – 1.01\n0.186\n\n\nsex [Male]\n1.96\n1.69 – 2.27\n&lt;0.001\n\n\nObservations\n3165\n\n\nR2 Nagelkerke\n0.200\n\n\n\n\n\n\n\n\n\nSurvival Curves\n\n\nCode\nsurv_fit_diab &lt;-  survfit(Surv(TimeDeathYears, death) ~ diabetes, data = sd)\n\ncol_diab &lt;- c(\"lightgreen\", \"darkgreen\")\n\nplot(\n  surv_fit_diab,\n  col = col_diab,\n  xlab = \"Years\",\n  ylab = \"Survival Probability\")\nlegend(\n  \"bottomright\",\n  legend = c(\"Not diabetic\",\"Diabetic\"),\n  col = col_diab,\n  lty = 1,\n  cex = .9,\n  bty = \"n\")\n\n\n\n\n\n\n\nInterpretation\nHazard ratios for the cox regression show that smoker status, diabetic status, prevalent coronary heart disease, age, sex, and the highest level of education all have significant p-values. This means that each were found to impact the outcome of death in our survival analysis.\nSmoker status has a hazard ratio of 1.54 meaning that, compared to non-smokers, current smokers have 1.54 times the risk of death.\nDiabetic status has a hazard ratio of 2.10. This means that those with diabetes, compared to those that were not diabetic, had 2.1 times greater risk of death.\nEducation at the level of college degree or more had a hazard ratio of 0.63. Compared to those with 0-11 years of education, this group had 37% decreased risk of death.\nPrevalence of coronary heart disease has a hazard ratio of 2.20, meaning that compared to those without CHD, they had 120% increased risk of death.\nAge also has a significant p-value, and a hazard ratio of 1.10. This means for every increase unit in age, there is 10% greater risk of death.\nLastly, sex had a hazard ratio of 1.96. This means that compared to females, males had 95% greater risk of death.\nThe survival curve shows the difference in survival probability between diabetics and non-diabetics. The differences are quite noticeably, with a lower survival probability among diabetics. This is in line with the results of the cox regression. For example, at 10 years, the survival probability among non-diabetics is about 85%, while the probability among diabetics is 65%."
  },
  {
    "objectID": "blog/Survival Analysis/index.html#kaplan-meier",
    "href": "blog/Survival Analysis/index.html#kaplan-meier",
    "title": "Survival Analysis in R",
    "section": "Kaplan-Meier",
    "text": "Kaplan-Meier\nConduct Kaplan-Meier for each categorical IV. Interpret the summary, mean and median survival time, Log Rank Mantel-Cox Test, survival probability at 10 years. Compare and contrast between each variable.\n\nFunction for Analysis\nBecause I have to compare quite a few variables, I make a quick function to output exactly what I need.\n\n\nCode\nkm &lt;- function(time, event, data, iv, title_label){\n  \nmodel &lt;-  survfit(Surv(time, event) ~ iv, data = sd)\n\ncols &lt;- RColorBrewer::brewer.pal(4, \"Set1\")\n\nplot_title &lt;- paste(\"Survival Curve by\", title_label)\n\nplot(\n  model,\n  col = cols,\n  lwd = 2,\n  main = plot_title,\n  xlab = \"Years\",\n  ylab = \"Survival Probability\")\nlegend(\n  \"bottomleft\",\n  legend = levels(iv),\n  col = cols,\n  lty = 1,\n  cex = .9,\n  bty = \"n\")\nabline(h = seq(0,1,.2), lty = \"dashed\", col = \"gray75\")\nabline(lty = \"dashed\", col = \"black\", v = 10)\n  \n  \ncat(\"Model summary with mean and median: \\n\")\nprint(model, print.rmean = TRUE)\n\nlogrank &lt;- survdiff(Surv(time, event) ~ iv, data = data)\nprint(logrank)\n  \n}\n\n\n\n\nDiabetes\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$diabetes, \"Diabetes\")\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n                   n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=Not diabetic 3009    646   13.7    0.0525     NA      NA      NA\niv=Diabetic      254    129   11.8    0.2540     14      13      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n                   N Observed Expected (O-E)^2/E (O-E)^2/V\niv=Not diabetic 3009      646    724.5       8.5       133\niv=Diabetic      254      129     50.5     121.8       133\n\n Chisq= 133  on 1 degrees of freedom, p= &lt;2e-16 \n\n\nAs interpreted before, the survival probability differs quite drastically between these two groups. At 10 years, the survival probability among non-diabetics is about 85%, while the probability among diabetics is 65%.\nThe model summary shows the total number in each group and the number of events (deaths) in each group.\nThe mean survival time is 13.7 years for non-diabetics, compared to 11.8 for diabetics. The median survival time could not be computed for non-diabetics, and was 14 years for diabetics. The median was not computed for non-diabetics because over 50% were still alive by the end of the time period.\nThe Log Rank Mantel-Cox Test shows a resulting p-value of &lt;0.0001, meaning that the null hypothesis, that there is no difference in survival between groups, is rejected.\n\n\nSmoker Status\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$cursmoke, \"Smoker Status\")\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n                         n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=Not current smoker 2142    501   13.6    0.0649     NA      NA      NA\niv=Current smoker     1121    274   13.5    0.0922     NA      NA      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n                         N Observed Expected (O-E)^2/E (O-E)^2/V\niv=Not current smoker 2142      501      510     0.173     0.517\niv=Current smoker     1121      274      265     0.333     0.517\n\n Chisq= 0.5  on 1 degrees of freedom, p= 0.5 \n\n\nThe model results show that the mean survival time was 13.6 among non-smokers and 13.5 among current smokers. These are not very different from each other, and on par with the average survival time of non-diabetics. The median survival times were not able to be calculated for this variable.\nThe Log Rank test shows a p-value of 0.5 indicating we should accept the null hypothesis that there is no difference in survival between the two groups.\nAt 10 years, the survival probability is nearly the same between the two groups, a bit greater than 80%. Once again, similar to non-diabetic suvival probability at the same time.\n\n\nEducation Level\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$educ, \"Education\")\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n   82 observations deleted due to missingness \n                                     n events rmean* se(rmean) median 0.95LCL\niv=0-11 years                     1281    381   13.2    0.0936     NA      NA\niv=HS Diploma/GED                  967    194   13.8    0.0911     NA      NA\niv=Some College/Vocational School  542    108   13.9    0.1188     NA      NA\niv=College degree or more          391     71   14.0    0.1275     NA      NA\n                                  0.95UCL\niv=0-11 years                          NA\niv=HS Diploma/GED                      NA\niv=Some College/Vocational School      NA\niv=College degree or more              NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\nn=3181, 82 observations deleted due to missingness.\n\n                                     N Observed Expected (O-E)^2/E (O-E)^2/V\niv=0-11 years                     1281      381    291.6     27.40     45.74\niv=HS Diploma/GED                  967      194    234.0      6.84     10.14\niv=Some College/Vocational School  542      108    131.9      4.32      5.36\niv=College degree or more          391       71     96.5      6.74      7.91\n\n Chisq= 46.4  on 3 degrees of freedom, p= 5e-10 \n\n\nThis model summary compares each of the four education levels in our variable. The mean survival years for those 0-11 is 13.2, for HS/Diploma/GED it is 13.8, for Some College/Vocational School it is 13.9 and for College degree or more it is 14. These are close to the averages we saw among smokers/nonsmokers, and non-diabetics. However, diabetics have still had the lowest average at 11 years. Once again, the medians could not be calculated for this variable because of the high proportion of groups surviving by the end of the time period.\nThe Log Rank test shows a p-value of &lt;0.0001. This leads us to reject the null and accept the alternative hypothesis that there is a significant difference in survival time between these groups (somewhere).\nThe survival probability at 10 years is 80% for the group 0-11, and around 90% for the other three groups. This is in the range of most groups thus far, aside from diabetics.\n\n\nPrevalence of Coronary Heart Disease\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$prevchd, \"CHD Prevalence\")\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n          n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=No  2903    582   13.8    0.0522     NA      NA      NA\niv=Yes  360    193   11.7    0.2077     14      12      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n          N Observed Expected (O-E)^2/E (O-E)^2/V\niv=No  2903      582    704.1      21.2       237\niv=Yes  360      193     70.9     210.4       237\n\n Chisq= 237  on 1 degrees of freedom, p= &lt;2e-16 \n\n\nThose without coronary heart disease had an average survival time of 13.8 years, while those with CHD had an average of 11.7 years. The median was only calculated for those with CHD, which was at 14 years. These metrics align with results from many other groups. the average survival years for those without CHD is comparable to the same metrics examined among the three highest education levels, smokers and non-smokers, and non-diabetics. Diabetics and those with CHD have similar average survival time.\nThe Log Rank Test shows a p-value of less than 0.0001. This leads us to reject the null and accept the alternative hypothesis that there is a difference in survival times between the two groups.\nLooking at the survival curve, the survival probability of those with CHD at 10 years is about 65%. The survival probability of those without CHD is around 90%. This is a comparable split to diabetics/non-diabetics.\n\n\nSex\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$sex, \"Sex\")\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n             n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=Female 1876    345   13.9    0.0635     NA      NA      NA\niv=Male   1387    430   13.1    0.0894     NA      NA      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n             N Observed Expected (O-E)^2/E (O-E)^2/V\niv=Female 1876      345      458      28.0      70.1\niv=Male   1387      430      317      40.5      70.1\n\n Chisq= 70.1  on 1 degrees of freedom, p= &lt;2e-16 \n\n\nFor the Kaplan-Meier examining sex, the model results show that the average survival time among females was 13.9 compared to male’s 13.1. This is a similar split between the highest and lowest education levels. Overall, this seems to be a significant difference, but not as big of a difference as CHD or diabetes status. The medians for these groups could not be calculated.\nThe Log Rank Test shows a p-value of less than 0.0001, which again leads us to accept the alternative hypothesis that this model shows a significant difference in survival time between the two groups.\nOn the survival curve, it appears that at 10 years, males had 80% survival probability, and females had about 90%. This is a much closer gap, agian comparable to the difference between education level. The gap is narrower among smokers and non-smokers, but larger when diabetes or CHD is examined."
  },
  {
    "objectID": "blog/Survival Analysis/index.html#reflections-on-cox-regression-vs.-kaplan-meier",
    "href": "blog/Survival Analysis/index.html#reflections-on-cox-regression-vs.-kaplan-meier",
    "title": "Survival Analysis in R",
    "section": "Reflections on Cox Regression vs. Kaplan-Meier",
    "text": "Reflections on Cox Regression vs. Kaplan-Meier\nThe cox regression showed that smoker status, diabetes status, education level (college degree or more), CHD status, age, and sex were all statistically significant in the model. The highest increased hazard ratios were from the variables for CHD and diabetes.\nWhen we examine the Kaplan-Meier and Log Rank tests, all categorical variables were significant except for smoker status. This difference was not expected. Being that the cox regression showed it as significant and with a fairly high hazard ratio, I expected to see a bigger difference in survival time. Perhaps this is due to comorbidities associated with this variable. But the two largest hazard ratios in the cox regression, diabetes and CHD, displayed the biggest differences in suvival time, which was expected. Also, variables like education and sex showed smaller but still present difference in line with cox regression results.\nCox regression is obviously necessary whenever you are interested in a continuous variable’s relationship to the outcome. It is also preferred when you have multiple groups in a categorical variables. As we saw in this project, education level was shown as significant using both methods. However, cox regression gave us a greater level of detail of increased risk within groups. The Kaplan-Meier (and Log Rank test) simply told us there was a significant difference somewhere within the groups.\nThere are other advantages to picking a particular method. For instance, if you are more interested in metrics like average survival time, KP delivers that information. If you are looking for information for example in a clinical trial, a cox regression may be preferable due to the hazard ratio it gives you. This may be more practical too if you are interested in multiple factors influencing an outcome. KP is limited to one factor at a time.\nLastly, Kaplan-Meier may be the most reliable method to use if you have data that do not meet the proper assumptions, as KP is a non-parametric test. Cox regression is semi-parametric, meaning there are some assumptions that must be met. In this way, it may be easier to apply KP to ill fitting data. But one method is not “better” than the other, they are simply different techniques that answer slightly different questions."
  },
  {
    "objectID": "blog/Michigan COVID Cases and Deaths by County/index.html",
    "href": "blog/Michigan COVID Cases and Deaths by County/index.html",
    "title": "Michigan COVID-19 County Maps",
    "section": "",
    "text": "This post is intended to demonstrate some basic ways to map data in R. For our example, we will be creating a choropleth map of Michigan’s counties featuring COVID-19 data. The result is something quite similar to the map featured on the state’s dashboard. The data used in this post is from October 4, 2022.\nFor the sake of practice, we will walk through two different ways to go about this process. First we will use ggplot2. We will use a function called map_data to pull in shape file data easily. In our second example, we will use leaflet to create a better looking version of this map and use a raw shape file."
  },
  {
    "objectID": "blog/Michigan COVID Cases and Deaths by County/index.html#introduction",
    "href": "blog/Michigan COVID Cases and Deaths by County/index.html#introduction",
    "title": "Michigan COVID-19 County Maps",
    "section": "",
    "text": "This post is intended to demonstrate some basic ways to map data in R. For our example, we will be creating a choropleth map of Michigan’s counties featuring COVID-19 data. The result is something quite similar to the map featured on the state’s dashboard. The data used in this post is from October 4, 2022.\nFor the sake of practice, we will walk through two different ways to go about this process. First we will use ggplot2. We will use a function called map_data to pull in shape file data easily. In our second example, we will use leaflet to create a better looking version of this map and use a raw shape file."
  },
  {
    "objectID": "blog/Michigan COVID Cases and Deaths by County/index.html#ggplot2-map",
    "href": "blog/Michigan COVID Cases and Deaths by County/index.html#ggplot2-map",
    "title": "Michigan COVID-19 County Maps",
    "section": "Ggplot2 map",
    "text": "Ggplot2 map\nTo start, we will make a base map with ggplot2 and make it interactive with plotly. First, as always, we load in the libraries we will be using.\n\n\nCode\n# Load packages -----------------------------------------------------------\nlibrary(tidyverse) # really just dplyr but the whole verse can't hurt\nlibrary(openxlsx) # to read in excel data\nlibrary(plotly) # for the interactive part\nlibrary(RColorBrewer) # to set our color palette\n\n\nNext, we will get our county map. To do this we can simply call the function map_data and specify that we want it at the county level. This will give us data for every county in the US. Because we are only mapping Michigan, we add a second line to subset our first data frame ‘counties’ to only include Michigan.\n\n\nCode\n# Make the base state map -------------------------------------------------\ncounties &lt;- map_data(\"county\")\nmi_county &lt;- subset(counties, region == \"michigan\")\n\n\nFor our COVID-19 data, I am importing an older file from state’s website (linked previously). If you want a current version to follow along, you can find it there. Once the file is loaded into R Studio, we need to make a few adjustments. The original file splits the cases into two categories, confirmed and probable. On the state’s dashboard, they combine these numbers into a total for map reporting. We will do the same. This is easily done with the group_by and summarise functions. We will also change the county names to lowercase in preparation for merging.\n\n\nCode\n# Data prep ---------------------------------------------------------------\nmicovid &lt;- read.xlsx(\"Cases and Deaths by County 2022-10-04.xlsx\")\n\nmicovid &lt;- micovid %&gt;%\n  group_by(COUNTY) %&gt;%\n  summarise(total_cases = sum(Cases),\n            total_deaths = sum(Deaths)) %&gt;%\n  ungroup() %&gt;%\n  mutate(subregion = tolower(COUNTY))\n\ncases_and_county &lt;- inner_join(mi_county, micovid, by = \"subregion\")\ncases_and_county &lt;- cases_and_county %&gt;%\n  rename(county = COUNTY)\n\n\n\n\nCode\ncases_and_county&lt;- cases_and_county %&gt;%\n  mutate(Category = case_when(total_cases &lt; 1000 ~ '0-999', \n                              total_cases &lt; 5000 ~ '1000-4999',\n                              total_cases &lt;15000 ~ '5000-14999',\n                              total_cases &lt; 30000 ~ '15000-29999',\n                              total_cases &lt; 100000~ '30000-99999',\n                              total_cases &lt; 1000000 ~ '100000+',\n                              TRUE ~ 'NA'))\n\ncases_and_county$Category &lt;- as.factor(cases_and_county$Category)\n\nlvls &lt;- c('0-999', \n          '1000-4999',\n          '5000-14999',\n          '15000-29999',\n          '30000-99999',\n          '100000+')\n\ncases_and_county$Category &lt;- fct_relevel(cases_and_county$Category, lvls)\n\n\n\n\nCode\n# Making the map ----------------------------------------------------------\n\np &lt;- c(\"#ACD1E7\", \"#82BADC\", \"#59A1CF\", \"#236893\",\"#174562\", \"#122548\")\n\nlabel &lt;- list(\n  bgcolor = \"#EEEEEE\",\n  font = list(color = \"black\")\n)\n\nnoax &lt;- list(\n  title = \"\",\n  zeroline = FALSE,\n  showline = FALSE,\n  showticklabels = FALSE,\n  showgrid = FALSE\n)\n\ng &lt;- cases_and_county %&gt;%\n  ggplot(aes(long, lat, \n                group = group,\n                text = paste('&lt;/br&gt;County:', county, '&lt;/br&gt;Category:', Category,\n                             '&lt;/br&gt;Cases:', total_cases)))+\n  geom_polygon(colour = alpha(\"black\", 1/2), fill = NA) +\n  geom_polygon(data = cases_and_county, colour = \"black\", aes(fill = Category))+\n  theme_void() +\n  scale_fill_manual(values = p) \n\n\n\n\nCode\nggplotly(g, tooltip = c(\"text\"), width = 700, height = 600) %&gt;%\n  layout(xaxis = noax,\n         yaxis = noax) %&gt;%\n  style(hoverlabel = label) %&gt;%\n  config(displayModeBar = FALSE)"
  },
  {
    "objectID": "blog/Michigan COVID Cases and Deaths by County/index.html#using-leaflet",
    "href": "blog/Michigan COVID Cases and Deaths by County/index.html#using-leaflet",
    "title": "Michigan COVID-19 County Maps",
    "section": "Using Leaflet",
    "text": "Using Leaflet\n\n\nCode\n# leaflet -----------------------------------------------------------------\nlibrary(sp)\nlibrary(tigris)\nlibrary(leaflet)\n\nmiCounties &lt;- counties(state = \"MI\", cb = TRUE, progress_bar = FALSE)\n\nmicovid &lt;- micovid %&gt;%\n  mutate(NAME = case_when(\n    COUNTY == \"St Clair\" ~ \"St. Clair\",\n    COUNTY == \"St Joseph\" ~ \"St. Joseph\",\n    TRUE ~ COUNTY\n  ))\n\ncombined &lt;- merge(miCounties, micovid)\n\n\n# pals and labels for each map -------------------------------------------------------\n\ncase_bins &lt;- c(0, 1000, 5000, 15000, 30000, 100000, Inf)\ncase_pal &lt;- colorBin(\"Blues\", domain = combined$total_cases, bins = case_bins)\n\ncase_labels &lt;- sprintf(\n  \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br/&gt;Cases: %g\",\n  combined$NAME, combined$total_cases\n) %&gt;% lapply(htmltools::HTML)\n\ndeath_bins &lt;- c(0, 50, 100, 150, 500, 1500, 3000, Inf)\n\ndeath_pal &lt;- colorBin(\"Reds\", domain = combined$total_deaths, bins = death_bins)\n\ndeath_labels  &lt;- sprintf(\n  \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br/&gt;Deaths: %g\",\n  combined$NAME, combined$total_deaths\n) %&gt;% lapply(htmltools::HTML)\n\nleaflet() %&gt;% \n  addTiles(group = \"base\") %&gt;%\n  addPolygons(data = combined,\n              group = \"Cases\",\n              fillColor = ~case_pal(total_cases),\n              weight = 2,\n              opacity = 1,\n              color = \"white\",\n              dashArray = \"3\",\n              fillOpacity = 0.7,\n              highlightOptions = highlightOptions(\n                weight = 5,\n                color = \"#666\",\n                dashArray = \"\",\n                fillOpacity = 0.7,\n                bringToFront = TRUE),\n              label = case_labels,\n              labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"15px\",\n                direction = \"auto\")) %&gt;%\n  addLegend(data = combined,\n            title = \"Cases\",\n            pal = case_pal, values = ~total_cases, opacity = 0.7,\n            position = \"bottomright\", group = \"Cases\") %&gt;%\n  addPolygons(data = combined,\n              group = \"Deaths\",\n              fillColor = ~death_pal(total_deaths),\n              weight = 2,\n              opacity = 1,\n              color = \"white\",\n              dashArray = \"3\",\n              fillOpacity = 0.7,\n              highlightOptions = highlightOptions(\n                weight = 5,\n                color = \"#666\",\n                dashArray = \"\",\n                fillOpacity = 0.7,\n                bringToFront = TRUE),\n              label = death_labels,\n              labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"15px\",\n                direction = \"auto\")) %&gt;%\n  addLegend(data = combined, \n            title = \"Deaths\",\n            pal = death_pal, values = ~total_deaths, opacity = 0.7,\n            position = \"bottomright\", group = \"Deaths\") %&gt;%\n  addLayersControl(overlayGroups = c(\"Cases\", \"Deaths\"),\n                   options = layersControlOptions(collapsed = FALSE)) %&gt;%\n  hideGroup(\"Deaths\")"
  },
  {
    "objectID": "blog/Shapefiles in CDCPLACES/index.html",
    "href": "blog/Shapefiles in CDCPLACES/index.html",
    "title": "What’s New in CDCPLACES 1.1.5",
    "section": "",
    "text": "An earlier version of this blog post was published on February 6, 2024 and described the new features in the development version of this package. This update shows all of the new features of the package as of March 16, 2024."
  },
  {
    "objectID": "blog/Shapefiles in CDCPLACES/index.html#introduction",
    "href": "blog/Shapefiles in CDCPLACES/index.html#introduction",
    "title": "What’s New in CDCPLACES 1.1.5",
    "section": "Introduction",
    "text": "Introduction\nCDCPLACES version 1.1.5 is now available on CRAN. Users can now request an sf data frame to allow for simple, streamlined mapping of PLACES data. To use this new feature, be sure to install the latest version from CRAN or GitHub.\n\n\nCode\n# Install the latest development version\n# devtools::install_github(\"brendensm/CDCPLACES\")\n\n# Or from CRAN\n# install.packages(\"CDCPLACES\")\n\nlibrary(CDCPLACES)\nlibrary(ggplot2)\nlibrary(dplyr)"
  },
  {
    "objectID": "blog/Shapefiles in CDCPLACES/index.html#new-argument-geometry",
    "href": "blog/Shapefiles in CDCPLACES/index.html#new-argument-geometry",
    "title": "What’s New in CDCPLACES 1.1.5",
    "section": "New argument geometry",
    "text": "New argument geometry\nFirst we need to query our data. To include our shape file, we need to specify the argument geometry as “TRUE”. For our first example we will look at the percentage of adults sleeping less than 7 hours in Michigan Counties.\n\n\nCode\nmi &lt;- get_places(state = \"MI\", \n                 measure = \"SLEEP\", \n                 geometry = TRUE)\n\n\nNow we can take this dataset and immediately plot the spatial data with ggplot2. I will also add a nicer looking color palette and the percentage scale in scale_fill_viridis_c, as well as a title with the function labs.\n\n\nCode\nmi |&gt; \n  filter(datavaluetypeid == \"AgeAdjPrv\") |&gt; \n  ggplot(aes(fill = data_value)) +\n  geom_sf() +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  theme_void() +\n  labs(title = mi$measure) +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\nWe can do the same for census level data. This is as simple as specifying our geography to “census”.\n\n\nCode\nvt &lt;- get_places(geography = \"census\", \n                 state = \"VT\", \n                 measure = \"SLEEP\", \n                 geometry = TRUE)\n\n\nThen we can map it just the same.\n\n\nCode\nvt |&gt; \n  ggplot(aes(fill = data_value)) +\n  geom_sf() +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  theme_void() +\n  labs(title = vt$measure) +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "blog/Shapefiles in CDCPLACES/index.html#query-by-county",
    "href": "blog/Shapefiles in CDCPLACES/index.html#query-by-county",
    "title": "What’s New in CDCPLACES 1.1.5",
    "section": "Query by County",
    "text": "Query by County\nThis update also allows for the user to query specific counties using the argument county. In the example below, we can specify the state and counties we want to plot with simple syntax.\n\n\nCode\ncap_county &lt;- get_places(geography = \"census\", \n                         state = \"MI\", \n                         measure = \"ACCESS2\", \n                         county = c(\"Ingham\", \"Eaton\", \"Clinton\"), \n                         geometry = TRUE)\n\n\nOnce this is done, we can plot our data.\n\n\nCode\ncap_county |&gt; \n  ggplot(aes(fill = data_value)) +\n  geom_sf() +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  theme_void() +\n  labs(title = cap_county$measure) +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "blog/Shapefiles in CDCPLACES/index.html#acknowledgements",
    "href": "blog/Shapefiles in CDCPLACES/index.html#acknowledgements",
    "title": "What’s New in CDCPLACES 1.1.5",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese features would not be possible without the excellent work of Kyle Walker’s package tigris. The contributions he has made to the R community have been incredibly inspiring to me. His other package, tidycensus was the inspiration for this entire pacakge. To see his work visit his website here."
  },
  {
    "objectID": "blog/Text_in_R/index.html",
    "href": "blog/Text_in_R/index.html",
    "title": "I Made R Text For Me",
    "section": "",
    "text": "Up front, I have problems with procrastination. The last few years in graduate school have made me prioritize certain things MUCH better. However, in my personal life, I still struggle. I continue to put off things that I would rather do later. A prime example of this is my role as utility-bill-payer in my current living situation.\nIt is my duty to pay our house’s gas, internet, trash, and electric/water bills every month. I am reliable enough for this (especially with the convenience of automatic payments). My struggle is the monthly task of rounding up these payments, calculating the totals owed by my respective roommates, and the herculean task of texting them the breakdown for the month. Lately, I have been contemplating fun, useful projects to work on using the beauty of programming languages and I realized this is the perfect thing to do.\nThe plan? Make this process as easy as possible for me. With a little trial and error, I’ve done it.\nThis project consists of:\n\nA spreadsheet to store the monthly breakdown of utility payments (unfortunately, this still has to be done by hand).\nAn R script to pull this spreadsheet in and send a custom text message that uses the most recent month’s total and roommate share amount (along with a breakdown of each bill amount).\nA method to automatically run this process without any reliability on my behalf (insert cron jobs)."
  },
  {
    "objectID": "blog/Text_in_R/index.html#introduction",
    "href": "blog/Text_in_R/index.html#introduction",
    "title": "I Made R Text For Me",
    "section": "",
    "text": "Up front, I have problems with procrastination. The last few years in graduate school have made me prioritize certain things MUCH better. However, in my personal life, I still struggle. I continue to put off things that I would rather do later. A prime example of this is my role as utility-bill-payer in my current living situation.\nIt is my duty to pay our house’s gas, internet, trash, and electric/water bills every month. I am reliable enough for this (especially with the convenience of automatic payments). My struggle is the monthly task of rounding up these payments, calculating the totals owed by my respective roommates, and the herculean task of texting them the breakdown for the month. Lately, I have been contemplating fun, useful projects to work on using the beauty of programming languages and I realized this is the perfect thing to do.\nThe plan? Make this process as easy as possible for me. With a little trial and error, I’ve done it.\nThis project consists of:\n\nA spreadsheet to store the monthly breakdown of utility payments (unfortunately, this still has to be done by hand).\nAn R script to pull this spreadsheet in and send a custom text message that uses the most recent month’s total and roommate share amount (along with a breakdown of each bill amount).\nA method to automatically run this process without any reliability on my behalf (insert cron jobs)."
  },
  {
    "objectID": "blog/Text_in_R/index.html#the-spreadsheet",
    "href": "blog/Text_in_R/index.html#the-spreadsheet",
    "title": "I Made R Text For Me",
    "section": "The Spreadsheet",
    "text": "The Spreadsheet\nThis was a task I already had mostly completed. At the beginning of this year, I created a very basic spreadsheet in Google Sheets to track my utility bills. One table consists of the data in a tidy format, including columns for the month, bill type, amount, and date paid. A second table creates a sum from the first table giving the date to notify (the first of the month after the month in which the bill was paid), the total amount, and the amount owed by the roommate (one-third split on the total).\nBecause each bill comes from a different place and my email isn’t easily accessible to a programming language, I still have to update this spreadsheet by hand whenever I am notified of a payment. And for my purposes, I was ok with this!"
  },
  {
    "objectID": "blog/Text_in_R/index.html#r-script",
    "href": "blog/Text_in_R/index.html#r-script",
    "title": "I Made R Text For Me",
    "section": "R Script",
    "text": "R Script\nThe script for this project has three main tasks:\n\nImport the data from Google Sheets.\nCreate the text of the message.\nSend the text message.\n\n\nGetting the Data\nFirst, we can call the libraries we will need.\n\n\nCode\nlibrary(googlesheets4)\nlibrary(dplyr)\n\n\nThe package googlesheets4 made this project incredibly easy.\nYou can connect to your Google account using gs4_auth.\n\n\nCode\ngs4_auth(email = \"your email here\")\n\n\nThen, you can import your sheet.\n\n\nCode\ndata &lt;- read_sheet(\"your_url_here\")\n\n\nTo demonstrate what my data looked like, I will create a demo data set to work with in this example.\n\n\nCode\nmonth &lt;- c(\"Feb\", \"Feb\", \"Feb\", \"Mar\", \"Mar\", \"Mar\")\n\nbill_type &lt;- c(\"Gas\", \"Water\", \"Internet\", \"Gas\", \"Water\", \"Internet\")\n\namount &lt;- c(50, 62, 25, 55, 70, 25)\n\ndue_date &lt;- c(\"2/1/2024\", \"2/4/2024\", \"2/5/2024\", \n              \"3/1/2024\", \"3/5/2024\", \"3/6/2024\")\n\ntable1 &lt;- data.frame(month, bill_type, amount, due_date) |&gt; \n  mutate(due_date = lubridate::mdy(due_date))\n\ntable1\n\n\n  month bill_type amount   due_date\n1   Feb       Gas     50 2024-02-01\n2   Feb     Water     62 2024-02-04\n3   Feb  Internet     25 2024-02-05\n4   Mar       Gas     55 2024-03-01\n5   Mar     Water     70 2024-03-05\n6   Mar  Internet     25 2024-03-06\n\n\nCode\ntable2.1&lt;- table1 |&gt; \n  summarise(.by = month,\n            total = sum(amount),\n            third = total/3) \n\nnotify &lt;- c(\"3/1/2024\", \"4/1/2024\")\n\ntable2.2 &lt;- data.frame(notify) |&gt; \n  mutate(notify = lubridate::mdy(notify))\n\ntable2 &lt;- cbind(table2.1, table2.2)\ntable2\n\n\n  month total    third     notify\n1   Feb   137 45.66667 2024-03-01\n2   Mar   150 50.00000 2024-04-01\n\n\n\n\nCreating the Message\nBecause my real data has all of the month’s data in it, we need to filter to get the right amounts to send in our text. We can use Sys.Date to get the current date, and lubridate::month to make the date a numeric value representing the month.\nThen we can do the same for our tables to filter by. Remember I will have this script executing at the first of every month to report what the costs were for the previous month.\n\n\nCode\n# current_month &lt;- lubridate::month(Sys.Date())\ncurrent_month &lt;- 4 # for our example\n\nfiltered_sum &lt;- table2 |&gt; \n  mutate(notify = lubridate::month(notify)) |&gt; \n  filter(notify == current_month)\n\nmonthly_total &lt;- filtered_sum$total\n\nthird &lt;- filtered_sum$third\n\nbreakdown &lt;- table1 |&gt; \n  mutate(month_num = lubridate::month(due_date)) \n\nbreakdown_amounts &lt;- breakdown |&gt; \n  filter(month_num == (current_month - 1)) |&gt; \n  select(bill_type, amount)\n\n\nNow that we have the amounts we need, we can construct a message.\n\n\nCode\n message &lt;- paste(\"The total of our utility bill for the month of\", \n                  filtered_sum$month, \"is:\", monthly_total, \n                  \"\\nA third of this total is:\", round(third, 2), \n                   \"\\n\\nHere is a breakdown of the bill:\",\n                   paste0(\"\\n\", breakdown_amounts[1,1], \": \",\n                     breakdown_amounts[1,2], \"\\n\",\n                     breakdown_amounts[2,1], \": \",\n                     breakdown_amounts[2,2], \"\\n\",\n                     breakdown_amounts[3,1], \": \",\n                     breakdown_amounts[3,2]\n                   )\n )\n\ncat(message)\n\n\nThe total of our utility bill for the month of Mar is: 150 \nA third of this total is: 50 \n\nHere is a breakdown of the bill: \nGas: 55\nWater: 70\nInternet: 25\n\n\n\n\nSending the Message\nNext, we text.\nThe method I am using is only for iMessage devices, and is really only possible from a Mac. This method is taken from a very helpful Stackoverflow post. There is probably a workaround for other devices and sending through SMS, but that is not the focus of this post.\nWe can send our text with an Apple Script. Here is a function to do just that. This is slightly adapted from the Stackoverflow answer and allows for separate texts to multiple recipients.\n\n\nCode\nsend_text &lt;- function(message, buddy){\n  \n  for(i in buddy){\n    system(paste('osascript -e \\'tell application \"Messages\"\\' -e \\'send \"', message, '\" to buddy', i,  'of (service 1 whose service type is iMessage)\\' -e \\'end tell\\''))\n  }\n  \n}\n\n\nThen we can simply plug in the rest. But be warned: running this command will send a text! Be careful when testing this out.\n\n\nCode\nbuddies &lt;- c(\"\\\"phonenumber1\\\"\", \"\\\"phonenumber2\\\"\")\n\nsend_text(message, buddies)"
  },
  {
    "objectID": "blog/Text_in_R/index.html#the-cron-job",
    "href": "blog/Text_in_R/index.html#the-cron-job",
    "title": "I Made R Text For Me",
    "section": "The Cron Job",
    "text": "The Cron Job\nNow that the hard part is over, we can simply create a cron job to run this script directly from the command line on the first of every month.\nImportant: make sure the following is at the top of your saved R script:\n\n\nCode\n#!/usr/local/bin/Rscript\n\n\nTo open your cron tab, in the terminal type the following command:\n\n\nCode\nexport VISUAL=nano; crontab -e\n\n\nAs an added tip, you can save this command as an alias in your .zshrc file to make it easier to quickly access.\nOnce the cron tab is open, you have to set up the job and specify how often you want it to run. The following runs on the first of every month at 9 AM. The command navigates to my home directory, and then executes my R script which I have named “utes_notif.R”.\n\n\nCode\n0 9 1 * * cd ~; ./Desktop/R/utility_notification/utes_notif.R"
  },
  {
    "objectID": "blog/Text_in_R/index.html#other-considerations",
    "href": "blog/Text_in_R/index.html#other-considerations",
    "title": "I Made R Text For Me",
    "section": "Other Considerations",
    "text": "Other Considerations\nLastly, I want to note a small consideration when setting up an automated process like this. The cron job will run in this form only if the computer is awake during the scheduled time.\nTo work around this, you can utilize the battery options in your Mac’s system preferences. I have scheduled my computer to wake up every day at 9 AM for about five minutes. This was the easiest work around for me. However, I am certain there are other options to achieve the same goal. One option may be to use alternative scheduling tools like cronwake or anacron."
  },
  {
    "objectID": "blog/Survival_Analysis/index.html",
    "href": "blog/Survival_Analysis/index.html",
    "title": "Survival Analysis in R",
    "section": "",
    "text": "At first I was afraid, I was petrified…"
  },
  {
    "objectID": "blog/Survival_Analysis/index.html#introduction",
    "href": "blog/Survival_Analysis/index.html#introduction",
    "title": "Survival Analysis in R",
    "section": "Introduction",
    "text": "Introduction\nIn this blog post, I’ll be exploring some basic survival analysis in R. Survival analysis focuses on describing the occurrence of an event (in this example death) in a set time frame. Survival analysis is often used in clinical research and cancer epidemiology. For more reading, I recommend visiting The Epidemiologist R Handbook page on survival analysis, as well as their listed resources. The following blog post was adapted from my biostatistics coursework and features data used in that course. We will create Kaplan-Meier plots and go through Cox Hazard Regression."
  },
  {
    "objectID": "blog/Survival_Analysis/index.html#packages-and-data",
    "href": "blog/Survival_Analysis/index.html#packages-and-data",
    "title": "Survival Analysis in R",
    "section": "Packages and Data",
    "text": "Packages and Data\nFor this blog post, I will use the packages have, dplyr, survival.\n\n\nCode\n# Load in libraries\nlibrary(dplyr)\nlibrary(readr)\nlibrary(survival)\nlibrary(sjPlot)\n\n\nNext, we will load the data.\n\n\nCode\nsd &lt;- read_csv(\"data/HM 878 730 Clements - Survival Analysis R Data.csv\") %&gt;% \n  mutate(\n    #death = factor(death, levels = c(0, 1),\n                 #  labels = c(\"Living\", \"Died\")),\n    cursmoke = factor(cursmoke, levels = c(0, 1), \n                      labels = c(\"Not current smoker\", \"Current smoker\")),\n    diabetes = factor(diabetes, levels = c(0, 1),\n                      labels = c(\"Not diabetic\", \"Diabetic\")),\n    educ = factor(educ, levels = c(1, 2, 3, 4),\n                  labels = c(\"0-11 years\", \"HS Diploma/GED\", \n                             \"Some College/Vocational School\",\n                             \"College degree or more\")),\n    prevchd = factor(prevchd, levels = c(0, 1),\n                    labels = c(\"No\", \"Yes\")),\n    sex = factor(sex, levels = c(0, 1),\n                 labels = c(\"Female\", \"Male\"))\n  )"
  },
  {
    "objectID": "blog/Survival_Analysis/index.html#cox-regression",
    "href": "blog/Survival_Analysis/index.html#cox-regression",
    "title": "Survival Analysis in R",
    "section": "Cox Regression",
    "text": "Cox Regression\n\nHazard Ratios\n\n\nCode\ncm &lt;- coxph(Surv(TimeDeathYears, death) ~ cursmoke + diabetes +\n              educ + prevchd + age + bmi + sex, data = sd)\n\nsummary(cm)\n\n\nCall:\ncoxph(formula = Surv(TimeDeathYears, death) ~ cursmoke + diabetes + \n    educ + prevchd + age + bmi + sex, data = sd)\n\n  n= 3165, number of events= 746 \n   (98 observations deleted due to missingness)\n\n                                        coef exp(coef)  se(coef)      z\ncursmokeCurrent smoker              0.432597  1.541256  0.081165  5.330\ndiabetesDiabetic                    0.741622  2.099338  0.100251  7.398\neducHS Diploma/GED                 -0.007861  0.992169  0.092149 -0.085\neducSome College/Vocational School -0.158231  0.853652  0.111205 -1.423\neducCollege degree or more         -0.454487  0.634773  0.131159 -3.465\nprevchdYes                          0.790013  2.203425  0.086862  9.095\nage                                 0.092917  1.097370  0.005068 18.333\nbmi                                -0.012792  0.987290  0.009667 -1.323\nsexMale                             0.672732  1.959583  0.075393  8.923\n                                   Pr(&gt;|z|)    \ncursmokeCurrent smoker             9.83e-08 ***\ndiabetesDiabetic                   1.39e-13 ***\neducHS Diploma/GED                  0.93201    \neducSome College/Vocational School  0.15477    \neducCollege degree or more          0.00053 ***\nprevchdYes                          &lt; 2e-16 ***\nage                                 &lt; 2e-16 ***\nbmi                                 0.18575    \nsexMale                             &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                                   exp(coef) exp(-coef) lower .95 upper .95\ncursmokeCurrent smoker                1.5413     0.6488    1.3146    1.8070\ndiabetesDiabetic                      2.0993     0.4763    1.7248    2.5551\neducHS Diploma/GED                    0.9922     1.0079    0.8282    1.1886\neducSome College/Vocational School    0.8537     1.1714    0.6865    1.0615\neducCollege degree or more            0.6348     1.5754    0.4909    0.8208\nprevchdYes                            2.2034     0.4538    1.8585    2.6124\nage                                   1.0974     0.9113    1.0865    1.1083\nbmi                                   0.9873     1.0129    0.9688    1.0062\nsexMale                               1.9596     0.5103    1.6904    2.2716\n\nConcordance= 0.761  (se = 0.009 )\nLikelihood ratio test= 688.4  on 9 df,   p=&lt;2e-16\nWald test            = 686.8  on 9 df,   p=&lt;2e-16\nScore (logrank) test = 783.3  on 9 df,   p=&lt;2e-16\n\n\nCode\nsjPlot::tab_model(cm)\n\n\n\n\n\n\n\n\n\n\n\n\n \nSurv(TimeDeathYears,\ndeath)\n\n\nPredictors\nEstimates\nCI\np\n\n\ncursmoke [Current smoker]\n1.54\n1.31 – 1.81\n&lt;0.001\n\n\ndiabetes [Diabetic]\n2.10\n1.72 – 2.56\n&lt;0.001\n\n\neduc [HS Diploma/GED]\n0.99\n0.83 – 1.19\n0.932\n\n\neduc [Some\nCollege/Vocational\nSchool]\n0.85\n0.69 – 1.06\n0.155\n\n\neduc [College degree or\nmore]\n0.63\n0.49 – 0.82\n0.001\n\n\nprevchd [Yes]\n2.20\n1.86 – 2.61\n&lt;0.001\n\n\nage\n1.10\n1.09 – 1.11\n&lt;0.001\n\n\nbmi\n0.99\n0.97 – 1.01\n0.186\n\n\nsex [Male]\n1.96\n1.69 – 2.27\n&lt;0.001\n\n\nObservations\n3165\n\n\nR2 Nagelkerke\n0.200\n\n\n\n\n\n\n\n\n\n\nSurvival Curves\n\n\nCode\nsurv_fit_diab &lt;-  survfit(Surv(TimeDeathYears, death) ~ diabetes, data = sd)\n\ncol_diab &lt;- c(\"lightgreen\", \"darkgreen\")\n\nplot(\n  surv_fit_diab,\n  col = col_diab,\n  xlab = \"Years\",\n  ylab = \"Survival Probability\")\nlegend(\n  \"bottomright\",\n  legend = c(\"Not diabetic\",\"Diabetic\"),\n  col = col_diab,\n  lty = 1,\n  cex = .9,\n  bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\nInterpretation\nHazard ratios for the cox regression show that smoker status, diabetic status, prevalent coronary heart disease, age, sex, and the highest level of education all have significant p-values. This means that each were found to impact the outcome of death in our survival analysis.\nSmoker status has a hazard ratio of 1.54 meaning that, compared to non-smokers, current smokers have 1.54 times the risk of death.\nDiabetic status has a hazard ratio of 2.10. This means that those with diabetes, compared to those that were not diabetic, had 2.1 times greater risk of death.\nEducation at the level of college degree or more had a hazard ratio of 0.63. Compared to those with 0-11 years of education, this group had 37% decreased risk of death.\nPrevalence of coronary heart disease has a hazard ratio of 2.20, meaning that compared to those without CHD, they had 120% increased risk of death.\nAge also has a significant p-value, and a hazard ratio of 1.10. This means for every increase unit in age, there is 10% greater risk of death.\nLastly, sex had a hazard ratio of 1.96. This means that compared to females, males had 95% greater risk of death.\nThe survival curve shows the difference in survival probability between diabetics and non-diabetics. The differences are quite noticeably, with a lower survival probability among diabetics. This is in line with the results of the cox regression. For example, at 10 years, the survival probability among non-diabetics is about 85%, while the probability among diabetics is 65%."
  },
  {
    "objectID": "blog/Survival_Analysis/index.html#kaplan-meier",
    "href": "blog/Survival_Analysis/index.html#kaplan-meier",
    "title": "Survival Analysis in R",
    "section": "Kaplan-Meier",
    "text": "Kaplan-Meier\nConduct Kaplan-Meier for each categorical IV. Interpret the summary, mean and median survival time, Log Rank Mantel-Cox Test, survival probability at 10 years. Compare and contrast between each variable.\n\nFunction for Analysis\nBecause I have to compare quite a few variables, I make a quick function to output exactly what I need.\n\n\nCode\nkm &lt;- function(time, event, data, iv, title_label){\n  \nmodel &lt;-  survfit(Surv(time, event) ~ iv, data = sd)\n\ncols &lt;- RColorBrewer::brewer.pal(4, \"Set1\")\n\nplot_title &lt;- paste(\"Survival Curve by\", title_label)\n\nplot(\n  model,\n  col = cols,\n  lwd = 2,\n  main = plot_title,\n  xlab = \"Years\",\n  ylab = \"Survival Probability\")\nlegend(\n  \"bottomleft\",\n  legend = levels(iv),\n  col = cols,\n  lty = 1,\n  cex = .9,\n  bty = \"n\")\nabline(h = seq(0,1,.2), lty = \"dashed\", col = \"gray75\")\nabline(lty = \"dashed\", col = \"black\", v = 10)\n  \n  \ncat(\"Model summary with mean and median: \\n\")\nprint(model, print.rmean = TRUE)\n\nlogrank &lt;- survdiff(Surv(time, event) ~ iv, data = data)\nprint(logrank)\n  \n}\n\n\n\n\nDiabetes\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$diabetes, \"Diabetes\")\n\n\n\n\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n                   n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=Not diabetic 3009    646   13.7    0.0525     NA      NA      NA\niv=Diabetic      254    129   11.8    0.2540     14      13      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n                   N Observed Expected (O-E)^2/E (O-E)^2/V\niv=Not diabetic 3009      646    724.5       8.5       133\niv=Diabetic      254      129     50.5     121.8       133\n\n Chisq= 133  on 1 degrees of freedom, p= &lt;2e-16 \n\n\nAs interpreted before, the survival probability differs quite drastically between these two groups. At 10 years, the survival probability among non-diabetics is about 85%, while the probability among diabetics is 65%.\nThe model summary shows the total number in each group and the number of events (deaths) in each group.\nThe mean survival time is 13.7 years for non-diabetics, compared to 11.8 for diabetics. The median survival time could not be computed for non-diabetics, and was 14 years for diabetics. The median was not computed for non-diabetics because over 50% were still alive by the end of the time period.\nThe Log Rank Mantel-Cox Test shows a resulting p-value of &lt;0.0001, meaning that the null hypothesis, that there is no difference in survival between groups, is rejected.\n\n\nSmoker Status\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$cursmoke, \"Smoker Status\")\n\n\n\n\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n                         n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=Not current smoker 2142    501   13.6    0.0649     NA      NA      NA\niv=Current smoker     1121    274   13.5    0.0922     NA      NA      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n                         N Observed Expected (O-E)^2/E (O-E)^2/V\niv=Not current smoker 2142      501      510     0.173     0.517\niv=Current smoker     1121      274      265     0.333     0.517\n\n Chisq= 0.5  on 1 degrees of freedom, p= 0.5 \n\n\nThe model results show that the mean survival time was 13.6 among non-smokers and 13.5 among current smokers. These are not very different from each other, and on par with the average survival time of non-diabetics. The median survival times were not able to be calculated for this variable.\nThe Log Rank test shows a p-value of 0.5 indicating we should accept the null hypothesis that there is no difference in survival between the two groups.\nAt 10 years, the survival probability is nearly the same between the two groups, a bit greater than 80%. Once again, similar to non-diabetic suvival probability at the same time.\n\n\nEducation Level\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$educ, \"Education\")\n\n\n\n\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n   82 observations deleted due to missingness \n                                     n events rmean* se(rmean) median 0.95LCL\niv=0-11 years                     1281    381   13.2    0.0936     NA      NA\niv=HS Diploma/GED                  967    194   13.8    0.0911     NA      NA\niv=Some College/Vocational School  542    108   13.9    0.1188     NA      NA\niv=College degree or more          391     71   14.0    0.1275     NA      NA\n                                  0.95UCL\niv=0-11 years                          NA\niv=HS Diploma/GED                      NA\niv=Some College/Vocational School      NA\niv=College degree or more              NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\nn=3181, 82 observations deleted due to missingness.\n\n                                     N Observed Expected (O-E)^2/E (O-E)^2/V\niv=0-11 years                     1281      381    291.6     27.40     45.74\niv=HS Diploma/GED                  967      194    234.0      6.84     10.14\niv=Some College/Vocational School  542      108    131.9      4.32      5.36\niv=College degree or more          391       71     96.5      6.74      7.91\n\n Chisq= 46.4  on 3 degrees of freedom, p= 5e-10 \n\n\nThis model summary compares each of the four education levels in our variable. The mean survival years for those 0-11 is 13.2, for HS/Diploma/GED it is 13.8, for Some College/Vocational School it is 13.9 and for College degree or more it is 14. These are close to the averages we saw among smokers/nonsmokers, and non-diabetics. However, diabetics have still had the lowest average at 11 years. Once again, the medians could not be calculated for this variable because of the high proportion of groups surviving by the end of the time period.\nThe Log Rank test shows a p-value of &lt;0.0001. This leads us to reject the null and accept the alternative hypothesis that there is a significant difference in survival time between these groups (somewhere).\nThe survival probability at 10 years is 80% for the group 0-11, and around 90% for the other three groups. This is in the range of most groups thus far, aside from diabetics.\n\n\nPrevalence of Coronary Heart Disease\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$prevchd, \"CHD Prevalence\")\n\n\n\n\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n          n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=No  2903    582   13.8    0.0522     NA      NA      NA\niv=Yes  360    193   11.7    0.2077     14      12      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n          N Observed Expected (O-E)^2/E (O-E)^2/V\niv=No  2903      582    704.1      21.2       237\niv=Yes  360      193     70.9     210.4       237\n\n Chisq= 237  on 1 degrees of freedom, p= &lt;2e-16 \n\n\nThose without coronary heart disease had an average survival time of 13.8 years, while those with CHD had an average of 11.7 years. The median was only calculated for those with CHD, which was at 14 years. These metrics align with results from many other groups. the average survival years for those without CHD is comparable to the same metrics examined among the three highest education levels, smokers and non-smokers, and non-diabetics. Diabetics and those with CHD have similar average survival time.\nThe Log Rank Test shows a p-value of less than 0.0001. This leads us to reject the null and accept the alternative hypothesis that there is a difference in survival times between the two groups.\nLooking at the survival curve, the survival probability of those with CHD at 10 years is about 65%. The survival probability of those without CHD is around 90%. This is a comparable split to diabetics/non-diabetics.\n\n\nSex\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$sex, \"Sex\")\n\n\n\n\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n             n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=Female 1876    345   13.9    0.0635     NA      NA      NA\niv=Male   1387    430   13.1    0.0894     NA      NA      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n             N Observed Expected (O-E)^2/E (O-E)^2/V\niv=Female 1876      345      458      28.0      70.1\niv=Male   1387      430      317      40.5      70.1\n\n Chisq= 70.1  on 1 degrees of freedom, p= &lt;2e-16 \n\n\nFor the Kaplan-Meier examining sex, the model results show that the average survival time among females was 13.9 compared to male’s 13.1. This is a similar split between the highest and lowest education levels. Overall, this seems to be a significant difference, but not as big of a difference as CHD or diabetes status. The medians for these groups could not be calculated.\nThe Log Rank Test shows a p-value of less than 0.0001, which again leads us to accept the alternative hypothesis that this model shows a significant difference in survival time between the two groups.\nOn the survival curve, it appears that at 10 years, males had 80% survival probability, and females had about 90%. This is a much closer gap, agian comparable to the difference between education level. The gap is narrower among smokers and non-smokers, but larger when diabetes or CHD is examined."
  },
  {
    "objectID": "blog/Survival_Analysis/index.html#reflections-on-cox-regression-vs.-kaplan-meier",
    "href": "blog/Survival_Analysis/index.html#reflections-on-cox-regression-vs.-kaplan-meier",
    "title": "Survival Analysis in R",
    "section": "Reflections on Cox Regression vs. Kaplan-Meier",
    "text": "Reflections on Cox Regression vs. Kaplan-Meier\nThe cox regression showed that smoker status, diabetes status, education level (college degree or more), CHD status, age, and sex were all statistically significant in the model. The highest increased hazard ratios were from the variables for CHD and diabetes.\nWhen we examine the Kaplan-Meier and Log Rank tests, all categorical variables were significant except for smoker status. This difference was not expected. Being that the cox regression showed it as significant and with a fairly high hazard ratio, I expected to see a bigger difference in survival time. Perhaps this is due to comorbidities associated with this variable. But the two largest hazard ratios in the cox regression, diabetes and CHD, displayed the biggest differences in suvival time, which was expected. Also, variables like education and sex showed smaller but still present difference in line with cox regression results.\nCox regression is obviously necessary whenever you are interested in a continuous variable’s relationship to the outcome. It is also preferred when you have multiple groups in a categorical variables. As we saw in this project, education level was shown as significant using both methods. However, cox regression gave us a greater level of detail of increased risk within groups. The Kaplan-Meier (and Log Rank test) simply told us there was a significant difference somewhere within the groups.\nThere are other advantages to picking a particular method. For instance, if you are more interested in metrics like average survival time, KP delivers that information. If you are looking for information for example in a clinical trial, a cox regression may be preferable due to the hazard ratio it gives you. This may be more practical too if you are interested in multiple factors influencing an outcome. KP is limited to one factor at a time.\nLastly, Kaplan-Meier may be the most reliable method to use if you have data that do not meet the proper assumptions, as KP is a non-parametric test. Cox regression is semi-parametric, meaning there are some assumptions that must be met. In this way, it may be easier to apply KP to ill fitting data. But one method is not “better” than the other, they are simply different techniques that answer slightly different questions."
  },
  {
    "objectID": "blog/Shapefiles_in_CDCPLACES/index.html",
    "href": "blog/Shapefiles_in_CDCPLACES/index.html",
    "title": "What’s New in CDCPLACES 1.1.5",
    "section": "",
    "text": "An earlier version of this blog post was published on February 6, 2024 and described the new features in the development version of this package. This update shows all of the new features of the package as of March 16, 2024.\nThis is part of the CDCPLACES blog series. To view the other posts in this series click here."
  },
  {
    "objectID": "blog/Shapefiles_in_CDCPLACES/index.html#introduction",
    "href": "blog/Shapefiles_in_CDCPLACES/index.html#introduction",
    "title": "What’s New in CDCPLACES 1.1.5",
    "section": "Introduction",
    "text": "Introduction\nCDCPLACES version 1.1.5 is now available on CRAN. Users can now request an sf data frame to allow for simple, streamlined mapping of PLACES data. To use this new feature, be sure to install the latest version from CRAN or GitHub.\n\n\nCode\n# Install the latest development version\n# devtools::install_github(\"brendensm/CDCPLACES\")\n\n# Or from CRAN\n# install.packages(\"CDCPLACES\")\n\nlibrary(CDCPLACES)\nlibrary(ggplot2)\nlibrary(dplyr)"
  },
  {
    "objectID": "blog/Shapefiles_in_CDCPLACES/index.html#new-argument-geometry",
    "href": "blog/Shapefiles_in_CDCPLACES/index.html#new-argument-geometry",
    "title": "What’s New in CDCPLACES 1.1.5",
    "section": "New argument geometry",
    "text": "New argument geometry\nFirst we need to query our data. To include our shape file, we need to specify the argument geometry as “TRUE”. For our first example we will look at the percentage of adults sleeping less than 7 hours in Michigan Counties.\n\n\nCode\nmi &lt;- get_places(state = \"MI\", \n                 measure = \"SLEEP\", \n                 geometry = TRUE)\n\n\nNow we can take this dataset and immediately plot the spatial data with ggplot2. I will also add a nicer looking color palette and the percentage scale in scale_fill_viridis_c, as well as a title with the function labs.\n\n\nCode\nmi |&gt; \n  filter(datavaluetypeid == \"AgeAdjPrv\") |&gt; \n  ggplot(aes(fill = data_value)) +\n  geom_sf() +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  theme_void() +\n  labs(title = mi$measure) +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\n\n\n\n\nWe can do the same for census level data. This is as simple as specifying our geography to “census”.\n\n\nCode\nvt &lt;- get_places(geography = \"census\", \n                 state = \"VT\", \n                 measure = \"SLEEP\", \n                 geometry = TRUE)\n\n\nThen we can map it just the same.\n\n\nCode\nvt |&gt; \n  ggplot(aes(fill = data_value)) +\n  geom_sf() +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  theme_void() +\n  labs(title = vt$measure) +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "blog/Shapefiles_in_CDCPLACES/index.html#query-by-county",
    "href": "blog/Shapefiles_in_CDCPLACES/index.html#query-by-county",
    "title": "What’s New in CDCPLACES 1.1.5",
    "section": "Query by County",
    "text": "Query by County\nThis update also allows for the user to query specific counties using the argument county. In the example below, we can specify the state and counties we want to plot with simple syntax.\n\n\nCode\ncap_county &lt;- get_places(geography = \"census\", \n                         state = \"MI\", \n                         measure = \"ACCESS2\", \n                         county = c(\"Ingham\", \"Eaton\", \"Clinton\"), \n                         geometry = TRUE)\n\n\nOnce this is done, we can plot our data.\n\n\nCode\ncap_county |&gt; \n  ggplot(aes(fill = data_value)) +\n  geom_sf() +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  theme_void() +\n  labs(title = cap_county$measure) +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "blog/Shapefiles_in_CDCPLACES/index.html#acknowledgements",
    "href": "blog/Shapefiles_in_CDCPLACES/index.html#acknowledgements",
    "title": "What’s New in CDCPLACES 1.1.5",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese features would not be possible without the excellent work of Kyle Walker’s package tigris. The contributions he has made to the R community have been incredibly inspiring to me. His other package, tidycensus was the inspiration for this entire pacakge. To see his work visit his website here."
  },
  {
    "objectID": "blog/HM878:_Helper_Functions/index.html",
    "href": "blog/HM878:_Helper_Functions/index.html",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "This vignette demonstrates how to use the functions included in this package so far. If you have not yet, install the package with the following code: devtools::install_github(\"brendensm/hm878\"). If you do not have the package devtools, be sure to install that first install.packages(\"devtools\").\nTo start, we load the package\n\nlibrary(hm878)\n\nLet’s assume we are running a binomial logistic regression using the data from mtcars, a built-in data set included with R. We will use vs (engine type as V-shaped or straight) as the dependent variable, and cyl (number of cylinders) as the independent variable. We will store our models for block 1 and block 2.\n\nmb1 &lt;- glm(vs ~ 1, data = mtcars, family = \"binomial\")\nmb2 &lt;- glm(vs ~ cyl, data = mtcars, family = \"binomial\")\n\n\n\nTo assess the fit of our models, we may want to use the function chi_log. To use it, simply type in the name of your model as the first argument, followed by the data set that the model uses. Optionally, you can provide labels for each model using the third argument. Here I will label each block.\n\nchi_log(mb1, mtcars, \"Block 1\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 1:  32 \n Degrees of freedom for Block 1:  31 \n P-value for Block 1:  0.416744 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\nchi_log(mb2, mtcars, \"Block 2\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 2:  27.42 \n Degrees of freedom for Block 2:  30 \n P-value for Block 2:  0.6013516 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\n\nThe function gives us the chi-squared statistic, degrees of freedom, and a p-value. It also reminds us of the null and alternative hypotheses. Both models appear to be a good fit.\n\n\n\nWe may want to also check the accuracy of our models. To do this, we can use predict_percent. To use this function, enter the name of the model in the first argument, followed by the dependent variable we used in the model. For this, we must use the data$variable format. In the example below, we use the variable vs from the data set mtcars. Once again, we can label the output with a string as the optional third argument.\n\npredict_percent(mb1, mtcars$vs, \"Block 1\")\n\n\nAccuracy for Block 1: 56.25%\n\npredict_percent(mb2, mtcars$vs, \"Block 2\")\n\n\nAccuracy for Block 2: 84.38%\n\n\n\n\n\nTo calculate odds ratios for the models, simply pass the model through the function or.\n\nor(mb1)\n\n            Odds_Ratio  CI_Lower CI_Upper  p_values\n(Intercept)  0.7777778 0.3801366 1.558936 0.4806496\n\nor(mb2)\n\n              Odds_Ratio    CI_Lower     CI_Upper    p_values\n(Intercept) 10873.447296 95.35600799 6.507716e+07 0.002692584\ncyl             0.204474  0.04827075 4.455527e-01 0.001917098\n\n\nThe output results in a data frame with the odds ratios, confidence intervals, and p-values.\n\n\n\nIf you want to revise and adjust your model, it can be helpful to limit outliers. To find upper and lower fences quickly, use the function fences. To do this, pass the continuous variable you are interested in examining through the function. Once again, use the format data$variable.\n\n#fences(iris$Sepal.Length)\n#fences(mtcars$cyl)$Upper\n#fences(mtcars$cyl)$Lower\n\n\n\n\nLastly, when you are putting together multiple models, it can be helpful to view them all at the same time, next to one another. This is particularly helpful if you have more than two models you are comparing. For this function, pass through however many models you have to compare, and optionally label each one, using a vector of strings for each model. To demonstrate, I will add on another model mb3 that will have another continuous independent variable.\n\nmb3 &lt;- glm(vs ~ cyl + wt, data = mtcars, family = \"binomial\")\n\ncompare_models(mb1, mb2, mb3, labels = c(\"Model 1 Block 1\", \"Model 1 Block 2\", \"Model Block 3\"))\n\n$`Model 1 Block 1`\n\nCall:  glm(formula = vs ~ 1, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)  \n    -0.2513  \n\nDegrees of Freedom: 31 Total (i.e. Null);  31 Residual\nNull Deviance:      43.86 \nResidual Deviance: 43.86    AIC: 45.86\n\n$`Model 1 Block 2`\n\nCall:  glm(formula = vs ~ cyl, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl  \n      9.294       -1.587  \n\nDegrees of Freedom: 31 Total (i.e. Null);  30 Residual\nNull Deviance:      43.86 \nResidual Deviance: 17.96    AIC: 21.96\n\n$`Model Block 3`\n\nCall:  glm(formula = vs ~ cyl + wt, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl           wt  \n     10.619       -2.931        2.100  \n\nDegrees of Freedom: 31 Total (i.e. Null);  29 Residual\nNull Deviance:      43.86 \nResidual Deviance: 15.55    AIC: 21.55\n\n\n\n\n\n\ndeviance_aic(mb1, mb2, mb3)\n\nmb1 \nResidual Deviance: 43.86 \nNull Deviance: 43.86 \nAIC: 45.86 \n\nmb2 \nResidual Deviance: 17.96 \nNull Deviance: 43.86 \nAIC: 21.96 \n\nmb3 \nResidual Deviance: 15.55 \nNull Deviance: 43.86 \nAIC: 21.55"
  },
  {
    "objectID": "blog/HM878:_Helper_Functions/index.html#testing-goodness-of-fit-with-chi_log",
    "href": "blog/HM878:_Helper_Functions/index.html#testing-goodness-of-fit-with-chi_log",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "To assess the fit of our models, we may want to use the function chi_log. To use it, simply type in the name of your model as the first argument, followed by the data set that the model uses. Optionally, you can provide labels for each model using the third argument. Here I will label each block.\n\nchi_log(mb1, mtcars, \"Block 1\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 1:  32 \n Degrees of freedom for Block 1:  31 \n P-value for Block 1:  0.416744 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\nchi_log(mb2, mtcars, \"Block 2\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 2:  27.42 \n Degrees of freedom for Block 2:  30 \n P-value for Block 2:  0.6013516 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\n\nThe function gives us the chi-squared statistic, degrees of freedom, and a p-value. It also reminds us of the null and alternative hypotheses. Both models appear to be a good fit."
  },
  {
    "objectID": "blog/HM878:_Helper_Functions/index.html#accuracy-percentage-with-predict_percent",
    "href": "blog/HM878:_Helper_Functions/index.html#accuracy-percentage-with-predict_percent",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "We may want to also check the accuracy of our models. To do this, we can use predict_percent. To use this function, enter the name of the model in the first argument, followed by the dependent variable we used in the model. For this, we must use the data$variable format. In the example below, we use the variable vs from the data set mtcars. Once again, we can label the output with a string as the optional third argument.\n\npredict_percent(mb1, mtcars$vs, \"Block 1\")\n\n\nAccuracy for Block 1: 56.25%\n\npredict_percent(mb2, mtcars$vs, \"Block 2\")\n\n\nAccuracy for Block 2: 84.38%"
  },
  {
    "objectID": "blog/HM878:_Helper_Functions/index.html#calculating-odds-ratios-with-or",
    "href": "blog/HM878:_Helper_Functions/index.html#calculating-odds-ratios-with-or",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "To calculate odds ratios for the models, simply pass the model through the function or.\n\nor(mb1)\n\n            Odds_Ratio  CI_Lower CI_Upper  p_values\n(Intercept)  0.7777778 0.3801366 1.558936 0.4806496\n\nor(mb2)\n\n              Odds_Ratio    CI_Lower     CI_Upper    p_values\n(Intercept) 10873.447296 95.35600799 6.507716e+07 0.002692584\ncyl             0.204474  0.04827075 4.455527e-01 0.001917098\n\n\nThe output results in a data frame with the odds ratios, confidence intervals, and p-values."
  },
  {
    "objectID": "blog/HM878:_Helper_Functions/index.html#upper-and-lower-fences-with-fences",
    "href": "blog/HM878:_Helper_Functions/index.html#upper-and-lower-fences-with-fences",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "If you want to revise and adjust your model, it can be helpful to limit outliers. To find upper and lower fences quickly, use the function fences. To do this, pass the continuous variable you are interested in examining through the function. Once again, use the format data$variable.\n\n#fences(iris$Sepal.Length)\n#fences(mtcars$cyl)$Upper\n#fences(mtcars$cyl)$Lower"
  },
  {
    "objectID": "blog/HM878:_Helper_Functions/index.html#comparing-model-results-with-compare_models",
    "href": "blog/HM878:_Helper_Functions/index.html#comparing-model-results-with-compare_models",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "Lastly, when you are putting together multiple models, it can be helpful to view them all at the same time, next to one another. This is particularly helpful if you have more than two models you are comparing. For this function, pass through however many models you have to compare, and optionally label each one, using a vector of strings for each model. To demonstrate, I will add on another model mb3 that will have another continuous independent variable.\n\nmb3 &lt;- glm(vs ~ cyl + wt, data = mtcars, family = \"binomial\")\n\ncompare_models(mb1, mb2, mb3, labels = c(\"Model 1 Block 1\", \"Model 1 Block 2\", \"Model Block 3\"))\n\n$`Model 1 Block 1`\n\nCall:  glm(formula = vs ~ 1, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)  \n    -0.2513  \n\nDegrees of Freedom: 31 Total (i.e. Null);  31 Residual\nNull Deviance:      43.86 \nResidual Deviance: 43.86    AIC: 45.86\n\n$`Model 1 Block 2`\n\nCall:  glm(formula = vs ~ cyl, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl  \n      9.294       -1.587  \n\nDegrees of Freedom: 31 Total (i.e. Null);  30 Residual\nNull Deviance:      43.86 \nResidual Deviance: 17.96    AIC: 21.96\n\n$`Model Block 3`\n\nCall:  glm(formula = vs ~ cyl + wt, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl           wt  \n     10.619       -2.931        2.100  \n\nDegrees of Freedom: 31 Total (i.e. Null);  29 Residual\nNull Deviance:      43.86 \nResidual Deviance: 15.55    AIC: 21.55"
  },
  {
    "objectID": "blog/HM878:_Helper_Functions/index.html#deviance_aic-pull-the-deviances-and-aics-from-model-summarys",
    "href": "blog/HM878:_Helper_Functions/index.html#deviance_aic-pull-the-deviances-and-aics-from-model-summarys",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "deviance_aic(mb1, mb2, mb3)\n\nmb1 \nResidual Deviance: 43.86 \nNull Deviance: 43.86 \nAIC: 45.86 \n\nmb2 \nResidual Deviance: 17.96 \nNull Deviance: 43.86 \nAIC: 21.96 \n\nmb3 \nResidual Deviance: 15.55 \nNull Deviance: 43.86 \nAIC: 21.55"
  },
  {
    "objectID": "blog/Intro_to_Bash_Scripting/index.html",
    "href": "blog/Intro_to_Bash_Scripting/index.html",
    "title": "Intro to Bash Scripting",
    "section": "",
    "text": "And I thought R gave me super powers…"
  },
  {
    "objectID": "blog/Intro_to_Bash_Scripting/index.html#introduction",
    "href": "blog/Intro_to_Bash_Scripting/index.html#introduction",
    "title": "Intro to Bash Scripting",
    "section": "Introduction",
    "text": "Introduction\nRecently, I’ve been having fun with Linux. I really didn’t know much about Linux or how it was different from MacOS or Windows. All I really knew was that very smart people use it and many computers depend on it!\nBy recommendation of a friend, I tried loading Pop!_OS on an old Macbook Air I had laying around. I quickly learned how lightweight many distributions of Linux are, and how customizable they can be.\nFor anyone familiar with Linux you know that, even when you are just setting up a computer with the OS, you have to start using a bit of the command line. I had used this before learning some helpful functions with git, but nothing has exposed me to the command line and Bash more than this endeavor.\nI have been inspired by this exposure and want to start learning more about the functionality of Bash. As a part of this, I wanted to try creating a Bash script of my own that I could implement into my current workflows."
  },
  {
    "objectID": "blog/Intro_to_Bash_Scripting/index.html#the-idea",
    "href": "blog/Intro_to_Bash_Scripting/index.html#the-idea",
    "title": "Intro to Bash Scripting",
    "section": "The Idea",
    "text": "The Idea\nI work primarily in R. And I love a good R Project. One of my usual habits for creating a project include adding sub folders and a starting script. I realized Bash is really good for doing this! So with some basic commands, I wanted to create a single executable script that makes a new R project, default sub folders, and a starting script."
  },
  {
    "objectID": "blog/Intro_to_Bash_Scripting/index.html#writing-the-script",
    "href": "blog/Intro_to_Bash_Scripting/index.html#writing-the-script",
    "title": "Intro to Bash Scripting",
    "section": "Writing the Script",
    "text": "Writing the Script\nFor the script I wanted several tasks accomplished:\n\nCreated an R project file within a contained folder\nSeveral sub-directories within that folder (data-raw, data, ref, output)\nA blank R script file\n\nTo start, I had the script ask for the name of the project. This was done by using echo to print the prompt, then read takes in the name of the project.\n\n\nCode\n#!/bin/bash\n\necho \"Please enter your project title: \"\n\nread name\n\n\nNext, I had to make the script navigate to the folder I want my projects in (for me, this is a folder on my desktop called ‘R’). Then, I had a directory made with sub-folders using mkdir -p. Here we use $name to use the variable stored as the name of the project. Within the {} are the names of the sub-folder I most commonly use. This could be anything you like though! Lastly, touch creates the blank R script.\n\n\nCode\ncd Desktop/R\n\nmkdir -p $name/{data-raw,data,ref,output}\n\ncd $name\n\ntouch script.R\n\n\nNext, we have an extra step that allows RStudio to open our new project properly. When I first tried this script out, I created a blank file with the .Rproj extension to set up the project. This immediately gave me problems when I tried to open the project. Specifically, I recall an issue with the version being unspecified.\nAfter a bit a research, I discovered that files with .Rproj are nothing really but a .txt file. I opened one of my existing R projects with a text editor and copied the contents exactly into the code chunk below. I wrote this text into the new R project. After some trial and error, I can confirm this method works!\n\n\nCode\n\necho -e 'Version: 1.0\n\nRestoreWorkspace: Default\nSaveWorkspace: Default\nAlwaysSaveHistory: Default\n\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 2\nEncoding: UTF-8\n\nRnwWeave: Sweave\nLaTex: pdfLaTeX' &gt;&gt; $name.Rproj\n\n\nThe last few lines of code echo some responses to the terminal and launch the new R project.\n\n\nCode\necho \"Project $name has been created.\"\necho \"It is stored in the R directory.\"\necho \"Opening project now...\"\n\nopen $name.Rproj"
  },
  {
    "objectID": "blog/Intro_to_Bash_Scripting/index.html#making-it-accessible",
    "href": "blog/Intro_to_Bash_Scripting/index.html#making-it-accessible",
    "title": "Intro to Bash Scripting",
    "section": "Making it Accessible",
    "text": "Making it Accessible\nFor me, personally, I like to be able to execute my scripts without worrying where I am in the terminal. Once my script was working properly, I moved it to the /usr/local/bin folder.\n\n\nCode\nmv setupr /usr/local/bin\n\n\nAnd that’s it! You can find the full script code below. I hope this is helpful! It was certainly useful to me to learn more about bash and make a useful script to help me set up projects."
  },
  {
    "objectID": "blog/Intro_to_Bash_Scripting/index.html#full-script-code",
    "href": "blog/Intro_to_Bash_Scripting/index.html#full-script-code",
    "title": "Intro to Bash Scripting",
    "section": "Full Script Code",
    "text": "Full Script Code\n\n\nCode\n#!/bin/bash\n\necho \"Please enter your project title: \"\n\nread name\n\ncd Desktop/R\n\nmkdir -p $name/{data-raw,data,ref,output}\n\ncd $name\n\ntouch script.R\n\necho -e 'Version: 1.0\n\nRestoreWorkspace: Default\nSaveWorkspace: Default\nAlwaysSaveHistory: Default\n\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 2\nEncoding: UTF-8\n\nRnwWeave: Sweave\nLaTex: pdfLaTeX' &gt;&gt; $name.Rproj\n\necho \"Project $name has been created.\"\necho \"It is stored in the R directory.\"\necho \"Opening project now...\"\n\nopen $name.Rproj"
  },
  {
    "objectID": "blog/opioid_plotting_practice/index.html",
    "href": "blog/opioid_plotting_practice/index.html",
    "title": "Opioid Plotting Practice",
    "section": "",
    "text": "Over the summer, I took a course on public health surveillance. As a culminating project, we were tasked with creating original data visualizations for a fact sheet on a topic of our choosing. I chose to examine local opioid overdose and mortality data for my project.\nThis is a topic that is near to me. The opioid crisis has impacted many communities across the country. At this point, the topic is well known to most people. Despite awareness, overdoses are still rising.\nIn the following post, I will demonstrate how easily you can spice up basic ggplot graphics. In particular we will look at:\n\na basic ggplot2 line chart\nggthemes we can use to make a more professional looking figure\nand a brief glimpse at plotly (because interactive graphs are so cool!)"
  },
  {
    "objectID": "blog/opioid_plotting_practice/index.html#introduction",
    "href": "blog/opioid_plotting_practice/index.html#introduction",
    "title": "Opioid Plotting Practice",
    "section": "",
    "text": "Over the summer, I took a course on public health surveillance. As a culminating project, we were tasked with creating original data visualizations for a fact sheet on a topic of our choosing. I chose to examine local opioid overdose and mortality data for my project.\nThis is a topic that is near to me. The opioid crisis has impacted many communities across the country. At this point, the topic is well known to most people. Despite awareness, overdoses are still rising.\nIn the following post, I will demonstrate how easily you can spice up basic ggplot graphics. In particular we will look at:\n\na basic ggplot2 line chart\nggthemes we can use to make a more professional looking figure\nand a brief glimpse at plotly (because interactive graphs are so cool!)"
  },
  {
    "objectID": "blog/opioid_plotting_practice/index.html#data-prep",
    "href": "blog/opioid_plotting_practice/index.html#data-prep",
    "title": "Opioid Plotting Practice",
    "section": "Data Prep",
    "text": "Data Prep\nTo begin, we will load in our libraries. Be sure to install them if you haven’t already.\n\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(readxl)\nlibrary(plotly)\n\nNext, we will read in our data using readxl. The data I am using comes from the Michigan Substance Use Disorder Data Repository (SUDDR). You can download the data yourself here. Keep in mind that the numbers we are working with in this example are raw counts of opioid overdose deaths by county, NOT rates. Therefore, we should not compare these counties against each other without considering population size differences. I’m interested in looking at changes over time with this dataset.\nBecause I’m focusing on the three counties in my area, I’m going to create a vector with the names of the capital area counties. This will make subsetting the data a little easier.\n\nopdeaths &lt;- read_xlsx(\"Opioid Overdose Deaths.xlsx\")\n\ncounties &lt;- c(\"Ingham\", \"Eaton\", \"Clinton\")"
  },
  {
    "objectID": "blog/opioid_plotting_practice/index.html#time-to-plot",
    "href": "blog/opioid_plotting_practice/index.html#time-to-plot",
    "title": "Opioid Plotting Practice",
    "section": "Time to Plot!",
    "text": "Time to Plot!\nFrom here, we can start our first plot. I will select my target counties using the filter() function that comes from the dplyr package. Be sure to specify which aesthetics you want to plot on the respective axes. Here we are putting the variable Year on the x-axis and Opioid Overdose Deaths on the y.\n\nopdeaths %&gt;%\n  filter(County %in% counties) %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line()\n\n\n\n\n\n\n\n\nOh no! What happened? We didn’t tell ggplot which lines we wanted to see. It is important that within the layer geom_line() we specify that we want to plot different lines based on our county variable. To do this, we simply add an aes() layer and assign color to County.\n\nopdeaths %&gt;%\n  filter(County %in% counties) %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(aes(color = County))\n\n\n\n\n\n\n\n\nThat looks a lot better! But we can do more. The lines look a bit skinny to me. I would like them to stand out more. It also might help to adjust the opacity of the lines. This can make points that cross over easier to read. To make these changes, we can specify linewidth and alpha in geom_line() outside of the aes() argument.\nI think it would be great to add points to our plot, too. Like the geom_line() layer, I want these to be large enough and overlap easily. I will pass through similar arguments in the geom_point() layer, also specifying the color.\n\nopdeaths %&gt;%\n  filter(County %in% counties)  %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(linewidth = 1, alpha = 0.8, aes(color = County)) +\n  geom_point(size = 2, alpha = 0.8, aes(color = County))\n\n\n\n\n\n\n\n\nLastly, I want to add labels and theme to really polish up our plot. This is surprisingly easy! To add our labels, we add another layer called labs(). Here we can add a proper title, and more accurate labels for the axes.\nAdding a theme is even easier. We can quickly add on a layer and pick a theme that we like. For my example, I’m using the fivethirtyeight theme that comes from ggthemes. Be sure to check out the other options available in this package.\nAfter our theme_fivethrityeight() layer, I’m adding a general theme() layer to specify that I want all my main title and axes titles to be shown. I am also adjusting the text size to make the title a bit more readable.\n\nopdeaths %&gt;%\n  filter(County %in% counties)  %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(linewidth = 1, alpha = 0.8, aes(color = County)) +\n  geom_point(size = 2, alpha = 0.8, aes(color = County)) +\n  labs(title = \"Opioid Overdose Deaths in Michigan's Capital Area \\nCounties, 1999 – 2020\",\n       x = \"Year\",\n       y = \"Number of Deaths\") +\n  theme_fivethirtyeight() +\n  theme(plot.title = element_text(size = 16),\n        plot.title.position = \"plot\",\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size = 11),\n        axis.title.y = element_text(vjust = +3),\n        axis.title.x = element_text(vjust = -0.75),\n        text = element_text(family = \"Georgia\"),\n        plot.margin = unit(c(1, 1, 1, 1), \"lines\"))\n\n\n\n\n\n\n\n\nAnd just like that, we have a very nice looking line chart!"
  },
  {
    "objectID": "blog/opioid_plotting_practice/index.html#a-glimpse-of-plotly",
    "href": "blog/opioid_plotting_practice/index.html#a-glimpse-of-plotly",
    "title": "Opioid Plotting Practice",
    "section": "A Glimpse of Plotly",
    "text": "A Glimpse of Plotly\nNext I want to briefly show how easy it is to take a basic ggplot figure and make it interactive with the amazing package plotly. If I save the figure we created before as an object, we can pass it through the function ggplotly(), and as a result, we get a chart where we can zoom in and hover over points to gain more insight. I will demonstrate this below.\n\np1 &lt;- opdeaths %&gt;%\n  filter(County %in% counties)  %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(linewidth = 1, alpha = 0.8, aes(color = County)) +\n  geom_point(size = 2, alpha = 0.8, aes(color = County)) +\n  labs(title = \"Opioid Overdose Deaths in Michigan's Capital Area Counties, 1999 – 2020\",\n       x = \"Year\",\n       y = \"Number of Deaths\") +\n  theme_fivethirtyeight() +\n  theme(plot.title = element_text(size = 16),\n        plot.title.position = \"plot\",\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size = 11),\n        axis.title.y = element_text(vjust = +3),\n        axis.title.x = element_text(vjust = -0.75),\n        text = element_text(family = \"Georgia\"),\n        plot.margin = unit(c(1, 1, 1, 1), \"lines\"))\n\nggplotly(p1)\n\n\n\n\n\nIt’s amazing how quickly you can produce interactive charts with R! The output from this function in an html widget. So it can easily be viewed on a website or a local html file. This makes it ideal for sharing graphics quickly among coworkers.\nFor my project, I created a few more graphics with the same color palette and arranged them on a pdf for easy distribution. If you want to view the finished product you can find that here.\nI hope you found this post helpful. Next time I want to focus more on plotly demonstrating its capabilities with spatial data analysis. Until next time!"
  },
  {
    "objectID": "blog/Introducing_the_PLACES_Package/index.html",
    "href": "blog/Introducing_the_PLACES_Package/index.html",
    "title": "Introducing the CDCPLACES Package",
    "section": "",
    "text": "This is part of the CDCPLACES blog series. To view the other posts in this series click here.\nThis post was updated on March 19, 2024 to reflect updates introduced in CDCPLACES 1.1.5."
  },
  {
    "objectID": "blog/Introducing_the_PLACES_Package/index.html#introduction",
    "href": "blog/Introducing_the_PLACES_Package/index.html#introduction",
    "title": "Introducing the CDCPLACES Package",
    "section": "Introduction",
    "text": "Introduction\nTo begin, we can install from CRAN, or from github, then load our packages.\n\n\nCode\n# Install from CRAN\n# install.packages(\"CDCPLACES)\n\n# Install from Github\n# devtools::install_github(\"brendensm/CDCPLACES\")\n\nlibrary(CDCPLACES)\nlibrary(dplyr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "blog/Introducing_the_PLACES_Package/index.html#function-get_dictionary",
    "href": "blog/Introducing_the_PLACES_Package/index.html#function-get_dictionary",
    "title": "Introducing the CDCPLACES Package",
    "section": "Function: get_dictionary",
    "text": "Function: get_dictionary\nOur first functions allows us to easily view what measures we can query, via ‘measureid’, along with a brief definition of each function. If we run get_dictionary, a data frame is returned. We can view the measures in a data frame in the R Studio with View(). This is the preferred method for exploring the available measures.\nFor our example here, I will print the names of the variables in this dataframe.\n\n\nCode\n# To open a viewer\n# get_dictionary() %&gt;% View()\n\nget_dictionary() %&gt;% names()\n\n\n [1] \"measureid\"                \"measure_full_name\"       \n [3] \"measure_short_name\"       \"categoryid\"              \n [5] \"category_name\"            \"places_release_2024\"     \n [7] \"measurename16_23\"         \"places_release_2023\"     \n [9] \"places_release_2022\"      \"places_release_2021\"     \n[11] \"places_release_2020\"      \"_500_cities_release_2019\"\n[13] \"_500_cities_release_2018\" \"_500_cities_release_2017\"\n[15] \"_500_cities_release_2016\" \"frequency_brfss_year\"    \n[17] \"shortname16_23\"          \n\n\nThis data frame is useful for several reasons. It lists the available measures for each year of the CDC PLACES data, along with the data each variable was collected, all in a single place. Remember to use the measureid when querying your data."
  },
  {
    "objectID": "blog/Introducing_the_PLACES_Package/index.html#function-get_places",
    "href": "blog/Introducing_the_PLACES_Package/index.html#function-get_places",
    "title": "Introducing the CDCPLACES Package",
    "section": "Function: get_places",
    "text": "Function: get_places\nThis function allows us to easily query data that we specify. In the example below, I will get the measure ACCESS2 (the current lack of health insurance among adults aged 18-64 years) for the state of Arizona. This function allows for multiple of these arguments.\n\n\nCode\naz_access &lt;- get_places(state = \"AZ\", \n                        measure = \"ACCESS2\") \nhead(az_access)\n\n\n  year stateabbr statedesc locationname datasource   category\n1 2022        AZ   Arizona         Yuma      BRFSS Prevention\n2 2022        AZ   Arizona       La Paz      BRFSS Prevention\n3 2022        AZ   Arizona      Yavapai      BRFSS Prevention\n4 2022        AZ   Arizona      Yavapai      BRFSS Prevention\n5 2022        AZ   Arizona       Graham      BRFSS Prevention\n6 2022        AZ   Arizona       La Paz      BRFSS Prevention\n                                                         measure\n1 Current lack of health insurance among adults aged 18-64 years\n2 Current lack of health insurance among adults aged 18-64 years\n3 Current lack of health insurance among adults aged 18-64 years\n4 Current lack of health insurance among adults aged 18-64 years\n5 Current lack of health insurance among adults aged 18-64 years\n6 Current lack of health insurance among adults aged 18-64 years\n  data_value_unit         data_value_type data_value low_confidence_limit\n1               %        Crude prevalence       15.6                 14.2\n2               %        Crude prevalence        9.2                  8.3\n3               % Age-adjusted prevalence       10.9                  9.8\n4               %        Crude prevalence        6.5                  5.7\n5               % Age-adjusted prevalence       16.2                 14.4\n6               % Age-adjusted prevalence       20.4                 18.5\n  high_confidence_limit totalpopulation totalpop18plus locationid categoryid\n1                  17.1          207842         155973      04027    PREVENT\n2                  10.2           16506          13903      04012    PREVENT\n3                  12.2          246191         208516      04025    PREVENT\n4                   7.2          246191         208516      04025    PREVENT\n5                  18.0           38779          28375      04009    PREVENT\n6                  22.3           16506          13903      04012    PREVENT\n  measureid datavaluetypeid short_question_text\n1   ACCESS2          CrdPrv    Health Insurance\n2   ACCESS2          CrdPrv    Health Insurance\n3   ACCESS2       AgeAdjPrv    Health Insurance\n4   ACCESS2          CrdPrv    Health Insurance\n5   ACCESS2       AgeAdjPrv    Health Insurance\n6   ACCESS2       AgeAdjPrv    Health Insurance\n                                 geolocation\n1 Point, -113.905997385394, 32.7694427722845\n2  Point, -113.98153747073, 33.7292571142703\n3 Point, -112.553640853115, 34.5996977529402\n4 Point, -112.553640853115, 34.5996977529402\n5 Point, -109.887402691851, 32.9327553402921\n6  Point, -113.98153747073, 33.7292571142703\n\n\nIt is also worth noting that by default geography specifying geography is set to “county”. If instead we want to examine census tracts, we could specify the argument. Likewise, release is set to “2023” by default.\nThe argument county can be used to filter results to specific counties. This is extremely useful for examining census level data for specific areas of states. Additionally, geometry can be added to include a shapefile in the query. For further examples of plotting with shapefiles, see this dedicated blog post.\n\n\nCode\ncap_counties &lt;- get_places(geography = \"census\",\n                           state = \"MI\",\n                           measure = \"ACCESS2\",\n                           county = c(\"Ingham\", \"Eaton\", \"Clinton\"),\n                           geometry = TRUE)"
  },
  {
    "objectID": "blog/Introducing_the_PLACES_Package/index.html#use-case",
    "href": "blog/Introducing_the_PLACES_Package/index.html#use-case",
    "title": "Introducing the CDCPLACES Package",
    "section": "Use Case",
    "text": "Use Case\nFrom here, we can start to have fun. It is fairly straight forward to begin exploring data. Here I will first filter out the data so that I can plot the age adjusted rates of lack of health insurance in Arizona.\nNotice that the data provide you with confidence limits, so I have chosen to plot them here with error bars.\n\n\nCode\naz_access %&gt;%\n  filter(datavaluetypeid == \"AgeAdjPrv\") %&gt;%\n  ggplot(aes(data_value, reorder(locationname, data_value))) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(xmin = low_confidence_limit, xmax = high_confidence_limit)) +\n  labs(title = \"Lack of health insurance among adults aged 18-64 years In Arizona Counties\",\n       y = \"\", x = \"Percent\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\n\n\n\n\nYou can also extend this to multiple states to compare. You can easily query two (or more) state names, and plot them. Arizona seems to have a couple of counties that have a much higher rate compared to others.\n\n\nCode\n# multi state comparison\ntwo &lt;- get_places(state = c(\"AZ\", \"NV\"), \n                  measure = \"ACCESS2\")\n\ntwo %&gt;%\n  filter(datavaluetypeid == \"AgeAdjPrv\") %&gt;%\n  ggplot(aes(data_value, reorder(locationname, data_value), color = stateabbr)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(xmin = low_confidence_limit, xmax = high_confidence_limit)) +\n  labs(title = \n         \"Lack of health insurance among adults aged 18-64 years In Arizona and Nevada\",\n       y = \"Counties\", x = \"Percent\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\n\n\n\n\nWe can go even further by comparing more states in the region. Here I have taken the average rate by state to easily compare. Texas appears to be far above the average.\n\n\nCode\nmulti &lt;- get_places(state = c(\"AZ\", \"NV\", \"NM\", \"TX\", \"CA\"), measure = \"ACCESS2\") %&gt;%\n  filter(datavaluetypeid == \"AgeAdjPrv\") %&gt;%\n  summarise(.by = \"stateabbr\", mean_val = mean(data_value), mean_low = mean(low_confidence_limit), mean_high = mean(high_confidence_limit))\n\nmulti %&gt;%\n  ggplot(aes(mean_val, reorder(stateabbr, mean_val), color = stateabbr)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(xmin = mean_low, xmax = mean_high)) +\n  labs(title = \"Mean lack of health insurance among adults aged 18-64 years In Southwest States\",\n       y = \"\", x = \"Percent\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "blog/shiny_map_filter/index.html#example-data",
    "href": "blog/shiny_map_filter/index.html#example-data",
    "title": "Interactive Map Filter in Shiny",
    "section": "Example Data",
    "text": "Example Data\nThe data I will be using for this example can be queried using the CDCPLACES package (see more on GitHub). I will take a sample of county data from the State of Ohio. Here I am filtering only the age-adjusted rates and the measure “ACCESS2” which is the percentage of the population aged 18-64 that lack health insurance. I will also set the CRS for the data using sf::st_transform to avoid warnings when the data is queried.\n\n\nCode\nlibrary(leaflet)\nlibrary(shiny)\nlibrary(CDCPLACES)\nlibrary(dplyr)\n\nohio &lt;- get_places(state = \"OH\", measure = \"ACCESS2\", geometry = TRUE) |&gt;\n  filter(datavaluetypeid == \"AgeAdjPrv\") |&gt;\n  select(year, stateabbr, locationname, measure, data_value, geometry) |&gt; \n  sf::st_transform(crs = 4326)"
  },
  {
    "objectID": "blog/shiny_map_filter/index.html#ui",
    "href": "blog/shiny_map_filter/index.html#ui",
    "title": "Interactive Map Filter in Shiny",
    "section": "UI",
    "text": "UI\nNext, we can get into the UI side of our demo app. This is fairly straightforward. We initiate a fluid page, a title, and a sidebar layout. The sidebar has our leaflet map as a filter. In the main panel, we will output a data table.\nI have added a tags$head function to add some custom CSS to the app. This is an optional step, but these two options make the panel transparent, which I think adds a lot to the look and feel of the app.\n\n\nCode\nui &lt;- fluidPage(\n\n  tags$head(\n    tags$style(HTML(\".leaflet-container { background: none; } \n                    .well { background: none;}\"))\n  ),\n\n    titlePanel(\"My Demo App\"),\n\n    sidebarLayout(\n        sidebarPanel(\n            leafletOutput(\"mapfilter\", height = 250)\n        ),\n\n        mainPanel(\n           DT::DTOutput(\"table\")\n        )\n    )\n)"
  },
  {
    "objectID": "blog/shiny_map_filter/index.html#server",
    "href": "blog/shiny_map_filter/index.html#server",
    "title": "Interactive Map Filter in Shiny",
    "section": "Server",
    "text": "Server\nNow we can specify the logic of the server to get the result we want. To start we can initialize a few reactive values. This will allow us to update our filtered data and what is displayed on the map. selected_counties will correspond to what is highlighted on the map when we click, filtered_data will be the data frame that is displayed on the main table output.\n\n\nCode\nserver &lt;- function(input, output, session) {\n      # Initialize reactive values\n     rv &lt;- reactiveValues(selected_counties = NULL,\n                        filtered_data = ohio) # Initialize reactive values\n}\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe following code chunks are wrapped within the server function call.\n\n\n\nOutputs\nThis section will briefly describe the functions for our outputs: the map filter and the table.\n\nTable\nThis chunk defines the output corresponding to the id table, and renders a datatable. We input the reactive value of our filtered data with rv$filtered_data, remove the geometry with sf::st_set_geometry(NULL), and send it to DT::datatable() for a simple table display.\n\n\nCode\n  output$table &lt;- DT::renderDT({\n\n      rv$filtered_data |&gt;\n        sf::st_set_geometry(NULL) |&gt;\n        DT::datatable()\n\n    })\n\n\n\n\nMap\nFor our map, we follow similar steps. We use the base data frame ohio to create our map. Future steps will show how we update this with our click behavior. highlightOptions here defines how the map reacts to hovering over polygons. It will fill the county the mouse is hovering over.\n\n\nCode\n  output$mapfilter &lt;- renderLeaflet({ # rendering the filter map\n\n    leaflet(ohio, # initializing the map\n            options = leafletOptions( \n              zoomControl = FALSE,\n              dragging = FALSE,\n              minZoom = 6,\n              maxZoom = 6\n            )) |&gt;  # then add polygons\n    addPolygons(layerId = ~locationname,\n                  label = ~locationname,\n                  col = \"black\",\n                  fillColor = \"steelblue\",\n                  weight = 2,\n                  fillOpacity = .1,\n                  highlight = highlightOptions(\n                    fillOpacity = 1,\n                    bringToFront = TRUE\n                  ))\n\n  })\n\n\n\n\n\nClick Behavior\nNext, we will define our behavior when the map is clicked. We can break this into two parts, updating the data that is fed into the output table, and changing the display of the input map.\nThe code chunk below runs when a polygon on our map is clicked. That is the logic of the observeEvent function and its argument input$mapfilter_shape_click. Because our actions all relate to this event, we can wrap all of our code in it. The other step here is to store the input in an object called click.\n\n\nCode\n  observeEvent(input$mapfilter_shape_click, { \n    # this is the logic behind the \"click\" of the map.\n    \n        click &lt;- input$mapfilter_shape_click\n\n  })\n\n\nIf we were to simply print(click) we would see the following output upon an initial click and a second click of the same polygon:\n\nInitial ClickSecond Click\n\n\n\n\n\n\n\n\n\nThis will inform how we use the input to update our data and map.\nWe can use a set of if and else statements to store data from click in our reactive values.\n\nThe first statement checks to see if the current click$id exists in rv$selected_counties. If it does, it will remove it from the vector.\nThe next statement checks to see if the click$id is equal to “selected”. Recall that this occurs when the same polygon is selected twice in a row. If this condition is met, we will filter rv$selected_counties by removing the last value in the length of the vector.\nLastly, if the other two conditions are not met, the new and unique click$id is added to rv$selected_counties.\n\n\n\nCode\n      if (click$id %in% rv$selected_counties) {\n        # If selected, remove it\n        rv$selected_counties &lt;- \n          rv$selected_counties[rv$selected_counties != click$id]\n        \n      } else if(click$id == \"selected\"){ \n        # when a county is clicked again it is removed\n\n        rv$selected_counties &lt;- \n          rv$selected_counties[rv$selected_counties !=\n                                 tail(rv$selected_counties, n = 1)]\n\n      }else { # If not selected, add it\n        rv$selected_counties &lt;- c(rv$selected_counties, click$id)\n        \n      }\n\n\nThen we have an update to our map. We can accomplish this with leafletProxy. We will simply add an ifelse function to the argument fillOpacity. This ensures that counties present in our rv$selected_counties will have the proper fill.\n\n\nCode\n      leafletProxy(\"mapfilter\", session) |&gt;\n        addPolygons(data = ohio,\n                    layerId = ~locationname,\n                    label = ~locationname,\n                    fillColor = \"steelblue\", \n                    col = \"black\",\n                    weight = 2,\n                    fillOpacity = ifelse(\n                      ohio$locationname %in% rv$selected_counties, 1, 0.1\n                      ),\n                    highlight = highlightOptions(\n                      fillOpacity = 1,\n                      bringToFront = TRUE)\n                    )\n\n\nEach of these pieces all fit into our observeEvent function for a click on the map, so in our consolidated code it will look like this:\n\n\nCode\n  observeEvent(input$mapfilter_shape_click, { \n\n    click &lt;- input$mapfilter_shape_click\n\n      if (click$id %in% rv$selected_counties) {\n        rv$selected_counties &lt;- \n          rv$selected_counties[rv$selected_counties != click$id]\n      } else if(click$id == \"selected\"){ \n        rv$selected_counties &lt;- \n          rv$selected_counties[rv$selected_counties !=\n                                 tail(rv$selected_counties, n = 1)]\n\n      }else {\n        rv$selected_counties &lt;- c(rv$selected_counties, click$id)\n      }\n\n      leafletProxy(\"mapfilter\", session) |&gt;\n        addPolygons(data = ohio,\n                    layerId = ~locationname,\n                    label = ~locationname,\n                    fillColor = \"steelblue\", \n                    col = \"black\",\n                    weight = 2,\n                    fillOpacity = ifelse(\n                      ohio$locationname %in% rv$selected_counties, 1, 0.1\n                      ),\n                    highlight = highlightOptions(\n                      fillOpacity = 1,\n                      bringToFront = TRUE)\n                    )\n\n  })\n\n\nLastly, we have one more if else statement in our server. The following code chunk takes the reactive value rv$selected_counties and updates rv$filtered_data which we use to render the table. This logic will cause the data to reset when we have no selected counties (all the shapes are “unclicked”).\n\n\nCode\n    observe({ # Update table filtering based on selected counties\n      if (!is.null(rv$selected_counties) && \n          length(rv$selected_counties) &gt; 0) { \n        # Check if any counties are selected\n        rv$filtered_data &lt;- ohio |&gt;\n                        filter(locationname %in% rv$selected_counties)\n      } else {\n        rv$filtered_data &lt;- ohio\n      }\n    })"
  },
  {
    "objectID": "blog/shiny_map_filter/index.html#full-code",
    "href": "blog/shiny_map_filter/index.html#full-code",
    "title": "Interactive Map Filter in Shiny",
    "section": "Full Code",
    "text": "Full Code\n\n\nCode\nlibrary(leaflet)\nlibrary(shiny)\nlibrary(tigris)\nlibrary(CDCPLACES)\nlibrary(dplyr)\nlibrary(htmltools)\n\nohio &lt;- get_places(state = \"OH\", measure = \"ACCESS2\", geometry = TRUE) |&gt;\n  filter(datavaluetypeid == \"AgeAdjPrv\") |&gt;\n  select(year, stateabbr, locationname, measure, data_value, geometry) |&gt;\n  sf::st_transform(crs = 4326)\n\n\nui &lt;- fluidPage(\n\n  tags$head(\n    tags$style(HTML(\".leaflet-container { background: none; } .well { background: none;}\"))\n  ),\n\n    # Application title\n    titlePanel(\"My Demo App\"),\n\n    # Sidebar with a slider input for number of bins\n    sidebarLayout(\n        sidebarPanel(\n            leafletOutput(\"mapfilter\", height = 250)\n        ),\n\n        # Show a plot of the generated distribution\n        mainPanel(\n           DT::DTOutput(\"table\")\n        )\n    )\n)\n\n# Define server logic required to draw a histogram\nserver &lt;- function(input, output, session) {\n\n   rv &lt;- reactiveValues(selected_counties = NULL,\n                        filtered_data = ohio) # Initialize reactive value for selected counties\n\n  observeEvent(input$mapfilter_shape_click, { # this is the logic behind the \"click\" of the map.\n\n    click &lt;- input$mapfilter_shape_click\n\n    ########## map behavior ################\n      # If a county is clicked\n\n      if (click$id %in% rv$selected_counties) {\n        # If selected, remove it\n        rv$selected_counties &lt;- rv$selected_counties[rv$selected_counties != click$id]\n      } else if(click$id == \"selected\"){ # when a county is clicked again it is removed\n\n        rv$selected_counties &lt;- rv$selected_counties[rv$selected_counties != tail(rv$selected_counties, n = 1)]\n\n      }else {\n        # If not selected, add it\n        rv$selected_counties &lt;- c(rv$selected_counties, click$id)\n      }\n\n      leafletProxy(\"mapfilter\", session) |&gt;\n        addPolygons(data = ohio,\n                    layerId = ~locationname,\n                    label = ~locationname,\n                    fillColor = \"steelblue\", # Change fill color based on selection\n                    col = \"black\",\n                    weight = 2,\n                    fillOpacity = ifelse(ohio$locationname %in% rv$selected_counties, 1, 0.1),\n                    highlight = highlightOptions(\n                      fillOpacity = 1,\n                      bringToFront = TRUE)\n                    )\n\n\n  })\n\n  output$mapfilter &lt;- renderLeaflet({ # rendering the filter map\n\n    leaflet(ohio,\n            options = leafletOptions( # initializing the map\n              zoomControl = FALSE,\n              dragging = FALSE,\n              minZoom = 6,\n              maxZoom = 6\n            )) %&gt;%\n      addPolygons(layerId = ~locationname,\n                  label = ~locationname,\n                  #   fillColor = \"black\",\n                  col = \"black\",\n                  fillColor = \"steelblue\",\n                  weight = 2,\n                  fillOpacity = .1,\n                  highlight = highlightOptions(\n                    fillOpacity = 1,\n                    bringToFront = TRUE\n                  ))\n\n  })\n\n    output$table &lt;- DT::renderDT({\n\n      rv$filtered_data |&gt;\n        sf::st_set_geometry(NULL) |&gt;\n        DT::datatable()\n\n    })\n\n    observe({ # Update table filtering based on selected counties\n      if (!is.null(rv$selected_counties) & length(rv$selected_counties) &gt; 0) { # Check if any counties are selected\n        rv$filtered_data &lt;- ohio |&gt;\n                        filter(locationname %in% rv$selected_counties)\n      } else {\n        rv$filtered_data &lt;- ohio\n      }\n    })\n\n}\n\n# Run the application\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "blog/shiny_map_filter/index.html#introduction",
    "href": "blog/shiny_map_filter/index.html#introduction",
    "title": "Interactive Map Filter in Shiny",
    "section": "",
    "text": "Recently, I participated in Posit’s 2024 Table Contest. For my submission, which you can view here, I included a leaflet map that acts as a filter in Shiny. This is a cool, dashboard-like feature similar to what you might find in Power BI. I recreated this effect and learned a bit through the process.\nI first saw this wonderful blog post by Nathan Day but realized didn’t exactly match the feel I was going for. I adapted his code and added my own preferences (specifically allowing the input map to select multiple polygons and resetting the output table when polygons were “unclicked”). I wanted to share a basic example for others who might want to try this out!"
  },
  {
    "objectID": "blog/shiny_map_filter/index.html",
    "href": "blog/shiny_map_filter/index.html",
    "title": "Interactive Map Filter in Shiny",
    "section": "",
    "text": "Recently, I participated in Posit’s 2024 Table Contest. For my submission, which you can view here, I included a leaflet map that acts as a filter in Shiny. This is a cool, dashboard-like feature similar to what you might find in Power BI. I recreated this effect and learned a bit through the process.\nI first saw this wonderful blog post by Nathan Day but realized didn’t exactly match the feel I was going for. I adapted his code and added my own preferences (specifically allowing the input map to select multiple polygons and resetting the output table when polygons were “unclicked”). I wanted to share a basic example for others who might want to try this out!"
  },
  {
    "objectID": "blog/shiny_map_filter/index.html#conclusion",
    "href": "blog/shiny_map_filter/index.html#conclusion",
    "title": "Interactive Map Filter in Shiny",
    "section": "Conclusion",
    "text": "Conclusion\nThis post was an excellent way for me to revisit my code and share an interesting and unique Shiny feature. In this process I ended up eliminating quite a few redundancies in my original code and reinforced some of the concepts of reactivity showcased here.\nI hope you find this tutorial useful. If you put it to use, please share it with me! I would love to see the work you come up with.\nSee the full consolidated example code below."
  },
  {
    "objectID": "blog/CDCPLACES_1.1.8/index.html",
    "href": "blog/CDCPLACES_1.1.8/index.html",
    "title": "CDCPLACES 1.1.8: 2024 Release",
    "section": "",
    "text": "This is part of the CDCPLACES blog series. To view the other posts in this series click here."
  },
  {
    "objectID": "blog/CDCPLACES_1.1.8/index.html#introduction",
    "href": "blog/CDCPLACES_1.1.8/index.html#introduction",
    "title": "CDCPLACES 1.1.8: 2024 Release",
    "section": "Introduction",
    "text": "Introduction\nThis brief blog post explains the new additions to CDCPLACES 1.1.8. This update provides a few new features:\n\nUpdated 2024 release data, including several new measures under the health-related social needs category\nTwo new arguments to help filter your data, cat and age_adjust\nThe ability to query Zip Code Tabulation Areas (ZCTAs)\nImproved functionality when querying counties with the same name across different states\n\nIn addition to these features, CDCPLACES now depends on yyjsonr instead of jsonlite. Originally, the get_places function included a step to clean the returned geolocation variable (essentially a centroid of the geography queried). This step was removed as it was computationally intensive on larger queries and unncessary given the support for shapefiles with the geometry argument. These changes drastically improve the speed of the package.\nTo begin, we will load the required packages.\n\n\nCode\n# install.packages(\"CDCPLACES\")\n# install.packges(\"tidyverse)\n\nlibrary(CDCPLACES)\nlibrary(tidyverse)"
  },
  {
    "objectID": "blog/CDCPLACES_1.1.8/index.html#new-measures",
    "href": "blog/CDCPLACES_1.1.8/index.html#new-measures",
    "title": "CDCPLACES 1.1.8: 2024 Release",
    "section": "New Measures",
    "text": "New Measures\nWith the 2024 release of the PLACES data, the default option for the release argument in get_places has been updated to “2024”. You can find all the details of these updated data in the release notes.\nAn exciting addition to the PLACES data are the new health-related social needs variables. These include: social isolation, food stamps, food insecurity, housing insecurity, utility services threat, transportation barriers, and lack of social and emotional support. These measures are only available in 39 states and the District of Columbia (DC).\n\nYou can view these measures by calling get_dictionary. The category ID for these new measures is “SOCLNEED”.\n\n\nCode\nget_dictionary() |&gt; filter(categoryid == \"SOCLNEED\") |&gt; as_tibble()\n\n\n# A tibble: 7 × 17\n  measureid   measure_full_name      measure_short_name categoryid category_name\n  &lt;chr&gt;       &lt;chr&gt;                  &lt;chr&gt;              &lt;chr&gt;      &lt;chr&gt;        \n1 ISOLATION   Feeling socially isol… Social Isolation   SOCLNEED   Health-Relat…\n2 FOODSTAMP   Received food stamps … Food Stamps        SOCLNEED   Health-Relat…\n3 FOODINSECU  Food insecurity in th… Food Insecurity    SOCLNEED   Health-Relat…\n4 HOUSINSECU  Housing insecurity in… Housing Insecurity SOCLNEED   Health-Relat…\n5 SHUTUTILITY Utility services thre… Utilities Service… SOCLNEED   Health-Relat…\n6 LACKTRPT    Lack of reliable tran… Transportation Ba… SOCLNEED   Health-Relat…\n7 EMOTIONSPT  Lack of social and em… Lack of Social/Em… SOCLNEED   Health-Relat…\n# ℹ 12 more variables: places_release_2024 &lt;chr&gt;, measurename16_23 &lt;chr&gt;,\n#   places_release_2023 &lt;chr&gt;, places_release_2022 &lt;chr&gt;,\n#   places_release_2021 &lt;chr&gt;, places_release_2020 &lt;chr&gt;,\n#   `_500_cities_release_2019` &lt;chr&gt;, `_500_cities_release_2018` &lt;chr&gt;,\n#   `_500_cities_release_2017` &lt;chr&gt;, `_500_cities_release_2016` &lt;chr&gt;,\n#   frequency_brfss_year &lt;chr&gt;, shortname16_23 &lt;chr&gt;"
  },
  {
    "objectID": "blog/CDCPLACES_1.1.8/index.html#new-arguments-cat-and-age_adjust",
    "href": "blog/CDCPLACES_1.1.8/index.html#new-arguments-cat-and-age_adjust",
    "title": "CDCPLACES 1.1.8: 2024 Release",
    "section": "New Arguments: cat and age_adjust",
    "text": "New Arguments: cat and age_adjust\nSome minor quality of life improvements are introduced with the new arguments cat and age_adjust.\nWe can filter our results to returns a set of measures by category ID.\n\n\nCode\nget_places(geography = \"county\",\n           state = \"AL\", \n           cat = \"SOCLNEED\") |&gt; as_tibble()\n\n\n# A tibble: 938 × 20\n   year  stateabbr statedesc locationname datasource category            measure\n   &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;               &lt;chr&gt;  \n 1 2022  AL        Alabama   Escambia     BRFSS      Health-Related Soc… Food i…\n 2 2022  AL        Alabama   Greene       BRFSS      Health-Related Soc… Utilit…\n 3 2022  AL        Alabama   Morgan       BRFSS      Health-Related Soc… Receiv…\n 4 2022  AL        Alabama   Franklin     BRFSS      Health-Related Soc… Feelin…\n 5 2022  AL        Alabama   Dale         BRFSS      Health-Related Soc… Food i…\n 6 2022  AL        Alabama   Crenshaw     BRFSS      Health-Related Soc… Food i…\n 7 2022  AL        Alabama   Greene       BRFSS      Health-Related Soc… Feelin…\n 8 2022  AL        Alabama   Tuscaloosa   BRFSS      Health-Related Soc… Housin…\n 9 2022  AL        Alabama   Clay         BRFSS      Health-Related Soc… Utilit…\n10 2022  AL        Alabama   Clay         BRFSS      Health-Related Soc… Housin…\n# ℹ 928 more rows\n# ℹ 13 more variables: data_value_unit &lt;chr&gt;, data_value_type &lt;chr&gt;,\n#   data_value &lt;dbl&gt;, low_confidence_limit &lt;dbl&gt;, high_confidence_limit &lt;dbl&gt;,\n#   totalpopulation &lt;chr&gt;, totalpop18plus &lt;chr&gt;, locationid &lt;chr&gt;,\n#   categoryid &lt;chr&gt;, measureid &lt;chr&gt;, datavaluetypeid &lt;chr&gt;,\n#   short_question_text &lt;chr&gt;, geolocation &lt;list&gt;\n\n\nIf a measure is provided as well as a category, the category will override it. A message is displayed in the console noting this when it occurs.\nTo return only the age-adjusted prevalence rates, we can set the argument age_adjust to TRUE. Age-adjusted rates are only available at the county level.\n\n\nCode\nget_places(geography = \"county\",\n           state = \"AL\", \n           cat = \"SOCLNEED\", \n           age_adjust = TRUE) |&gt; as_tibble()\n\n\n# A tibble: 469 × 20\n   year  stateabbr statedesc locationname datasource category            measure\n   &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;               &lt;chr&gt;  \n 1 2022  AL        Alabama   Choctaw      BRFSS      Health-Related Soc… Feelin…\n 2 2022  AL        Alabama   Escambia     BRFSS      Health-Related Soc… Food i…\n 3 2022  AL        Alabama   Morgan       BRFSS      Health-Related Soc… Receiv…\n 4 2022  AL        Alabama   Dale         BRFSS      Health-Related Soc… Food i…\n 5 2022  AL        Alabama   Etowah       BRFSS      Health-Related Soc… Lack o…\n 6 2022  AL        Alabama   Wilcox       BRFSS      Health-Related Soc… Housin…\n 7 2022  AL        Alabama   Limestone    BRFSS      Health-Related Soc… Food i…\n 8 2022  AL        Alabama   Coosa        BRFSS      Health-Related Soc… Food i…\n 9 2022  AL        Alabama   Crenshaw     BRFSS      Health-Related Soc… Housin…\n10 2022  AL        Alabama   Cleburne     BRFSS      Health-Related Soc… Lack o…\n# ℹ 459 more rows\n# ℹ 13 more variables: data_value_unit &lt;chr&gt;, data_value_type &lt;chr&gt;,\n#   data_value &lt;dbl&gt;, low_confidence_limit &lt;dbl&gt;, high_confidence_limit &lt;dbl&gt;,\n#   totalpopulation &lt;chr&gt;, totalpop18plus &lt;chr&gt;, locationid &lt;chr&gt;,\n#   categoryid &lt;chr&gt;, measureid &lt;chr&gt;, datavaluetypeid &lt;chr&gt;,\n#   short_question_text &lt;chr&gt;, geolocation &lt;list&gt;"
  },
  {
    "objectID": "blog/CDCPLACES_1.1.8/index.html#query-zctas",
    "href": "blog/CDCPLACES_1.1.8/index.html#query-zctas",
    "title": "CDCPLACES 1.1.8: 2024 Release",
    "section": "Query ZCTAs",
    "text": "Query ZCTAs\nA new option has been added to query ZCTAs. To do this, simply set the geography argument equal to “zcta”.\n\n\nCode\nw_sleep &lt;- get_places(geography = \"zcta\", \n                      state = \"MI\", \n                      measure = \"SLEEP\",\n                      county = \"Barry\", \n                      geometry = TRUE)\n\n\nLike other geographies, we can query shapefiles in the same call and easily plot the output:\n\n\nCode\nw_sleep |&gt; \n  ggplot(aes(fill = data_value, label = locationname)) +\n  geom_sf() +\n  geom_sf_label(fill = \"white\") +\n  theme_void() +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  labs(title = \"% Sleeping less than 7 hours among adults aged &gt;=18 years\",\n       subtitle = \"In Barry County, Michigan ZCTAs\")"
  },
  {
    "objectID": "blog/CDCPLACES_1.1.8/index.html#handle-overlapping-counties",
    "href": "blog/CDCPLACES_1.1.8/index.html#handle-overlapping-counties",
    "title": "CDCPLACES 1.1.8: 2024 Release",
    "section": "Handle Overlapping Counties",
    "text": "Handle Overlapping Counties\nThis update provides the ability to query ZCTAs in different states and counties at the same time. This can raise issues when we want to look at counties that have the same name in multiple states.\nConsider the following example. If we were interested in looking at dental health access around the Michigan/Ohio border and the Toledo area, we might query Monroe and Lucas Counties. We would set the query up like this:\n\n\nCode\ntol &lt;- get_places(geography = \"zcta\",\n                  state = c(\"MI\", \"OH\"),\n                  measure = \"DENTAL\",\n                  county = c(\"LUCAS\", \"MONROE\"),\n                  geometry = TRUE)\n\n\nThe main issue here is that Ohio also has a Monroe County. CDCPLACES will automatically check to see if your returned data contains these overlaps. You will see output in the console that looks like this:\n\nThe package will prompt you if you want to include these overlaps. After asking this, it will ask you to specify the counties you wish to exclude from your returned data:\n\nIf you choose not to make any exclusions you will get the full data with overlaps. In this example, I excluded Ohio’s Monroe County because it is far from the area of interest.1\nWe can now plot our returned data:\n\n\nCode\ntol |&gt; \n     ggplot(aes(fill = data_value)) +\n     geom_sf() +\n     theme_void() +\n     scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n     labs(title = \"Visited a dentist or dental clinic in the past year among adults aged &gt;=18 years\", \n          subtitle = \"In Monroe County, Michigan and Lucas County, Ohio ZCTAs\")"
  },
  {
    "objectID": "blog/CDCPLACES_1.1.8/index.html#footnotes",
    "href": "blog/CDCPLACES_1.1.8/index.html#footnotes",
    "title": "CDCPLACES 1.1.8: 2024 Release",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt is crucial to mention that using this function in an R Markdown or Quarto document will override this user input. Full data with overlaps will be returned when knitting/rendering the document. If this is your specific use case, it is recommended to disregard this functionality and filter your data once it is returned.↩︎"
  }
]