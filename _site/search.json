[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Brenden Smith",
    "section": "",
    "text": "Hi, I’m Brenden. I am an MPH candidate with interests in health equity, harm reduction, and community engagement. I am a data analyst, community researcher, and R enthusiast.\nIf you would like to see some of my current and past work, you can visit my portfolio page or check out my blog."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome to my Blog",
    "section": "",
    "text": "This is hard for me to do! I’ve been wanting to start blogging for some time now. This whole website is only possible because of the wonderful blog posts by Bea Milz and Alber Rapp. A huge huge thank you to them both. Their posts demonstrate how easy it is to get up and running with a Quarto blog!\nInspired by their words, there is no better time to start writing. So consider this a first introduction. I am setting the intention to post monthly to this blog."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\n\n\n\n\nFeb 6, 2024\n\n\nShapefiles in CDCPLACES 1.1.5\n\n\n\n\nJan 10, 2024\n\n\nIntroducing the CDCPLACES Package\n\n\n\n\nNov 15, 2023\n\n\nIntro to Bash Scripting\n\n\n\n\nOct 24, 2023\n\n\nSurvival Analysis in R\n\n\n\n\nOct 12, 2023\n\n\nHM878: Helper Functions\n\n\n\n\nMar 1, 2023\n\n\nTwitter Bots\n\n\n\n\nOct 11, 2022\n\n\nMichigan COVID-19 County Maps\n\n\n\n\nOct 9, 2022\n\n\nOpioid Plotting Practice\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html#header-two",
    "href": "posts/welcome/index.html#header-two",
    "title": "Welcome",
    "section": "Header two",
    "text": "Header two\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/test post/index.html",
    "href": "posts/test post/index.html",
    "title": "test post",
    "section": "",
    "text": "This is my test."
  },
  {
    "objectID": "posts/welcome/index.html#who-am-i",
    "href": "posts/welcome/index.html#who-am-i",
    "title": "Welcome to my Blog (-:",
    "section": "Who am I?",
    "text": "Who am I?\nMy name is Brenden Smith. At this point, I am a little over a year into my graduate studies. I attend Michigan State University and I am working towards my Master in Public Health."
  },
  {
    "objectID": "posts/welcome/index.html#what-will-i-post",
    "href": "posts/welcome/index.html#what-will-i-post",
    "title": "Welcome to my Blog",
    "section": "What will I post?",
    "text": "What will I post?\nTo start, I think I will document certain projects I’ve taken on that relate to data analysis and visualization. I consider myself a beginning to intermediate level R user. To help me retain the information I’m learning, I will try to blog everything that seems worth sharing. I hope that these help you, if you are trying to learn more about R like I am.\nI don’t want my posts to be exclusive to R. Like any tool, the language has its strengths and weaknesses. I will likely include some content on PowerBI and perhaps its integration with R. I also want to document notable takeaways from my experiences in graduate school and other projects I am involved with in my professional work."
  },
  {
    "objectID": "posts/welcome/index.html#stay-in-touch",
    "href": "posts/welcome/index.html#stay-in-touch",
    "title": "Welcome to my Blog",
    "section": "Stay in touch",
    "text": "Stay in touch\nIf this description interests you, please follow along with my journey. If you are interested in hearing more about my work or would like to share resources, let me know! I have included links to my GitHub, Twitter, and LinkedIn. Feel free to reach out to my on any of those platforms (or comment here on my blog)."
  },
  {
    "objectID": "posts/Michigan COVID Cases and Deaths by County/index.html",
    "href": "posts/Michigan COVID Cases and Deaths by County/index.html",
    "title": "Michigan COVID-19 County Maps",
    "section": "",
    "text": "This post is intended to demonstrate some basic ways to map data in R. For our example, we will be creating a choropleth map of Michigan’s counties featuring COVID-19 data. The result is something quite similar to the map featured on the state’s dashboard. The data used in this post is from October 4, 2022.\nFor the sake of practice, we will walk through two different ways to go about this process. First we will use ggplot2. We will use a function called map_data to pull in shape file data easily. In our second example, we will use leaflet to create a better looking version of this map and use a raw shape file."
  },
  {
    "objectID": "posts/shiny/index.html",
    "href": "posts/shiny/index.html",
    "title": "Shiny test",
    "section": "",
    "text": "Warning: package 'tidycensus' was built under R version 4.1.2\n\n\nWarning: package 'leaflet' was built under R version 4.1.2\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n✔ tibble  3.1.8      ✔ dplyr   1.0.10\n✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n✔ readr   2.1.2      ✔ forcats 0.5.1 \n\n\nWarning: package 'tibble' was built under R version 4.1.2\n\n\nWarning: package 'tidyr' was built under R version 4.1.2\n\n\nWarning: package 'readr' was built under R version 4.1.2\n\n\nWarning: package 'dplyr' was built under R version 4.1.2\n\n\nWarning: package 'stringr' was built under R version 4.1.2\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nTo install your API key for use in future sessions, run this function with `install = TRUE`.\n\n\nGetting data from the 2016-2020 5-year ACS\n\n\nDownloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.\n\n\nFetching data by table type (\"B/C\", \"S\", \"DP\") and combining the result.\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |=======                                                               |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |================                                                      |  22%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |=================================                                     |  48%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |===================================                                   |  51%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |=======================================                               |  55%\n  |                                                                            \n  |========================================                              |  56%\n  |                                                                            \n  |========================================                              |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |===============================================                       |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |=====================================================                 |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |==========================================================            |  82%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |=================================================================     |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |======================================================================|  99%\n  |                                                                            \n  |======================================================================| 100%"
  },
  {
    "objectID": "posts/Michigan COVID Cases and Deaths by County/index.html#using-leaflet",
    "href": "posts/Michigan COVID Cases and Deaths by County/index.html#using-leaflet",
    "title": "Michigan COVID-19 County Maps",
    "section": "Using Leaflet",
    "text": "Using Leaflet\n\n\nCode\n# leaflet -----------------------------------------------------------------\nlibrary(sp)\nlibrary(tigris)\nlibrary(leaflet)\n\nmiCounties &lt;- counties(state = \"MI\", cb = TRUE, progress_bar = FALSE)\n\nmicovid &lt;- micovid %&gt;%\n  mutate(NAME = case_when(\n    COUNTY == \"St Clair\" ~ \"St. Clair\",\n    COUNTY == \"St Joseph\" ~ \"St. Joseph\",\n    TRUE ~ COUNTY\n  ))\n\ncombined &lt;- merge(miCounties, micovid)\n\n\n# pals and labels for each map -------------------------------------------------------\n\ncase_bins &lt;- c(0, 1000, 5000, 15000, 30000, 100000, Inf)\ncase_pal &lt;- colorBin(\"Blues\", domain = combined$total_cases, bins = case_bins)\n\ncase_labels &lt;- sprintf(\n  \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br/&gt;Cases: %g\",\n  combined$NAME, combined$total_cases\n) %&gt;% lapply(htmltools::HTML)\n\ndeath_bins &lt;- c(0, 50, 100, 150, 500, 1500, 3000, Inf)\n\ndeath_pal &lt;- colorBin(\"Reds\", domain = combined$total_deaths, bins = death_bins)\n\ndeath_labels  &lt;- sprintf(\n  \"&lt;strong&gt;%s&lt;/strong&gt;&lt;br/&gt;Deaths: %g\",\n  combined$NAME, combined$total_deaths\n) %&gt;% lapply(htmltools::HTML)\n\nleaflet() %&gt;% \n  addTiles(group = \"base\") %&gt;%\n  addPolygons(data = combined,\n              group = \"Cases\",\n              fillColor = ~case_pal(total_cases),\n              weight = 2,\n              opacity = 1,\n              color = \"white\",\n              dashArray = \"3\",\n              fillOpacity = 0.7,\n              highlightOptions = highlightOptions(\n                weight = 5,\n                color = \"#666\",\n                dashArray = \"\",\n                fillOpacity = 0.7,\n                bringToFront = TRUE),\n              label = case_labels,\n              labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"15px\",\n                direction = \"auto\")) %&gt;%\n  addLegend(data = combined,\n            title = \"Cases\",\n            pal = case_pal, values = ~total_cases, opacity = 0.7,\n            position = \"bottomright\", group = \"Cases\") %&gt;%\n  addPolygons(data = combined,\n              group = \"Deaths\",\n              fillColor = ~death_pal(total_deaths),\n              weight = 2,\n              opacity = 1,\n              color = \"white\",\n              dashArray = \"3\",\n              fillOpacity = 0.7,\n              highlightOptions = highlightOptions(\n                weight = 5,\n                color = \"#666\",\n                dashArray = \"\",\n                fillOpacity = 0.7,\n                bringToFront = TRUE),\n              label = death_labels,\n              labelOptions = labelOptions(\n                style = list(\"font-weight\" = \"normal\", padding = \"3px 8px\"),\n                textsize = \"15px\",\n                direction = \"auto\")) %&gt;%\n  addLegend(data = combined, \n            title = \"Deaths\",\n            pal = death_pal, values = ~total_deaths, opacity = 0.7,\n            position = \"bottomright\", group = \"Deaths\") %&gt;%\n  addLayersControl(overlayGroups = c(\"Cases\", \"Deaths\"),\n                   options = layersControlOptions(collapsed = FALSE)) %&gt;%\n  hideGroup(\"Deaths\")"
  },
  {
    "objectID": "posts/welcome/index.html#so-who-am-i",
    "href": "posts/welcome/index.html#so-who-am-i",
    "title": "Welcome to my Blog",
    "section": "So who am I?",
    "text": "So who am I?\nMy name is Brenden Smith. At this point, I am a little over a year into my graduate studies. I attend Michigan State University and I am working towards my Master in Public Health. I am most interested in data analysis, visualization, community-engaged research, and health disparities.\nPublic health as a field can be very broad. By its very nature, the field is multidisciplinary and covers a wide array of topics. I come from primarily a policy background. I received my Bachelor of Arts in social relations and policy from James Madison College (also here at MSU). My senior seminar was focused on US health care and policy and pretty much ever since I’ve been interested in a career in PH.\nDuring my undergrad I was also introduced to R for the first time in a quantitative methods course. That introduction began my interest in the programming language. More recently I have discovered the tidyverse and shiny packages. It is so exciting to be a part of the open-source community. I hope to contribute to it as I have most definitely benefited from the wealth of knowledge already available on the internet."
  },
  {
    "objectID": "posts/Michigan COVID Cases and Deaths by County/index.html#ggplot2-map",
    "href": "posts/Michigan COVID Cases and Deaths by County/index.html#ggplot2-map",
    "title": "Michigan COVID-19 County Maps",
    "section": "Ggplot2 map",
    "text": "Ggplot2 map\nTo start, we will make a base map with ggplot2 and make it interactive with plotly. First, as always, we load in the libraries we will be using.\n\n\nCode\n# Load packages -----------------------------------------------------------\nlibrary(tidyverse) # really just dplyr but the whole verse can't hurt\nlibrary(openxlsx) # to read in excel data\nlibrary(plotly) # for the interactive part\nlibrary(RColorBrewer) # to set our color palette\n\n\nNext, we will get our county map. To do this we can simply call the function map_data and specify that we want it at the county level. This will give us data for every county in the US. Because we are only mapping Michigan, we add a second line to subset our first data frame ‘counties’ to only include Michigan.\n\n\nCode\n# Make the base state map -------------------------------------------------\ncounties &lt;- map_data(\"county\")\nmi_county &lt;- subset(counties, region == \"michigan\")\n\n\nFor our COVID-19 data, I am importing an older file from state’s website (linked previously). If you want a current version to follow along, you can find it there. Once the file is loaded into R Studio, we need to make a few adjustments. The original file splits the cases into two categories, confirmed and probable. On the state’s dashboard, they combine these numbers into a total for map reporting. We will do the same. This is easily done with the group_by and summarise functions. We will also change the county names to lowercase in preparation for merging.\n\n\nCode\n# Data prep ---------------------------------------------------------------\nmicovid &lt;- read.xlsx(\"Cases and Deaths by County 2022-10-04.xlsx\")\n\nmicovid &lt;- micovid %&gt;%\n  group_by(COUNTY) %&gt;%\n  summarise(total_cases = sum(Cases),\n            total_deaths = sum(Deaths)) %&gt;%\n  ungroup() %&gt;%\n  mutate(subregion = tolower(COUNTY))\n\ncases_and_county &lt;- inner_join(mi_county, micovid, by = \"subregion\")\ncases_and_county &lt;- cases_and_county %&gt;%\n  rename(county = COUNTY)\n\n\n\n\nCode\ncases_and_county&lt;- cases_and_county %&gt;%\n  mutate(Category = case_when(total_cases &lt; 1000 ~ '0-999', \n                              total_cases &lt; 5000 ~ '1000-4999',\n                              total_cases &lt;15000 ~ '5000-14999',\n                              total_cases &lt; 30000 ~ '15000-29999',\n                              total_cases &lt; 100000~ '30000-99999',\n                              total_cases &lt; 1000000 ~ '100000+',\n                              TRUE ~ 'NA'))\n\ncases_and_county$Category &lt;- as.factor(cases_and_county$Category)\n\nlvls &lt;- c('0-999', \n          '1000-4999',\n          '5000-14999',\n          '15000-29999',\n          '30000-99999',\n          '100000+')\n\ncases_and_county$Category &lt;- fct_relevel(cases_and_county$Category, lvls)\n\n\n\n\nCode\n# Making the map ----------------------------------------------------------\n\np &lt;- c(\"#ACD1E7\", \"#82BADC\", \"#59A1CF\", \"#236893\",\"#174562\", \"#122548\")\n\nlabel &lt;- list(\n  bgcolor = \"#EEEEEE\",\n  font = list(color = \"black\")\n)\n\nnoax &lt;- list(\n  title = \"\",\n  zeroline = FALSE,\n  showline = FALSE,\n  showticklabels = FALSE,\n  showgrid = FALSE\n)\n\ng &lt;- cases_and_county %&gt;%\n  ggplot(aes(long, lat, \n                group = group,\n                text = paste('&lt;/br&gt;County:', county, '&lt;/br&gt;Category:', Category,\n                             '&lt;/br&gt;Cases:', total_cases)))+\n  geom_polygon(colour = alpha(\"black\", 1/2), fill = NA) +\n  geom_polygon(data = cases_and_county, colour = \"black\", aes(fill = Category))+\n  theme_void() +\n  scale_fill_manual(values = p) \n\n\n\n\nCode\nggplotly(g, tooltip = c(\"text\"), width = 700, height = 600) %&gt;%\n  layout(xaxis = noax,\n         yaxis = noax) %&gt;%\n  style(hoverlabel = label) %&gt;%\n  config(displayModeBar = FALSE)"
  },
  {
    "objectID": "posts/Michigan COVID Cases and Deaths by County/index.html#conclusion",
    "href": "posts/Michigan COVID Cases and Deaths by County/index.html#conclusion",
    "title": "Michigan COVID-19 County Maps",
    "section": "Conclusion",
    "text": "Conclusion"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Portfolio",
    "section": "",
    "text": "R Shiny Apps\n\n\nFeatured work using Shiny.\n\n\n\nBrenden Smith\n\n\nJan 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAcademic Posters\n\n\nVarious academic and professional projects that I have prepared into poster presentations.\n\n\n\nBrenden Smith\n\n\nAug 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTidy Tuesday\n\n\nAn ongoing collection of practice visualizations from the Tidy Tuesday weekly data project.\n\n\n\nBrenden Smith\n\n\nFeb 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPowerBI Dashboards\n\n\nA collection of work of mine in PowerBI.\n\n\n\nBrenden Smith\n\n\nDec 10, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/Michigan COVID-19 Dashboard/index.html",
    "href": "projects/Michigan COVID-19 Dashboard/index.html",
    "title": "PowerBI Dashboards",
    "section": "",
    "text": "Power BI\nThis page shows the Power BI projects that I have created in my academic and professional work. Samples below contain publicly available data.\n\n\nCOVID-19 Long Term Care Data Dashboard\nThis project was created to support the MDHHS long term care data reporting live on their website. I joined this project in early 2023 and recreated an existing dashboard that was made in Tableau into a PowerBI format. This was done to ease the integration process. The dashboard went live in March and was regularly updated until mid-May. This change was due to changing data reporting requirements.\n\n\n\nCOVID-19 Cases and Deaths by County\nThis past semester, I had the pleasure of taking a course on health informatics. We were tasked with creating an entire interactive dashboard using Power BI. This is my first experience using the software, and I have to say it is a lot of fun to play around with. After learning some of the ins and outs of exporting and transforming data, formatting beautiful visualizations came surprisingly easy.\nThe dashboard featured here is a re-imagining of the State’s current COVID-19 dashboard. I began with recreating the content they already provide. This entire project was made using the publicly available data files on the SOM’s website. In the last tab, I incorporated the CDC’s community level data that they provide for each state. I included this as the data provided is made comparable by population standardization, and increasingly, it seems that officials are looking to these levels specifically for policy guidance.\nTo view the dashboard in full screen you can use the link here. Below is the embedded dashboard. Enjoy!"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "#####Minor in Chicano/Latino Studies"
  },
  {
    "objectID": "projects/Tidy Tuesday/index.html",
    "href": "projects/Tidy Tuesday/index.html",
    "title": "Tidy Tuesday",
    "section": "",
    "text": "::: .g-col-12 .g-col-md-6} \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "posts/Bluets/index.html",
    "href": "posts/Bluets/index.html",
    "title": "Twitter Bots",
    "section": "",
    "text": "Update: Since a certain someone took over the bird app, this bot is no longer functional. Unfortunately, it is not worth paying $100/month to post random shades of blue. What an injustice."
  },
  {
    "objectID": "posts/Bluets/index.html#using-rvest",
    "href": "posts/Bluets/index.html#using-rvest",
    "title": "Twitter Bots",
    "section": "Using ‘rvest’",
    "text": "Using ‘rvest’\nTo help us source our data, the library 'rvest' provides everything we need. In order to create a data frame containing the color name and the hex code, we need to:\n\nimport the web search’s html\npull out the two elements from the code (name, hex code)\nthen repeat this process for each of the 89 pages\n\nThe function 'read_html' from rvest makes the first step incredibly easily. For this, we simply pass in the web address as an argument in the function and save the output as a new value called 'page'.\n\n\nCode\nlibrary(rvest)\nlink &lt;- \"https://www.color-name.com/search/blue\"\npage &lt;- read_html(link)\n\n\nNext, we’ll pass 'page' into the function 'html_nodes' and then into 'html_text' to extract the desired string vector. The text passed through 'html_nodes' must be sourced from the webpage you are scraping from. You can use the ‘inspect’ feature in Google Chrome, or the Chrome extension ‘SelectorGadget’ to find the proper tag to use.\n\n\nCode\nname &lt;- page |&gt; html_nodes(\"h2 a\") |&gt; html_text()\nhex &lt;- page |&gt; html_nodes(\".hx\") |&gt; html_text()\n\n\nOnce that is done, we can take both vectors and create a data frame.\n\n\nCode\ncolors &lt;- data.frame(name, hex, stringsAsFactors = FALSE)\n\n\nIn order to collect each page of data, it is easiest to use a for loop. For this we make a couple of changes. First, we will create an empty data frame titled 'colors' to store data in for each iteration of the loop. Because there are 89 pages, we set the for loop to iterate that many times. We store this as 'page_result' in the loop and change the url to match what is displayed on each page number then use 'paste0' to put them together. Lastly, I added 'rbind' to add the new rows to the 'colors' data frame and a print command to keep track of the loop progress.\n\n\nCode\ncolors &lt;- data.frame()\n\nfor (page_result in 1:89){\n  \n  link &lt;- paste0(\"https://www.color-name.com/search/blue/page/\", page_result)\n  \n  page &lt;- read_html(link)\n  \n  name &lt;- page |&gt; html_nodes(\"h2 a\") |&gt; html_text()\n  hex &lt;- page |&gt; html_nodes(\".hx\") |&gt; html_text()\n  \n  colors &lt;- rbind(colors, data.frame(name, hex, stringsAsFactors = FALSE))\n  \n  print(paste(\"Page:\", page_result))\n}\n\n\nAnd as a last step, I decided to clean up the colors a bit. Even though the search used the key word 'blue', I noticed that the last page displayed colors that did not have the word 'blue' in the title. To fix this, I filtered out any color that did not contain the word.\n\n\nCode\nlibrary(dplyr)\nblues &lt;- colors |&gt; filter(grepl('Blue', name))"
  },
  {
    "objectID": "projects/AcademyHealth Poster/index.html",
    "href": "projects/AcademyHealth Poster/index.html",
    "title": "Academic Posters",
    "section": "",
    "text": "Barriers to Refuse Disposal in Larteh, Ghana\nThis poster was put together as a result of my research experiences in Ghana. This fulfilled my practicum requirement for my MPH program. As of this posting, the research has not been submitted or presented formally.\n\n\n\n\n\n\n\nAcademyHealth Poster: Mental Health and the Pandemic\nThis research was put together in collaboration with Ann Annis and Wenjuan Ma. This poster would not be possible without their dedication and support!"
  },
  {
    "objectID": "projects/Mental Health and the Pandemic/index.html",
    "href": "projects/Mental Health and the Pandemic/index.html",
    "title": "Mental Health and the Pandemic",
    "section": "",
    "text": "Introduction\nThis project was originally a submission to the National Center for Health Statistics and AcademyHealth sponsored Data Visualization Challenge in Fall of 2022.\nThis web application was my first experience building a Shiny application! I found it fascinating to dive into the mechanics of making a usable, interactive web application for data exploration.\nThis project uses data from the Household Pulse Survey as well as data from the Uniform Data System to understand mental illness during the pandemic years. HHP data shows national trends for varying mental illnesses while the UDS data speaks to the experience of patients accessing care at federally qualified health centers throughout the country. We added this data and compared it with poverty rates across U.S. counties (American Community Survey) and mental health provider shortage levels (Area Health Resources Files).\nMy favorite part of this challenge was getting to create large, interactive maps to explore these data.\nWhile the application could be embedded here, it is best viewed in its own window. You can access the app and the full data here."
  },
  {
    "objectID": "posts/opioid plotting practice/index.html",
    "href": "posts/opioid plotting practice/index.html",
    "title": "Opioid Plotting Practice",
    "section": "",
    "text": "Over the summer, I took a course on public health surveillance. As a culminating project, we were tasked with creating original data visualizations for a fact sheet on a topic of our choosing. I chose to examine local opioid overdose and mortality data for my project.\nThis is a topic that is near to me. The opioid crisis has impacted many communities across the country. At this point, the topic is well known to most people. Despite awareness, overdoses are still rising.\nIn the following post, I will demonstrate how easily you can spice up basic ggplot graphics. In particular we will look at:\n\na basic ggplot2 line chart\nggthemes we can use to make a more professional looking figure\nand a brief glimpse at plotly (because interactive graphs are so cool!)"
  },
  {
    "objectID": "posts/opioid plotting practice/index.html#data-prep",
    "href": "posts/opioid plotting practice/index.html#data-prep",
    "title": "Opioid Plotting Practice",
    "section": "Data Prep",
    "text": "Data Prep\nTo begin, we will load in our libraries. Be sure to install them if you haven’t already.\n\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(readxl)\nlibrary(plotly)\n\nNext, we will read in our data using readxl. The data I am using comes from the Michigan Substance Use Disorder Data Repository (SUDDR). You can download the data yourself here. Keep in mind that the numbers we are working with in this example are raw counts of opioid overdose deaths by county, NOT rates. Therefore, we should not compare these counties against each other without considering population size differences. I’m interested in looking at changes over time with this dataset.\nBecause I’m focusing on the three counties in my area, I’m going to create a vector with the names of the capital area counties. This will make subsetting the data a little easier.\n\nopdeaths &lt;- read_xlsx(\"Opioid Overdose Deaths.xlsx\")\n\ncounties &lt;- c(\"Ingham\", \"Eaton\", \"Clinton\")"
  },
  {
    "objectID": "posts/opioid plotting practice/index.html#time-to-plot",
    "href": "posts/opioid plotting practice/index.html#time-to-plot",
    "title": "Opioid Plotting Practice",
    "section": "Time to Plot!",
    "text": "Time to Plot!\nFrom here, we can start our first plot. I will select my target counties using the filter() function that comes from the dplyr package. Be sure to specify which aesthetics you want to plot on the respective axes. Here we are putting the variable Year on the x-axis and Opioid Overdose Deaths on the y.\n\nopdeaths %&gt;%\n  filter(County %in% counties) %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line()\n\n\n\n\nOh no! What happened? We didn’t tell ggplot which lines we wanted to see. It is important that within the layer geom_line() we specify that we want to plot different lines based on our county variable. To do this, we simply add an aes() layer and assign color to County.\n\nopdeaths %&gt;%\n  filter(County %in% counties) %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(aes(color = County))\n\n\n\n\nThat looks a lot better! But we can do more. The lines look a bit skinny to me. I would like them to stand out more. It also might help to adjust the opacity of the lines. This can make points that cross over easier to read. To make these changes, we can specify linewidth and alpha in geom_line() outside of the aes() argument.\nI think it would be great to add points to our plot, too. Like the geom_line() layer, I want these to be large enough and overlap easily. I will pass through similar arguments in the geom_point() layer, also specifying the color.\n\nopdeaths %&gt;%\n  filter(County %in% counties)  %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(linewidth = 1, alpha = 0.8, aes(color = County)) +\n  geom_point(size = 2, alpha = 0.8, aes(color = County))\n\n\n\n\nLastly, I want to add labels and theme to really polish up our plot. This is surprisingly easy! To add our labels, we add another layer called labs(). Here we can add a proper title, and more accurate labels for the axes.\nAdding a theme is even easier. We can quickly add on a layer and pick a theme that we like. For my example, I’m using the fivethirtyeight theme that comes from ggthemes. Be sure to check out the other options available in this package.\nAfter our theme_fivethrityeight() layer, I’m adding a general theme() layer to specify that I want all my main title and axes titles to be shown. I am also adjusting the text size to make the title a bit more readable.\n\nopdeaths %&gt;%\n  filter(County %in% counties)  %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(linewidth = 1, alpha = 0.8, aes(color = County)) +\n  geom_point(size = 2, alpha = 0.8, aes(color = County)) +\n  labs(title = \"Opioid Overdose Deaths in Michigan's Capital Area \\nCounties, 1999 – 2020\",\n       x = \"Year\",\n       y = \"Number of Deaths\") +\n  theme_fivethirtyeight() +\n  theme(plot.title = element_text(size = 16),\n        plot.title.position = \"plot\",\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size = 11),\n        axis.title.y = element_text(vjust = +3),\n        axis.title.x = element_text(vjust = -0.75),\n        text = element_text(family = \"Georgia\"),\n        plot.margin = unit(c(1, 1, 1, 1), \"lines\"))\n\n\n\n\nAnd just like that, we have a very nice looking line chart!"
  },
  {
    "objectID": "posts/opioid plotting practice/index.html#a-glimpse-of-plotly",
    "href": "posts/opioid plotting practice/index.html#a-glimpse-of-plotly",
    "title": "Opioid Plotting Practice",
    "section": "A Glimpse of Plotly",
    "text": "A Glimpse of Plotly\nNext I want to briefly show how easy it is to take a basic ggplot figure and make it interactive with the amazing package plotly. If I save the figure we created before as an object, we can pass it through the function ggplotly(), and as a result, we get a chart where we can zoom in and hover over points to gain more insight. I will demonstrate this below.\n\np1 &lt;- opdeaths %&gt;%\n  filter(County %in% counties)  %&gt;%\n  ggplot(aes(x = Year, y = `Opioids Overdose Deaths`)) +\n  geom_line(linewidth = 1, alpha = 0.8, aes(color = County)) +\n  geom_point(size = 2, alpha = 0.8, aes(color = County)) +\n  labs(title = \"Opioid Overdose Deaths in Michigan's Capital Area Counties, 1999 – 2020\",\n       x = \"Year\",\n       y = \"Number of Deaths\") +\n  theme_fivethirtyeight() +\n  theme(plot.title = element_text(size = 16),\n        plot.title.position = \"plot\",\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size = 11),\n        axis.title.y = element_text(vjust = +3),\n        axis.title.x = element_text(vjust = -0.75),\n        text = element_text(family = \"Georgia\"),\n        plot.margin = unit(c(1, 1, 1, 1), \"lines\"))\n\nggplotly(p1)\n\n\n\n\n\nIt’s amazing how quickly you can produce interactive charts with R! The output from this function in an html widget. So it can easily be viewed on a website or a local html file. This makes it ideal for sharing graphics quickly among coworkers.\nFor my project, I created a few more graphics with the same color palette and arranged them on a pdf for easy distribution. If you want to view the finished product you can find that here.\nI hope you found this post helpful. Next time I want to focus more on plotly demonstrating its capabilities with spatial data analysis. Until next time!"
  },
  {
    "objectID": "index.html#blog-highlights",
    "href": "index.html#blog-highlights",
    "title": "Brenden Smith",
    "section": "Blog Highlights",
    "text": "Blog Highlights\n\nBlog post 1\nBlog post 2\nBlog post 3"
  },
  {
    "objectID": "index.html#featured-projects",
    "href": "index.html#featured-projects",
    "title": "Brenden Smith",
    "section": "Featured Projects",
    "text": "Featured Projects\n\nThis div...\n...required...\n...no offset (it’s still in the first row)"
  },
  {
    "objectID": "index.html#recent-blog-posts",
    "href": "index.html#recent-blog-posts",
    "title": "Brenden Smith",
    "section": "Recent Blog Posts",
    "text": "Recent Blog Posts\n\n\n\n\n\n\n\n\n\n\n\n\nTwitter Bots\n\n\n6 min\n\n\n\nR\n\n\ncolor\n\n\nweb-scraping\n\n\n\n\nBrenden Smith\n\n\nMar 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichigan COVID-19 County Maps\n\n\n8 min\n\n\n\nR\n\n\nmaps\n\n\n\n\nBrenden Smith\n\n\nOct 11, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpioid Plotting Practice\n\n\n6 min\n\n\n\nR\n\n\nggplot2\n\n\n\n\nBrenden Smith\n\n\nOct 9, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#mph-candidate-research-assistant-michigan-state-university-institute-for-health-policy",
    "href": "index.html#mph-candidate-research-assistant-michigan-state-university-institute-for-health-policy",
    "title": "Brenden Smith",
    "section": "",
    "text": "Hi, I’m Brenden. I am an MPH candidate with interests in health equity, harm reduction, and community engagement. I am a data analyst, community researcher, and R enthusiast.\nIf you would like to see some of my current and past work, you can visit my portfolio page or check out my blog."
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "Brenden Smith",
    "section": "Projects",
    "text": "Projects\n\n\n\n\n\n\n\n\n\n\nAcademyHealth Poster\n\n\n\n\n\n\n\n\n\n\n\n\n\nTidy Tuesday\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichigan COVID-19 Dashboard\n\n\n\n\n\n\n\n\n\n\n\n\n\nMental Health and the Pandemic\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#blog-posts",
    "href": "index.html#blog-posts",
    "title": "Brenden Smith",
    "section": "Blog Posts",
    "text": "Blog Posts\n\n\n\n\n\n\n\n\n\n\nTwitter Bots\n\n\n\nR\n\n\ncolor\n\n\nweb-scraping\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMichigan COVID-19 County Maps\n\n\n\nR\n\n\nmaps\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpioid Plotting Practice\n\n\n\nR\n\n\nggplot2\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/opioid plotting practice/index.html#introduction",
    "href": "posts/opioid plotting practice/index.html#introduction",
    "title": "Opioid Plotting Practice",
    "section": "",
    "text": "Over the summer, I took a course on public health surveillance. As a culminating project, we were tasked with creating original data visualizations for a fact sheet on a topic of our choosing. I chose to examine local opioid overdose and mortality data for my project.\nThis is a topic that is near to me. The opioid crisis has impacted many communities across the country. At this point, the topic is well known to most people. Despite awareness, overdoses are still rising.\nIn the following post, I will demonstrate how easily you can spice up basic ggplot graphics. In particular we will look at:\n\na basic ggplot2 line chart\nggthemes we can use to make a more professional looking figure\nand a brief glimpse at plotly (because interactive graphs are so cool!)"
  },
  {
    "objectID": "posts/Michigan COVID Cases and Deaths by County/index.html#introduction",
    "href": "posts/Michigan COVID Cases and Deaths by County/index.html#introduction",
    "title": "Michigan COVID-19 County Maps",
    "section": "",
    "text": "This post is intended to demonstrate some basic ways to map data in R. For our example, we will be creating a choropleth map of Michigan’s counties featuring COVID-19 data. The result is something quite similar to the map featured on the state’s dashboard. The data used in this post is from October 4, 2022.\nFor the sake of practice, we will walk through two different ways to go about this process. First we will use ggplot2. We will use a function called map_data to pull in shape file data easily. In our second example, we will use leaflet to create a better looking version of this map and use a raw shape file."
  },
  {
    "objectID": "posts/HM878: Helper Functions/index.html",
    "href": "posts/HM878: Helper Functions/index.html",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "This vignette demonstrates how to use the functions included in this package so far. If you have not yet, install the package with the following code: devtools::install_github(\"brendensm/hm878\"). If you do not have the package devtools, be sure to install that first install.packages(\"devtools\").\nTo start, we load the package\n\nlibrary(hm878)\n\nLet’s assume we are running a binomial logistic regression using the data from mtcars, a built-in data set included with R. We will use vs (engine type as V-shaped or straight) as the dependent variable, and cyl (number of cylinders) as the independent variable. We will store our models for block 1 and block 2.\n\nmb1 &lt;- glm(vs ~ 1, data = mtcars, family = \"binomial\")\nmb2 &lt;- glm(vs ~ cyl, data = mtcars, family = \"binomial\")\n\n\n\nTo assess the fit of our models, we may want to use the function chi_log. To use it, simply type in the name of your model as the first argument, followed by the data set that the model uses. Optionally, you can provide labels for each model using the third argument. Here I will label each block.\n\nchi_log(mb1, mtcars, \"Block 1\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 1:  32 \n Degrees of freedom for Block 1:  31 \n P-value for Block 1:  0.416744 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\nchi_log(mb2, mtcars, \"Block 2\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 2:  27.42 \n Degrees of freedom for Block 2:  30 \n P-value for Block 2:  0.6013516 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\n\nThe function gives us the chi-squared statistic, degrees of freedom, and a p-value. It also reminds us of the null and alternative hypotheses. Both models appear to be a good fit.\n\n\n\nWe may want to also check the accuracy of our models. To do this, we can use predict_percent. To use this function, enter the name of the model in the first argument, followed by the dependent variable we used in the model. For this, we must use the data$variable format. In the example below, we use the variable vs from the data set mtcars. Once again, we can label the output with a string as the optional third argument.\n\npredict_percent(mb1, mtcars$vs, \"Block 1\")\n\n\nAccuracy for Block 1: 56.25%\n\npredict_percent(mb2, mtcars$vs, \"Block 2\")\n\n\nAccuracy for Block 2: 84.38%\n\n\n\n\n\nTo calculate odds ratios for the models, simply pass the model through the function or.\n\nor(mb1)\n\n            Odds_Ratio  CI_Lower CI_Upper  p_values\n(Intercept)  0.7777778 0.3801366 1.558936 0.4806496\n\nor(mb2)\n\n              Odds_Ratio    CI_Lower     CI_Upper    p_values\n(Intercept) 10873.447296 95.35600799 6.507716e+07 0.002692584\ncyl             0.204474  0.04827075 4.455527e-01 0.001917098\n\n\nThe output results in a data frame with the odds ratios, confidence intervals, and p-values.\n\n\n\nIf you want to revise and adjust your model, it can be helpful to limit outliers. To find upper and lower fences quickly, use the function fences. To do this, pass the continuous variable you are interested in examining through the function. Once again, use the format data$variable.\n\nfences(mtcars$cyl)\n\n    Lower Upper\n25%    -2    14\n\nfences(mtcars$cyl)$Upper\n\n[1] 14\n\nfences(mtcars$cyl)$Lower\n\n[1] -2\n\n\n\n\n\nLastly, when you are putting together multiple models, it can be helpful to view them all at the same time, next to one another. This is particularly helpful if you have more than two models you are comparing. For this function, pass through however many models you have to compare, and optionally label each one, using a vector of strings for each model. To demonstrate, I will add on another model mb3 that will have another continuous independent variable.\n\nmb3 &lt;- glm(vs ~ cyl + wt, data = mtcars, family = \"binomial\")\n\ncompare_models(mb1, mb2, mb3, labels = c(\"Model 1 Block 1\", \"Model 1 Block 2\", \"Model Block 3\"))\n\n$`Model 1 Block 1`\n\nCall:  glm(formula = vs ~ 1, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)  \n    -0.2513  \n\nDegrees of Freedom: 31 Total (i.e. Null);  31 Residual\nNull Deviance:      43.86 \nResidual Deviance: 43.86    AIC: 45.86\n\n$`Model 1 Block 2`\n\nCall:  glm(formula = vs ~ cyl, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl  \n      9.294       -1.587  \n\nDegrees of Freedom: 31 Total (i.e. Null);  30 Residual\nNull Deviance:      43.86 \nResidual Deviance: 17.96    AIC: 21.96\n\n$`Model Block 3`\n\nCall:  glm(formula = vs ~ cyl + wt, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl           wt  \n     10.619       -2.931        2.100  \n\nDegrees of Freedom: 31 Total (i.e. Null);  29 Residual\nNull Deviance:      43.86 \nResidual Deviance: 15.55    AIC: 21.55\n\n\n\n\n\n\ndeviance_aic(mb1, mb2, mb3)\n\nmb1 \nResidual Deviance: 43.86 \nNull Deviance: 43.86 \nAIC: 45.86 \n\nmb2 \nResidual Deviance: 17.96 \nNull Deviance: 43.86 \nAIC: 21.96 \n\nmb3 \nResidual Deviance: 15.55 \nNull Deviance: 43.86 \nAIC: 21.55"
  },
  {
    "objectID": "posts/HM878: Helper Functions/index.html#testing-goodness-of-fit-with-chi_log",
    "href": "posts/HM878: Helper Functions/index.html#testing-goodness-of-fit-with-chi_log",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "To assess the fit of our models, we may want to use the function chi_log. To use it, simply type in the name of your model as the first argument, followed by the data set that the model uses. Optionally, you can provide labels for each model using the third argument. Here I will label each block.\n\nchi_log(mb1, mtcars, \"Block 1\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 1:  32 \n Degrees of freedom for Block 1:  31 \n P-value for Block 1:  0.416744 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\nchi_log(mb2, mtcars, \"Block 2\")\n\nPearson Goodness of Fit Test\n Null Hypothesis: The model fits.\n Alternative Hypothesis: The model does not fit.\n\n Pearson chi-squared for Block 2:  27.42 \n Degrees of freedom for Block 2:  30 \n P-value for Block 2:  0.6013516 \n\n ---\n Failed to reject Null Hypothesis. The model fits.\n ---\n\n\nThe function gives us the chi-squared statistic, degrees of freedom, and a p-value. It also reminds us of the null and alternative hypotheses. Both models appear to be a good fit."
  },
  {
    "objectID": "posts/HM878: Helper Functions/index.html#accuracy-percentage-with-predict_percent",
    "href": "posts/HM878: Helper Functions/index.html#accuracy-percentage-with-predict_percent",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "We may want to also check the accuracy of our models. To do this, we can use predict_percent. To use this function, enter the name of the model in the first argument, followed by the dependent variable we used in the model. For this, we must use the data$variable format. In the example below, we use the variable vs from the data set mtcars. Once again, we can label the output with a string as the optional third argument.\n\npredict_percent(mb1, mtcars$vs, \"Block 1\")\n\n\nAccuracy for Block 1: 56.25%\n\npredict_percent(mb2, mtcars$vs, \"Block 2\")\n\n\nAccuracy for Block 2: 84.38%"
  },
  {
    "objectID": "posts/HM878: Helper Functions/index.html#calculating-odds-ratios-with-or",
    "href": "posts/HM878: Helper Functions/index.html#calculating-odds-ratios-with-or",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "To calculate odds ratios for the models, simply pass the model through the function or.\n\nor(mb1)\n\n            Odds_Ratio  CI_Lower CI_Upper  p_values\n(Intercept)  0.7777778 0.3801366 1.558936 0.4806496\n\nor(mb2)\n\n              Odds_Ratio    CI_Lower     CI_Upper    p_values\n(Intercept) 10873.447296 95.35600799 6.507716e+07 0.002692584\ncyl             0.204474  0.04827075 4.455527e-01 0.001917098\n\n\nThe output results in a data frame with the odds ratios, confidence intervals, and p-values."
  },
  {
    "objectID": "posts/HM878: Helper Functions/index.html#upper-and-lower-fences-with-fences",
    "href": "posts/HM878: Helper Functions/index.html#upper-and-lower-fences-with-fences",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "If you want to revise and adjust your model, it can be helpful to limit outliers. To find upper and lower fences quickly, use the function fences. To do this, pass the continuous variable you are interested in examining through the function. Once again, use the format data$variable.\n\nfences(mtcars$cyl)\n\n    Lower Upper\n25%    -2    14\n\nfences(mtcars$cyl)$Upper\n\n[1] 14\n\nfences(mtcars$cyl)$Lower\n\n[1] -2"
  },
  {
    "objectID": "posts/HM878: Helper Functions/index.html#comparing-model-results-with-compare_models",
    "href": "posts/HM878: Helper Functions/index.html#comparing-model-results-with-compare_models",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "Lastly, when you are putting together multiple models, it can be helpful to view them all at the same time, next to one another. This is particularly helpful if you have more than two models you are comparing. For this function, pass through however many models you have to compare, and optionally label each one, using a vector of strings for each model. To demonstrate, I will add on another model mb3 that will have another continuous independent variable.\n\nmb3 &lt;- glm(vs ~ cyl + wt, data = mtcars, family = \"binomial\")\n\ncompare_models(mb1, mb2, mb3, labels = c(\"Model 1 Block 1\", \"Model 1 Block 2\", \"Model Block 3\"))\n\n$`Model 1 Block 1`\n\nCall:  glm(formula = vs ~ 1, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)  \n    -0.2513  \n\nDegrees of Freedom: 31 Total (i.e. Null);  31 Residual\nNull Deviance:      43.86 \nResidual Deviance: 43.86    AIC: 45.86\n\n$`Model 1 Block 2`\n\nCall:  glm(formula = vs ~ cyl, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl  \n      9.294       -1.587  \n\nDegrees of Freedom: 31 Total (i.e. Null);  30 Residual\nNull Deviance:      43.86 \nResidual Deviance: 17.96    AIC: 21.96\n\n$`Model Block 3`\n\nCall:  glm(formula = vs ~ cyl + wt, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl           wt  \n     10.619       -2.931        2.100  \n\nDegrees of Freedom: 31 Total (i.e. Null);  29 Residual\nNull Deviance:      43.86 \nResidual Deviance: 15.55    AIC: 21.55"
  },
  {
    "objectID": "posts/HM878: Helper Functions/index.html#deviance_aic-pull-the-deviances-and-aics-from-model-summarys",
    "href": "posts/HM878: Helper Functions/index.html#deviance_aic-pull-the-deviances-and-aics-from-model-summarys",
    "title": "HM878: Helper Functions",
    "section": "",
    "text": "deviance_aic(mb1, mb2, mb3)\n\nmb1 \nResidual Deviance: 43.86 \nNull Deviance: 43.86 \nAIC: 45.86 \n\nmb2 \nResidual Deviance: 17.96 \nNull Deviance: 43.86 \nAIC: 21.96 \n\nmb3 \nResidual Deviance: 15.55 \nNull Deviance: 43.86 \nAIC: 21.55"
  },
  {
    "objectID": "posts/Intro to Bash Scripting/index.html",
    "href": "posts/Intro to Bash Scripting/index.html",
    "title": "Intro to Bash Scripting",
    "section": "",
    "text": "And I thought R gave me super powers…"
  },
  {
    "objectID": "posts/Intro to Bash Scripting/index.html#introduction",
    "href": "posts/Intro to Bash Scripting/index.html#introduction",
    "title": "Intro to Bash Scripting",
    "section": "Introduction",
    "text": "Introduction\nRecently, I’ve been having fun with Linux. I really didn’t know much about Linux or how it was different from MacOS or Windows. All I really knew was that very smart people use it and many computers depend on it!\nBy recommendation of a friend, I tried loading Pop!_OS on an old Macbook Air I had laying around. I quickly learned how lightweight many distributions of Linux are, and how customizable they can be.\nFor anyone familiar with Linux you know that, even when you are just setting up a computer with the OS, you have to start using a bit of the command line. I had used this before learning some helpful functions with git, but nothing has exposed me to the command line and Bash more than this endeavor.\nI have been inspired by this exposure and want to start learning more about the functionality of Bash. As a part of this, I wanted to try creating a Bash script of my own that I could implement into my current workflows."
  },
  {
    "objectID": "posts/Intro to Bash Scripting/index.html#the-idea",
    "href": "posts/Intro to Bash Scripting/index.html#the-idea",
    "title": "Intro to Bash Scripting",
    "section": "The Idea",
    "text": "The Idea\nI work primarily in R. And I love a good R Project. One of my usual habits for creating a project include adding sub folders and a starting script. I realized Bash is really good for doing this! So with some basic commands, I wanted to create a single executable script that makes a new R project, default sub folders, and a starting script."
  },
  {
    "objectID": "posts/Intro to Bash Scripting/index.html#writing-the-script",
    "href": "posts/Intro to Bash Scripting/index.html#writing-the-script",
    "title": "Intro to Bash Scripting",
    "section": "Writing the Script",
    "text": "Writing the Script\nFor the script I wanted several tasks accomplished:\n\nCreated an R project file within a contained folder\nSeveral sub-directories within that folder (data-raw, data, ref, output)\nA blank R script file\n\nTo start, I had the script ask for the name of the project. This was done by using echo to print the prompt, then read takes in the name of the project.\n\n\nCode\n#!/bin/bash\n\necho \"Please enter your project title: \"\n\nread name\n\n\nNext, I had to make the script navigate to the folder I want my projects in (for me, this is a folder on my desktop called ‘R’). Then, I had a directory made with sub-folders using mkdir -p. Here we use $name to use the variable stored as the name of the project. Within the {} are the names of the sub-folder I most commonly use. This could be anything you like though! Lastly, touch creates the blank R script.\n\n\nCode\ncd Desktop/R\n\nmkdir -p $name/{data-raw,data,ref,output}\n\ncd $name\n\ntouch script.R\n\n\nNext, we have an extra step that allows RStudio to open our new project properly. When I first tried this script out, I created a blank file with the .Rproj extension to set up the project. This immediately gave me problems when I tried to open the project. Specifically, I recall an issue with the version being unspecified.\nAfter a bit a research, I discovered that files with .Rproj are nothing really but a .txt file. I opened one of my existing R projects with a text editor and copied the contents exactly into the code chunk below. I wrote this text into the new R project. After some trial and error, I can confirm this method works!\n\n\nCode\n\necho -e 'Version: 1.0\n\nRestoreWorkspace: Default\nSaveWorkspace: Default\nAlwaysSaveHistory: Default\n\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 2\nEncoding: UTF-8\n\nRnwWeave: Sweave\nLaTex: pdfLaTeX' &gt;&gt; $name.Rproj\n\n\nThe last few lines of code echo some responses to the terminal and launch the new R project.\n\n\nCode\necho \"Project $name has been created.\"\necho \"It is stored in the R directory.\"\necho \"Opening project now...\"\n\nopen $name.Rproj"
  },
  {
    "objectID": "posts/Intro to Bash Scripting/index.html#making-it-accessible",
    "href": "posts/Intro to Bash Scripting/index.html#making-it-accessible",
    "title": "Intro to Bash Scripting",
    "section": "Making it Accessible",
    "text": "Making it Accessible\nFor me, personally, I like to be able to execute my scripts without worrying where I am in the terminal. Once my script was working properly, I moved it to the /usr/local/bin folder.\n\n\nCode\nmv setupr /usr/local/bin\n\n\nAnd that’s it! You can find the full script code below. I hope this is helpful! It was certainly useful to me to learn more about bash and make a useful script to help me set up projects."
  },
  {
    "objectID": "posts/Intro to Bash Scripting/index.html#full-script-code",
    "href": "posts/Intro to Bash Scripting/index.html#full-script-code",
    "title": "Intro to Bash Scripting",
    "section": "Full Script Code",
    "text": "Full Script Code\n\n\nCode\n#!/bin/bash\n\necho \"Please enter your project title: \"\n\nread name\n\ncd Desktop/R\n\nmkdir -p $name/{data-raw,data,ref,output}\n\ncd $name\n\ntouch script.R\n\necho -e 'Version: 1.0\n\nRestoreWorkspace: Default\nSaveWorkspace: Default\nAlwaysSaveHistory: Default\n\nEnableCodeIndexing: Yes\nUseSpacesForTab: Yes\nNumSpacesForTab: 2\nEncoding: UTF-8\n\nRnwWeave: Sweave\nLaTex: pdfLaTeX' &gt;&gt; $name.Rproj\n\necho \"Project $name has been created.\"\necho \"It is stored in the R directory.\"\necho \"Opening project now...\"\n\nopen $name.Rproj"
  },
  {
    "objectID": "posts/Survival Analysis/index.html",
    "href": "posts/Survival Analysis/index.html",
    "title": "Survival Analysis in R",
    "section": "",
    "text": "At first I was afraid, I was petrified…"
  },
  {
    "objectID": "posts/Survival Analysis/index.html#introduction",
    "href": "posts/Survival Analysis/index.html#introduction",
    "title": "Survival Analysis in R",
    "section": "Introduction",
    "text": "Introduction\nIn this blog post, I’ll be exploring some basic survival analysis in R. Survival analysis focuses on describing the occurrence of an event (in this example death) in a set time frame. Survival analysis is often used in clinical research and cancer epidemiology. For more reading, I recommend visiting The Epidemiologist R Handbook page on survival analysis, as well as their listed resources. The following blog post was adapted from my biostatistics coursework and features data used in that course. We will create Kaplan-Meier plots and go through Cox Hazard Regression."
  },
  {
    "objectID": "posts/Survival Analysis/index.html#packages-and-data",
    "href": "posts/Survival Analysis/index.html#packages-and-data",
    "title": "Survival Analysis in R",
    "section": "Packages and Data",
    "text": "Packages and Data\nFor this blog post, I will use the packages have, dplyr, survival.\n\n\nCode\n# Load in libraries\nlibrary(dplyr)\nlibrary(readr)\nlibrary(survival)\nlibrary(sjPlot)\n\n\nNext, we will load the data.\n\n\nCode\nsd &lt;- read_csv(\"data/HM 878 730 Clements - Survival Analysis R Data.csv\") %&gt;% \n  mutate(\n    #death = factor(death, levels = c(0, 1),\n                 #  labels = c(\"Living\", \"Died\")),\n    cursmoke = factor(cursmoke, levels = c(0, 1), \n                      labels = c(\"Not current smoker\", \"Current smoker\")),\n    diabetes = factor(diabetes, levels = c(0, 1),\n                      labels = c(\"Not diabetic\", \"Diabetic\")),\n    educ = factor(educ, levels = c(1, 2, 3, 4),\n                  labels = c(\"0-11 years\", \"HS Diploma/GED\", \n                             \"Some College/Vocational School\",\n                             \"College degree or more\")),\n    prevchd = factor(prevchd, levels = c(0, 1),\n                    labels = c(\"No\", \"Yes\")),\n    sex = factor(sex, levels = c(0, 1),\n                 labels = c(\"Female\", \"Male\"))\n  )"
  },
  {
    "objectID": "posts/Survival Analysis/index.html#cox-regression",
    "href": "posts/Survival Analysis/index.html#cox-regression",
    "title": "Survival Analysis in R",
    "section": "Cox Regression",
    "text": "Cox Regression\n\nHazard Ratios\n\n\nCode\ncm &lt;- coxph(Surv(TimeDeathYears, death) ~ cursmoke + diabetes +\n              educ + prevchd + age + bmi + sex, data = sd)\n\nsummary(cm)\n\n\nCall:\ncoxph(formula = Surv(TimeDeathYears, death) ~ cursmoke + diabetes + \n    educ + prevchd + age + bmi + sex, data = sd)\n\n  n= 3165, number of events= 746 \n   (98 observations deleted due to missingness)\n\n                                        coef exp(coef)  se(coef)      z\ncursmokeCurrent smoker              0.432597  1.541256  0.081165  5.330\ndiabetesDiabetic                    0.741622  2.099338  0.100251  7.398\neducHS Diploma/GED                 -0.007861  0.992169  0.092149 -0.085\neducSome College/Vocational School -0.158231  0.853652  0.111205 -1.423\neducCollege degree or more         -0.454487  0.634773  0.131159 -3.465\nprevchdYes                          0.790013  2.203425  0.086862  9.095\nage                                 0.092917  1.097370  0.005068 18.333\nbmi                                -0.012792  0.987290  0.009667 -1.323\nsexMale                             0.672732  1.959583  0.075393  8.923\n                                   Pr(&gt;|z|)    \ncursmokeCurrent smoker             9.83e-08 ***\ndiabetesDiabetic                   1.39e-13 ***\neducHS Diploma/GED                  0.93201    \neducSome College/Vocational School  0.15477    \neducCollege degree or more          0.00053 ***\nprevchdYes                          &lt; 2e-16 ***\nage                                 &lt; 2e-16 ***\nbmi                                 0.18575    \nsexMale                             &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                                   exp(coef) exp(-coef) lower .95 upper .95\ncursmokeCurrent smoker                1.5413     0.6488    1.3146    1.8070\ndiabetesDiabetic                      2.0993     0.4763    1.7248    2.5551\neducHS Diploma/GED                    0.9922     1.0079    0.8282    1.1886\neducSome College/Vocational School    0.8537     1.1714    0.6865    1.0615\neducCollege degree or more            0.6348     1.5754    0.4909    0.8208\nprevchdYes                            2.2034     0.4538    1.8585    2.6124\nage                                   1.0974     0.9113    1.0865    1.1083\nbmi                                   0.9873     1.0129    0.9688    1.0062\nsexMale                               1.9596     0.5103    1.6904    2.2716\n\nConcordance= 0.761  (se = 0.009 )\nLikelihood ratio test= 688.4  on 9 df,   p=&lt;2e-16\nWald test            = 686.8  on 9 df,   p=&lt;2e-16\nScore (logrank) test = 783.3  on 9 df,   p=&lt;2e-16\n\n\nCode\nsjPlot::tab_model(cm)\n\n\n\n\n\n\n\n\n\n\n\n \nSurv(Time Death\nYears,death)\n\n\nPredictors\nEstimates\nCI\np\n\n\ncursmoke [Current smoker]\n1.54\n1.31 – 1.81\n&lt;0.001\n\n\ndiabetes [Diabetic]\n2.10\n1.72 – 2.56\n&lt;0.001\n\n\neduc [HS Diploma/GED]\n0.99\n0.83 – 1.19\n0.932\n\n\neduc [Some\nCollege/Vocational\nSchool]\n0.85\n0.69 – 1.06\n0.155\n\n\neduc [College degree or\nmore]\n0.63\n0.49 – 0.82\n0.001\n\n\nprevchd [Yes]\n2.20\n1.86 – 2.61\n&lt;0.001\n\n\nage\n1.10\n1.09 – 1.11\n&lt;0.001\n\n\nbmi\n0.99\n0.97 – 1.01\n0.186\n\n\nsex [Male]\n1.96\n1.69 – 2.27\n&lt;0.001\n\n\nObservations\n3165\n\n\nR2 Nagelkerke\n0.200\n\n\n\n\n\n\n\n\n\nSurvival Curves\n\n\nCode\nsurv_fit_diab &lt;-  survfit(Surv(TimeDeathYears, death) ~ diabetes, data = sd)\n\ncol_diab &lt;- c(\"lightgreen\", \"darkgreen\")\n\nplot(\n  surv_fit_diab,\n  col = col_diab,\n  xlab = \"Years\",\n  ylab = \"Survival Probability\")\nlegend(\n  \"bottomright\",\n  legend = c(\"Not diabetic\",\"Diabetic\"),\n  col = col_diab,\n  lty = 1,\n  cex = .9,\n  bty = \"n\")\n\n\n\n\n\n\n\nInterpretation\nHazard ratios for the cox regression show that smoker status, diabetic status, prevalent coronary heart disease, age, sex, and the highest level of education all have significant p-values. This means that each were found to impact the outcome of death in our survival analysis.\nSmoker status has a hazard ratio of 1.54 meaning that, compared to non-smokers, current smokers have 1.54 times the risk of death.\nDiabetic status has a hazard ratio of 2.10. This means that those with diabetes, compared to those that were not diabetic, had 2.1 times greater risk of death.\nEducation at the level of college degree or more had a hazard ratio of 0.63. Compared to those with 0-11 years of education, this group had 37% decreased risk of death.\nPrevalence of coronary heart disease has a hazard ratio of 2.20, meaning that compared to those without CHD, they had 120% increased risk of death.\nAge also has a significant p-value, and a hazard ratio of 1.10. This means for every increase unit in age, there is 10% greater risk of death.\nLastly, sex had a hazard ratio of 1.96. This means that compared to females, males had 95% greater risk of death.\nThe survival curve shows the difference in survival probability between diabetics and non-diabetics. The differences are quite noticeably, with a lower survival probability among diabetics. This is in line with the results of the cox regression. For example, at 10 years, the survival probability among non-diabetics is about 85%, while the probability among diabetics is 65%."
  },
  {
    "objectID": "posts/Survival Analysis/index.html#kaplan-meier",
    "href": "posts/Survival Analysis/index.html#kaplan-meier",
    "title": "Survival Analysis in R",
    "section": "Kaplan-Meier",
    "text": "Kaplan-Meier\nConduct Kaplan-Meier for each categorical IV. Interpret the summary, mean and median survival time, Log Rank Mantel-Cox Test, survival probability at 10 years. Compare and contrast between each variable.\n\nFunction for Analysis\nBecause I have to compare quite a few variables, I make a quick function to output exactly what I need.\n\n\nCode\nkm &lt;- function(time, event, data, iv, title_label){\n  \nmodel &lt;-  survfit(Surv(time, event) ~ iv, data = sd)\n\ncols &lt;- RColorBrewer::brewer.pal(4, \"Set1\")\n\nplot_title &lt;- paste(\"Survival Curve by\", title_label)\n\nplot(\n  model,\n  col = cols,\n  lwd = 2,\n  main = plot_title,\n  xlab = \"Years\",\n  ylab = \"Survival Probability\")\nlegend(\n  \"bottomleft\",\n  legend = levels(iv),\n  col = cols,\n  lty = 1,\n  cex = .9,\n  bty = \"n\")\nabline(h = seq(0,1,.2), lty = \"dashed\", col = \"gray75\")\nabline(lty = \"dashed\", col = \"black\", v = 10)\n  \n  \ncat(\"Model summary with mean and median: \\n\")\nprint(model, print.rmean = TRUE)\n\nlogrank &lt;- survdiff(Surv(time, event) ~ iv, data = data)\nprint(logrank)\n  \n}\n\n\n\n\nDiabetes\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$diabetes, \"Diabetes\")\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n                   n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=Not diabetic 3009    646   13.7    0.0525     NA      NA      NA\niv=Diabetic      254    129   11.8    0.2540     14      13      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n                   N Observed Expected (O-E)^2/E (O-E)^2/V\niv=Not diabetic 3009      646    724.5       8.5       133\niv=Diabetic      254      129     50.5     121.8       133\n\n Chisq= 133  on 1 degrees of freedom, p= &lt;2e-16 \n\n\nAs interpreted before, the survival probability differs quite drastically between these two groups. At 10 years, the survival probability among non-diabetics is about 85%, while the probability among diabetics is 65%.\nThe model summary shows the total number in each group and the number of events (deaths) in each group.\nThe mean survival time is 13.7 years for non-diabetics, compared to 11.8 for diabetics. The median survival time could not be computed for non-diabetics, and was 14 years for diabetics. The median was not computed for non-diabetics because over 50% were still alive by the end of the time period.\nThe Log Rank Mantel-Cox Test shows a resulting p-value of &lt;0.0001, meaning that the null hypothesis, that there is no difference in survival between groups, is rejected.\n\n\nSmoker Status\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$cursmoke, \"Smoker Status\")\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n                         n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=Not current smoker 2142    501   13.6    0.0649     NA      NA      NA\niv=Current smoker     1121    274   13.5    0.0922     NA      NA      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n                         N Observed Expected (O-E)^2/E (O-E)^2/V\niv=Not current smoker 2142      501      510     0.173     0.517\niv=Current smoker     1121      274      265     0.333     0.517\n\n Chisq= 0.5  on 1 degrees of freedom, p= 0.5 \n\n\nThe model results show that the mean survival time was 13.6 among non-smokers and 13.5 among current smokers. These are not very different from each other, and on par with the average survival time of non-diabetics. The median survival times were not able to be calculated for this variable.\nThe Log Rank test shows a p-value of 0.5 indicating we should accept the null hypothesis that there is no difference in survival between the two groups.\nAt 10 years, the survival probability is nearly the same between the two groups, a bit greater than 80%. Once again, similar to non-diabetic suvival probability at the same time.\n\n\nEducation Level\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$educ, \"Education\")\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n   82 observations deleted due to missingness \n                                     n events rmean* se(rmean) median 0.95LCL\niv=0-11 years                     1281    381   13.2    0.0936     NA      NA\niv=HS Diploma/GED                  967    194   13.8    0.0911     NA      NA\niv=Some College/Vocational School  542    108   13.9    0.1188     NA      NA\niv=College degree or more          391     71   14.0    0.1275     NA      NA\n                                  0.95UCL\niv=0-11 years                          NA\niv=HS Diploma/GED                      NA\niv=Some College/Vocational School      NA\niv=College degree or more              NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\nn=3181, 82 observations deleted due to missingness.\n\n                                     N Observed Expected (O-E)^2/E (O-E)^2/V\niv=0-11 years                     1281      381    291.6     27.40     45.74\niv=HS Diploma/GED                  967      194    234.0      6.84     10.14\niv=Some College/Vocational School  542      108    131.9      4.32      5.36\niv=College degree or more          391       71     96.5      6.74      7.91\n\n Chisq= 46.4  on 3 degrees of freedom, p= 5e-10 \n\n\nThis model summary compares each of the four education levels in our variable. The mean survival years for those 0-11 is 13.2, for HS/Diploma/GED it is 13.8, for Some College/Vocational School it is 13.9 and for College degree or more it is 14. These are close to the averages we saw among smokers/nonsmokers, and non-diabetics. However, diabetics have still had the lowest average at 11 years. Once again, the medians could not be calculated for this variable because of the high proportion of groups surviving by the end of the time period.\nThe Log Rank test shows a p-value of &lt;0.0001. This leads us to reject the null and accept the alternative hypothesis that there is a significant difference in survival time between these groups (somewhere).\nThe survival probability at 10 years is 80% for the group 0-11, and around 90% for the other three groups. This is in the range of most groups thus far, aside from diabetics.\n\n\nPrevalence of Coronary Heart Disease\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$prevchd, \"CHD Prevalence\")\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n          n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=No  2903    582   13.8    0.0522     NA      NA      NA\niv=Yes  360    193   11.7    0.2077     14      12      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n          N Observed Expected (O-E)^2/E (O-E)^2/V\niv=No  2903      582    704.1      21.2       237\niv=Yes  360      193     70.9     210.4       237\n\n Chisq= 237  on 1 degrees of freedom, p= &lt;2e-16 \n\n\nThose without coronary heart disease had an average survival time of 13.8 years, while those with CHD had an average of 11.7 years. The median was only calculated for those with CHD, which was at 14 years. These metrics align with results from many other groups. the average survival years for those without CHD is comparable to the same metrics examined among the three highest education levels, smokers and non-smokers, and non-diabetics. Diabetics and those with CHD have similar average survival time.\nThe Log Rank Test shows a p-value of less than 0.0001. This leads us to reject the null and accept the alternative hypothesis that there is a difference in survival times between the two groups.\nLooking at the survival curve, the survival probability of those with CHD at 10 years is about 65%. The survival probability of those without CHD is around 90%. This is a comparable split to diabetics/non-diabetics.\n\n\nSex\n\n\nCode\nkm(sd$TimeDeathYears, sd$death, sd, sd$sex, \"Sex\")\n\n\n\n\n\nModel summary with mean and median: \nCall: survfit(formula = Surv(time, event) ~ iv, data = sd)\n\n             n events rmean* se(rmean) median 0.95LCL 0.95UCL\niv=Female 1876    345   13.9    0.0635     NA      NA      NA\niv=Male   1387    430   13.1    0.0894     NA      NA      NA\n    * restricted mean with upper limit =  15 \nCall:\nsurvdiff(formula = Surv(time, event) ~ iv, data = data)\n\n             N Observed Expected (O-E)^2/E (O-E)^2/V\niv=Female 1876      345      458      28.0      70.1\niv=Male   1387      430      317      40.5      70.1\n\n Chisq= 70.1  on 1 degrees of freedom, p= &lt;2e-16 \n\n\nFor the Kaplan-Meier examining sex, the model results show that the average survival time among females was 13.9 compared to male’s 13.1. This is a similar split between the highest and lowest education levels. Overall, this seems to be a significant difference, but not as big of a difference as CHD or diabetes status. The medians for these groups could not be calculated.\nThe Log Rank Test shows a p-value of less than 0.0001, which again leads us to accept the alternative hypothesis that this model shows a significant difference in survival time between the two groups.\nOn the survival curve, it appears that at 10 years, males had 80% survival probability, and females had about 90%. This is a much closer gap, agian comparable to the difference between education level. The gap is narrower among smokers and non-smokers, but larger when diabetes or CHD is examined."
  },
  {
    "objectID": "posts/Survival Analysis/index.html#reflections-on-cox-regression-vs.-kaplan-meier",
    "href": "posts/Survival Analysis/index.html#reflections-on-cox-regression-vs.-kaplan-meier",
    "title": "Survival Analysis in R",
    "section": "Reflections on Cox Regression vs. Kaplan-Meier",
    "text": "Reflections on Cox Regression vs. Kaplan-Meier\nThe cox regression showed that smoker status, diabetes status, education level (college degree or more), CHD status, age, and sex were all statistically significant in the model. The highest increased hazard ratios were from the variables for CHD and diabetes.\nWhen we examine the Kaplan-Meier and Log Rank tests, all categorical variables were significant except for smoker status. This difference was not expected. Being that the cox regression showed it as significant and with a fairly high hazard ratio, I expected to see a bigger difference in survival time. Perhaps this is due to comorbidities associated with this variable. But the two largest hazard ratios in the cox regression, diabetes and CHD, displayed the biggest differences in suvival time, which was expected. Also, variables like education and sex showed smaller but still present difference in line with cox regression results.\nCox regression is obviously necessary whenever you are interested in a continuous variable’s relationship to the outcome. It is also preferred when you have multiple groups in a categorical variables. As we saw in this project, education level was shown as significant using both methods. However, cox regression gave us a greater level of detail of increased risk within groups. The Kaplan-Meier (and Log Rank test) simply told us there was a significant difference somewhere within the groups.\nThere are other advantages to picking a particular method. For instance, if you are more interested in metrics like average survival time, KP delivers that information. If you are looking for information for example in a clinical trial, a cox regression may be preferable due to the hazard ratio it gives you. This may be more practical too if you are interested in multiple factors influencing an outcome. KP is limited to one factor at a time.\nLastly, Kaplan-Meier may be the most reliable method to use if you have data that do not meet the proper assumptions, as KP is a non-parametric test. Cox regression is semi-parametric, meaning there are some assumptions that must be met. In this way, it may be easier to apply KP to ill fitting data. But one method is not “better” than the other, they are simply different techniques that answer slightly different questions."
  },
  {
    "objectID": "posts/Bluets/index.html#introduction",
    "href": "posts/Bluets/index.html#introduction",
    "title": "Twitter Bots",
    "section": "Introduction",
    "text": "Introduction\nBlue is a color that moves me. I love how many forms it can take, the way its shades can channel moods. I recently reread my copy of Maggie Nelson’s Bluets and felt inspired to revisit an older project of mine. Possibly the first R project I put together (that was more fun, and not statistics or graphic related) was my twitter bot, everywordisblue.\nThis was a year or so back when I was just starting to dust off R and commit to learning the language fully. The original account was influenced by many of the silly bots on the website and my personal passion for the color blue. It took a randomly selected noun, pasted the word 'blue' in front of it, and posted it straight to Twitter once a day. While this creation gave me some immediate satisfaction (and some interesting results), I did feel that the account was a bit too simplistic; I always wanted to do more.\nInfinitely more satisfying would be a randomly selected hue of blue, shared daily, completely automated. To do this required editing my original script and, most importantly, web-scraping a data set of blue colors with accompanying hex codes. Follow along and let’s build something fun!"
  },
  {
    "objectID": "posts/Bluets/index.html#the-data",
    "href": "posts/Bluets/index.html#the-data",
    "title": "Twitter Bots",
    "section": "The Data",
    "text": "The Data\nOriginally, I attempted to find an existing data set. Most colors sets I’m familiar with using in R, however, are not as hyper-fixated on a singular color. I quickly found color-names.com, and noticed when you simply search for the word 'blue', the search provides over 89 pages (12 colors on each page), giving over a thousand colors with hex codes. This seemed like an adequate source for this project and a great way to practice web scraping data from R.\n\nUsing ‘rvest’\nTo help us source our data, the library 'rvest' provides everything we need. In order to create a data frame containing the color name and the hex code, we need to:\n\nimport the web search’s html\npull out the two elements from the code (name, hex code)\nthen repeat this process for each of the 89 pages\n\nThe function 'read_html' from rvest makes the first step incredibly easily. For this, we simply pass in the web address as an argument in the function and save the output as a new value called 'page'.\n\n\nCode\nlibrary(rvest)\nlink &lt;- \"https://www.color-name.com/search/blue\"\npage &lt;- read_html(link)\n\n\nNext, we’ll pass 'page' into the function 'html_nodes' and then into 'html_text' to extract the desired string vector. The text passed through 'html_nodes' must be sourced from the webpage you are scraping from. You can use the ‘inspect’ feature in Google Chrome, or the Chrome extension ‘SelectorGadget’ to find the proper tag to use.\n\n\nCode\nname &lt;- page |&gt; html_nodes(\"h2 a\") |&gt; html_text()\nhex &lt;- page |&gt; html_nodes(\".hx\") |&gt; html_text()\n\n\nOnce that is done, we can take both vectors and create a data frame.\n\n\nCode\ncolors &lt;- data.frame(name, hex, stringsAsFactors = FALSE)\n\n\nIn order to collect each page of data, it is easiest to use a for loop. For this we make a couple of changes. First, we will create an empty data frame titled 'colors' to store data in for each iteration of the loop. Because there are 89 pages, we set the for loop to iterate that many times. We store this as 'page_result' in the loop and change the url to match what is displayed on each page number then use 'paste0' to put them together. Lastly, I added 'rbind' to add the new rows to the 'colors' data frame and a print command to keep track of the loop progress.\n\n\nCode\ncolors &lt;- data.frame()\n\nfor (page_result in 1:89){\n  \n  link &lt;- paste0(\"https://www.color-name.com/search/blue/page/\", page_result)\n  \n  page &lt;- read_html(link)\n  \n  name &lt;- page |&gt; html_nodes(\"h2 a\") |&gt; html_text()\n  hex &lt;- page |&gt; html_nodes(\".hx\") |&gt; html_text()\n  \n  colors &lt;- rbind(colors, data.frame(name, hex, stringsAsFactors = FALSE))\n  \n  print(paste(\"Page:\", page_result))\n}\n\n\nAnd as a last step, I decided to clean up the colors a bit. Even though the search used the key word 'blue', I noticed that the last page displayed colors that did not have the word 'blue' in the title. To fix this, I filtered out any color that did not contain the word.\n\n\nCode\nlibrary(dplyr)\nblues &lt;- colors |&gt; filter(grepl('Blue', name))"
  },
  {
    "objectID": "posts/Bluets/index.html#the-script",
    "href": "posts/Bluets/index.html#the-script",
    "title": "Twitter Bots",
    "section": "The Script",
    "text": "The Script\nNow that we have the data, we need to make a script that randomly selects a color, creates a color square, saves it as an image, and posts a tweet. For all of this, we will load 'rtweet' and 'ggplot2'.\n\n\nCode\nlibrary(rtweet)\nlibrary(ggplot2)\n\n\nAfter importing, we need to create the token to interact with Twitter’s API. You can find a deeper dive into this process here. In my example below, I have stored my information as secrets in my Github repository.\n\n\nCode\nblues &lt;- read.csv(\"blues_dataset.csv\")[,-1] # import data \n\neverywordisblue_token &lt;- # Twitter token business\n  rtweet::rtweet_bot(\n   api_key =   Sys.getenv(\"TWITTER_CONSUMER_API_KEY\"),\n    api_secret = Sys.getenv(\"TWITTER_CONSUMER_API_SECRET\"),\n    access_token =    Sys.getenv(\"TWITTER_ACCESS_TOKEN\"),\n    access_secret =  Sys.getenv(\"TWITTER_ACCESS_TOKEN_SECRET\")\n  )\n\n\nNext we can select a single row in our main data frame by calling 'sample_n'. Then to separate the name and the hex code we can save each as an object and index using brackets.\n\n\nCode\nrandom_blue &lt;- sample_n(blues, 1)\n\ntemp &lt;- as.character(random_blue[1])\n\nblue_hex &lt;- as.character(random_blue[2])\n\n\nTo create a square with the randomly selected color, we can create an empty ggplot, add 'theme_void' to make it blank, and use theme to use the selected hex code. For this we use arguments 'plot.background' and 'panel.background'. Then we can use 'ggsave' to save a copy of this as an image and specify the desired path.\n\n\nCode\nblue_square &lt;- ggplot() + theme_void() +\n              theme(plot.background = element_rect(fill = blue_hex),\n              panel.background = element_rect(fill = blue_hex))\n\nggsave(paste0(\"blue_squares/\", temp, \".png\"), blue_square,\n       width = 150, height = 150, units = \"px\")\n\n\nNow that all the pieces are in place, we can assemble the tweet and sent it out! The function 'post_tweet' now requires that the user provides alt text (awesome!) so we will first save that (this will be the same for each tweet sent). We will also save an image path that changes each time the script is run using 'paste0' once again.\nTo send the actual tweet, we pull in each object to the 'post_tweet' and we are done!\n\n\nCode\nalt_text &lt;- \"A random shade of blue, sourced from color-name.com.\"\n\nimage_path &lt;- paste0(\"blue_squares/\", temp, \".png\")\n\nrtweet::post_tweet(status = temp, \n                   media = image_path, \n                   media_alt_text = alt_text,\n                   token = everywordisblue_token)"
  },
  {
    "objectID": "posts/Bluets/index.html#automation-with-github-actions",
    "href": "posts/Bluets/index.html#automation-with-github-actions",
    "title": "Twitter Bots",
    "section": "Automation with Github Actions",
    "text": "Automation with Github Actions\nGithub makes it surprisingly easy to automate scripts with Github Actions! Again for the full length guide on this process I will direct you to Matt Dray’s blog post which taught me how to properly set this bot up.\nEssentially, all that is needed in a yml file that lists the correct instructions on when and what to run. My example yml is below:\n\n\nCode\nname: blue-version-2\n\non:\n  schedule:\n    - cron: '0 0 * * *'  # once every day\n\njobs:\n  blue-post:\n    runs-on: macOS-latest\n    env:\n      TWITTER_CONSUMER_API_KEY: ${{ secrets.TWITTER_CONSUMER_API_KEY }}\n      TWITTER_CONSUMER_API_SECRET: ${{ secrets.TWITTER_CONSUMER_API_SECRET }}\n      TWITTER_ACCESS_TOKEN: ${{ secrets.TWITTER_ACCESS_TOKEN }}\n      TWITTER_ACCESS_TOKEN_SECRET: ${{ secrets.TWITTER_ACCESS_TOKEN_SECRET }}\n    steps:\n      - uses: actions/checkout@v2\n      - uses: r-lib/actions/setup-r@v2\n      - name: Install rtweet package\n        run: Rscript -e 'install.packages(\"rtweet\", dependencies = TRUE)'\n      - name: Install dplyr\n        run: Rscript -e 'install.packages(\"dplyr\", dependencies = TRUE)'\n      - name: Install ggplot2\n        run: Rscript -e 'install.packages(\"ggplot2\", dependencies = TRUE)'\n      - name: Create and post tweet\n        run: Rscript blue-script.R\n\n\nAnd that’s it! If you want to check out the live twitter bot you can follow it here."
  },
  {
    "objectID": "posts/Introducing the PLACES Package/index.html",
    "href": "posts/Introducing the PLACES Package/index.html",
    "title": "Introducing the CDCPLACES Package",
    "section": "",
    "text": "To begin, we can install the most recent version of CDCPLACES from github, then load our packages.\n\n\nCode\n# install from github\n# devtools::install_github(\"brendensm/CDCPLACES\")\n\nlibrary(CDCPLACES)\nlibrary(dplyr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "posts/Introducing the PLACES Package/index.html#introduction",
    "href": "posts/Introducing the PLACES Package/index.html#introduction",
    "title": "Introducing the CDCPLACES Package",
    "section": "",
    "text": "To begin, we can install the most recent version of CDCPLACES from github, then load our packages.\n\n\nCode\n# install from github\n# devtools::install_github(\"brendensm/CDCPLACES\")\n\nlibrary(CDCPLACES)\nlibrary(dplyr)\nlibrary(ggplot2)"
  },
  {
    "objectID": "posts/Introducing the PLACES Package/index.html#function-get_measures",
    "href": "posts/Introducing the PLACES Package/index.html#function-get_measures",
    "title": "Introducing the CDCPLACES Package",
    "section": "Function: get_measures",
    "text": "Function: get_measures\nOur first functions allows us to easily view what measures we can query, along with a brief definition. If we run get_measures, we must specify a release year. Then we can view the measures in a data frame in the R Studio viewer. If we instead print measures23, the pre-loaded data set, we see a preview.\n\n\nCode\nhead(measures23) %&gt;% tibble()\n\n\n# A tibble: 6 × 6\n  year  measureid short_question_text           measure       categoryid release\n  &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;                         &lt;chr&gt;         &lt;chr&gt;      &lt;chr&gt;  \n1 2021  OBESITY   Obesity                       Obesity amon… HLTHOUT    2023   \n2 2021  STROKE    Stroke                        Stroke among… HLTHOUT    2023   \n3 2021  ARTHRITIS Arthritis                     Arthritis am… HLTHOUT    2023   \n4 2020  SLEEP     Sleep &lt;7 hours                Sleeping les… RISKBEH    2023   \n5 2021  INDEPLIVE Independent Living Disability Independent … DISABLT    2023   \n6 2021  COGNITION Cognitive Disability          Cognitive di… DISABLT    2023   \n\n\nRemember to use the measureid when using the next function."
  },
  {
    "objectID": "posts/Introducing the PLACES Package/index.html#function-get_places",
    "href": "posts/Introducing the PLACES Package/index.html#function-get_places",
    "title": "Introducing the CDCPLACES Package",
    "section": "Function: get_places",
    "text": "Function: get_places\nThis function allows us to easily query data that we specify. In the example below, I will get the measure ACCESS2 (the current lack of health insurance among adults aged 18-64 years) for the state of Arizona. This function allows for multiple of these arguments.\n\n\nCode\naz_access &lt;- get_places(state = \"AZ\", measure = \"ACCESS2\") \nhead(az_access)\n\n\n# A tibble: 6 × 21\n  year  stateabbr statedesc locationname datasource category   measure          \n  &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;            \n1 2021  AZ        Arizona   Yuma         BRFSS      Prevention Current lack of …\n2 2021  AZ        Arizona   Graham       BRFSS      Prevention Current lack of …\n3 2021  AZ        Arizona   Apache       BRFSS      Prevention Current lack of …\n4 2021  AZ        Arizona   La Paz       BRFSS      Prevention Current lack of …\n5 2021  AZ        Arizona   Coconino     BRFSS      Prevention Current lack of …\n6 2021  AZ        Arizona   Cochise      BRFSS      Prevention Current lack of …\n# ℹ 14 more variables: data_value_unit &lt;chr&gt;, data_value_type &lt;chr&gt;,\n#   data_value &lt;dbl&gt;, low_confidence_limit &lt;dbl&gt;, high_confidence_limit &lt;dbl&gt;,\n#   totalpopulation &lt;chr&gt;, locationid &lt;chr&gt;, categoryid &lt;chr&gt;, measureid &lt;chr&gt;,\n#   datavaluetypeid &lt;chr&gt;, short_question_text &lt;chr&gt;, type &lt;chr&gt;, lon &lt;dbl&gt;,\n#   lat &lt;dbl&gt;\n\n\nIt is also worth noting that by default geo specifying geography is set to county. If instead we want to examine census tracts, we could specify the argument. Likewise, release is set to 2023."
  },
  {
    "objectID": "posts/Introducing the PLACES Package/index.html#use-case",
    "href": "posts/Introducing the PLACES Package/index.html#use-case",
    "title": "Introducing the CDCPLACES Package",
    "section": "Use Case",
    "text": "Use Case\nFrom here, we can start to have fun. It is fairly straight forward to begin exploring data. Here I will first filter out the data so that I can plot the age adjusted rates of lack of health insurance in Arizona.\nNotice that the data provide you with confidence limits, so I have chosen to plot them here with error bars.\n\n\nCode\naz_access %&gt;%\n  filter(datavaluetypeid == \"AgeAdjPrv\") %&gt;%\n  ggplot(aes(data_value, reorder(locationname, data_value))) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(xmin = low_confidence_limit, xmax = high_confidence_limit)) +\n  labs(title = \"Lack of health insurance among adults aged 18-64 years In Arizona Counties\",\n       y = \"\", x = \"Percent\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\nYou can also extend this to multiple states to compare. You can easily query two (or more) state names, and plot them. Arizona seems to have a couple of counties that have a much higher rate compared to others.\n\n\nCode\n# multi state comparison\ntwo &lt;- get_places(state = c(\"AZ\", \"NV\"), measure = \"ACCESS2\")\n\ntwo %&gt;%\n  filter(datavaluetypeid == \"AgeAdjPrv\") %&gt;%\n  ggplot(aes(data_value, reorder(locationname, data_value), color = stateabbr)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(xmin = low_confidence_limit, xmax = high_confidence_limit)) +\n  labs(title = \n         \"Lack of health insurance among adults aged 18-64 years In Arizona and Nevada\",\n       y = \"Counties\", x = \"Percent\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\nWe can go even further by comparing more states in the region. Here I have taken the average rate by state to easily compare. Texas appears to be far above the average.\n\n\nCode\nmulti &lt;- get_places(state = c(\"AZ\", \"NV\", \"NM\", \"TX\", \"CA\"), measure = \"ACCESS2\") %&gt;%\n  filter(datavaluetypeid == \"AgeAdjPrv\") %&gt;%\n  summarise(.by = \"stateabbr\", mean_val = mean(data_value), mean_low = mean(low_confidence_limit), mean_high = mean(high_confidence_limit))\n\nmulti %&gt;%\n  ggplot(aes(mean_val, reorder(stateabbr, mean_val), color = stateabbr)) +\n  geom_point(size = 2) +\n  geom_errorbar(aes(xmin = mean_low, xmax = mean_high)) +\n  labs(title = \"Mean lack of health insurance among adults aged 18-64 years In Southwest States\",\n       y = \"\", x = \"Percent\") +\n  theme_minimal() +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "projects/Tidy Tuesday/index.html#section-1",
    "href": "projects/Tidy Tuesday/index.html#section-1",
    "title": "Tidy Tuesday",
    "section": "2023",
    "text": "2023"
  },
  {
    "objectID": "projects/Tidy Tuesday/index.html#section",
    "href": "projects/Tidy Tuesday/index.html#section",
    "title": "Tidy Tuesday",
    "section": "",
    "text": "::: .g-col-12 .g-col-md-6} \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "posts/Introducing the PLACES Package/index.html#function-get_dictionary",
    "href": "posts/Introducing the PLACES Package/index.html#function-get_dictionary",
    "title": "Introducing the CDCPLACES Package",
    "section": "Function: get_dictionary",
    "text": "Function: get_dictionary\nOur first functions allows us to easily view what measures we can query, via ‘measureid’, along with a brief definition of each function. If we run get_dictionary, a data frame is returned. We can view the measures in a data frame in the R Studio with View(). This is the preferred method for exploring the available measures.\nFor our example here, I will print the names of the variables in this dataframe.\n\n\nCode\n# To open a viewer\n# get_dictionary() %&gt;% View()\n\nget_dictionary() %&gt;% names()\n\n\n [1] \"measureid\"                \"measure_full_name\"       \n [3] \"measure_short_name\"       \"categoryid\"              \n [5] \"category_name\"            \"places_release_2023\"     \n [7] \"places_release_2022\"      \"places_release_2021\"     \n [9] \"places_release_2020\"      \"_500_cities_release_2019\"\n[11] \"_500_cities_release_2018\" \"_500_cities_release_2017\"\n[13] \"_500_cities_release_2016\" \"frequency_brfss_year\"    \n\n\nThis data frame is useful for several reasons. It lists the available measures for each year of the CDC PLACES data, along with the data each variable was collected, all in a single place. Remember to use the measureid when querying your data."
  },
  {
    "objectID": "index.html#brenden-smith",
    "href": "index.html#brenden-smith",
    "title": "Brenden Smith",
    "section": "",
    "text": "Hi, I’m Brenden. I am an MPH candidate with interests in health equity, harm reduction, and community engagement. I am a data analyst, community researcher, and R enthusiast.\nIf you would like to see some of my current and past work, you can visit my portfolio page or check out my blog."
  },
  {
    "objectID": "projects/R Shiny Apps/Mental Health and the Pandemic/index.html",
    "href": "projects/R Shiny Apps/Mental Health and the Pandemic/index.html",
    "title": "Mental Health and the Pandemic",
    "section": "",
    "text": "Introduction\nThis project was originally a submission to the National Center for Health Statistics and AcademyHealth sponsored Data Visualization Challenge in Fall of 2022.\nThis web application was my first experience building a Shiny application! I found it fascinating to dive into the mechanics of making a usable, interactive web application for data exploration.\nThis project uses data from the Household Pulse Survey as well as data from the Uniform Data System to understand mental illness during the pandemic years. HHP data shows national trends for varying mental illnesses while the UDS data speaks to the experience of patients accessing care at federally qualified health centers throughout the country. We added this data and compared it with poverty rates across U.S. counties (American Community Survey) and mental health provider shortage levels (Area Health Resources Files).\nMy favorite part of this challenge was getting to create large, interactive maps to explore these data.\nWhile the application could be embedded here, it is best viewed in its own window. You can access the app and the full data here."
  },
  {
    "objectID": "projects/shiny.html",
    "href": "projects/shiny.html",
    "title": "R Shiny Apps",
    "section": "",
    "text": "Sugar Smart Coalition Lansing - Nutrition Calculator\n\n\nCalculator\n\n\n\nBrenden Smith\n\n\nJan 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMental Health and the Pandemic\n\n\nNCHS/AcademyHealth Data Visualization Challenge Submission\n\n\n\nBrenden Smith\n\n\nNov 14, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/R Shiny Apps/index.html#mental-health-and-the-pandemic",
    "href": "projects/R Shiny Apps/index.html#mental-health-and-the-pandemic",
    "title": "R Shiny Apps",
    "section": "Mental Health and the Pandemic",
    "text": "Mental Health and the Pandemic\nThis project was originally a submission to the National Center for Health Statistics and AcademyHealth sponsored Data Visualization Challenge in Fall of 2022.\nThis web application was my first experience building a Shiny application! I found it fascinating to dive into the mechanics of making a usable, interactive web application for data exploration.\nThis project uses data from the Household Pulse Survey as well as data from the Uniform Data System to understand mental illness during the pandemic years. HHP data shows national trends for varying mental illnesses while the UDS data speaks to the experience of patients accessing care at federally qualified health centers throughout the country. We added this data and compared it with poverty rates across U.S. counties (American Community Survey) and mental health provider shortage levels (Area Health Resources Files).\nMy favorite part of this challenge was getting to create large, interactive maps to explore these data.\nWhile the application could be embedded here, it is best viewed in its own window. You can access the app and the full data here."
  },
  {
    "objectID": "projects/R Shiny Apps/index.html#cdcplaces-data-explorer",
    "href": "projects/R Shiny Apps/index.html#cdcplaces-data-explorer",
    "title": "R Shiny Apps",
    "section": "CDCPLACES Data Explorer",
    "text": "CDCPLACES Data Explorer"
  },
  {
    "objectID": "posts/Shapefiles in CDCPLACES/index.html",
    "href": "posts/Shapefiles in CDCPLACES/index.html",
    "title": "Shapefiles in CDCPLACES 1.1.5",
    "section": "",
    "text": "With the most recent development release of CDCPLACES, users can now request an sf data frame to allow for simple, streamlined mapping of PLACES data. To use this new feature, be sure to install the latest development version from GitHub.\n\n\nCode\n# Install the latest development version\n# devtools::install_github(\"brendensm/CDCPLACES\")\n\nlibrary(CDCPLACES)\nlibrary(ggplot2)\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/Shapefiles in CDCPLACES/index.html#introduction",
    "href": "posts/Shapefiles in CDCPLACES/index.html#introduction",
    "title": "Shapefiles in CDCPLACES 1.1.5",
    "section": "",
    "text": "With the most recent development release of CDCPLACES, users can now request an sf data frame to allow for simple, streamlined mapping of PLACES data. To use this new feature, be sure to install the latest development version from GitHub.\n\n\nCode\n# Install the latest development version\n# devtools::install_github(\"brendensm/CDCPLACES\")\n\nlibrary(CDCPLACES)\nlibrary(ggplot2)\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/Shapefiles in CDCPLACES/index.html#new-arguement-geometry",
    "href": "posts/Shapefiles in CDCPLACES/index.html#new-arguement-geometry",
    "title": "Shapefiles in CDCPLACES 1.1.5",
    "section": "New arguement geometry",
    "text": "New arguement geometry\n\n\nCode\nmi &lt;- get_places(state = \"MI\", measure = \"SLEEP\", geometry = TRUE)\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |                                                                      |   1%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |==                                                                    |   4%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=====                                                                 |   8%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |=======                                                               |   9%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |=======                                                               |  11%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  12%\n  |                                                                            \n  |===========                                                           |  15%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |============                                                          |  16%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |============                                                          |  18%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |==============                                                        |  19%\n  |                                                                            \n  |==============                                                        |  20%\n  |                                                                            \n  |==============                                                        |  21%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |===============                                                       |  22%\n  |                                                                            \n  |================                                                      |  22%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  24%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |===================                                                   |  27%\n  |                                                                            \n  |===================                                                   |  28%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |====================                                                  |  29%\n  |                                                                            \n  |=====================                                                 |  29%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |=====================                                                 |  31%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |======================                                                |  32%\n  |                                                                            \n  |=======================                                               |  32%\n  |                                                                            \n  |=======================                                               |  33%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |=========================                                             |  35%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  36%\n  |                                                                            \n  |==========================                                            |  37%\n  |                                                                            \n  |==========================                                            |  38%\n  |                                                                            \n  |===========================                                           |  38%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |============================                                          |  41%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |===============================                                       |  45%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |=================================                                     |  46%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |=================================                                     |  48%\n  |                                                                            \n  |==================================                                    |  48%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |===================================                                   |  51%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |====================================                                  |  52%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |======================================                                |  54%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |=======================================                               |  55%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |========================================                              |  56%\n  |                                                                            \n  |========================================                              |  57%\n  |                                                                            \n  |========================================                              |  58%\n  |                                                                            \n  |=========================================                             |  58%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |==========================================                            |  61%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |============================================                          |  62%\n  |                                                                            \n  |============================================                          |  63%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |=============================================                         |  65%\n  |                                                                            \n  |==============================================                        |  65%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  66%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |===============================================                       |  68%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |=================================================                     |  69%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |=================================================                     |  71%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |==================================================                    |  72%\n  |                                                                            \n  |===================================================                   |  72%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=====================================================                 |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |======================================================                |  76%\n  |                                                                            \n  |======================================================                |  77%\n  |                                                                            \n  |======================================================                |  78%\n  |                                                                            \n  |=======================================================               |  78%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |========================================================              |  79%\n  |                                                                            \n  |========================================================              |  80%\n  |                                                                            \n  |========================================================              |  81%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |==========================================================            |  82%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |===========================================================           |  85%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |============================================================          |  86%\n  |                                                                            \n  |=============================================================         |  86%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |=============================================================         |  88%\n  |                                                                            \n  |==============================================================        |  88%\n  |                                                                            \n  |==============================================================        |  89%\n  |                                                                            \n  |===============================================================       |  89%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |===============================================================       |  91%\n  |                                                                            \n  |================================================================      |  91%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |=================================================================     |  92%\n  |                                                                            \n  |=================================================================     |  93%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |==================================================================    |  95%\n  |                                                                            \n  |===================================================================   |  95%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |====================================================================  |  98%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================|  99%\n  |                                                                            \n  |======================================================================| 100%\n\n\nCode\nmi |&gt; \n  filter(datavaluetypeid == \"AgeAdjPrv\") |&gt; \n  ggplot(aes(fill = data_value)) +\n  geom_sf() +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  theme_minimal() +\n  labs(title = mi$measure) +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\nCode\nvt &lt;- get_places(geo = \"census\", state = c(\"VT\"), measure = \"SLEEP\", geometry = TRUE)\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |===========                                                           |  16%\n  |                                                                            \n  |=============                                                         |  18%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |======================                                                |  31%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |================================                                      |  46%\n  |                                                                            \n  |====================================                                  |  51%\n  |                                                                            \n  |=====================================                                 |  53%\n  |                                                                            \n  |=======================================                               |  56%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |====================================================                  |  74%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |=========================================================             |  82%\n  |                                                                            \n  |===========================================================           |  84%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |===============================================================       |  89%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |======================================================================| 100%\n\n\nCode\nvt |&gt; \n  ggplot(aes(fill = data_value)) +\n  geom_sf(color = \"grey30\") +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  theme_minimal() +\n  labs(title = vt$measure) +\n  theme(plot.title.position = \"plot\")"
  },
  {
    "objectID": "posts/Shapefiles in CDCPLACES/index.html#acknowledgements",
    "href": "posts/Shapefiles in CDCPLACES/index.html#acknowledgements",
    "title": "Shapefiles in CDCPLACES 1.1.5",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese features would not be possible without the excellent work of Kyle Walker’s package tigris. The contributions he has made to the R community have been incredibly inspiring to me. His other package, tidycensus was the inspiration for this entire pacakge. To see his work visit his website here."
  },
  {
    "objectID": "posts/Shapefiles in CDCPLACES/index.html#new-argument-geometry",
    "href": "posts/Shapefiles in CDCPLACES/index.html#new-argument-geometry",
    "title": "Shapefiles in CDCPLACES 1.1.5",
    "section": "New argument geometry",
    "text": "New argument geometry\nFirst we need to query our data. To include our shape file, we need to specify the argument geometry as “TRUE”. For our first example we will look at the percentage of adults sleeping less than 7 hours in Michigan Counties.\n\n\nCode\nmi &lt;- get_places(state = \"MI\", measure = \"SLEEP\", geometry = TRUE)\n\n\nNow we can take this dataset and immediately plot the spatial data with ggplot2. I will also add a nicer looking color palette and the percentage scale in scale_fill_viridis_c, as well as a title with the function labs.\n\n\nCode\nmi |&gt; \n  filter(datavaluetypeid == \"AgeAdjPrv\") |&gt; \n  ggplot(aes(fill = data_value)) +\n  geom_sf() +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  theme_minimal() +\n  labs(title = mi$measure) +\n  theme(plot.title.position = \"plot\")\n\n\n\n\n\nWe can do the same for census level data. This is as simple as specifying our geography to “census”.\n\n\nCode\nvt &lt;- get_places(geo = \"census\", state = \"VT\", measure = \"SLEEP\", geometry = TRUE)\n\n\nThen we can map it just the same.\n\n\nCode\nvt |&gt; \n  ggplot(aes(fill = data_value)) +\n  geom_sf() +\n  scale_fill_viridis_c(labels = scales::percent_format(scale = 1)) +\n  theme_minimal() +\n  labs(title = vt$measure) +\n  theme(plot.title.position = \"plot\")"
  }
]