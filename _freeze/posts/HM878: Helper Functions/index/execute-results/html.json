{
  "hash": "f584d0500c1a6efad2a53f86c8e84ff9",
  "result": {
    "markdown": "---\ntitle: \"HM878: Helper Functions\"\nauthor: \"Brenden Smith\"\ndate: \"2023-10-12\"\ncategories: [R, packages, vignette]\ndescription: \"A walkthrough of the helper functions in the package `hm878`\"\nexecute: \n  warning: false\nimage: rp.png\ncode-overflow: scroll\n\n---\n\n\n# Introduction\n\nThis vignette demonstrates how to use the functions included in this package so far. If you have not yet, install the package with the following code: `devtools::install_github(\"brendensm/hm878\")`. If you do not have the package devtools, be sure to install that first `install.packages(\"devtools\")`.\n\nTo start, we load the package\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(hm878)\n```\n:::\n\n\nLet's assume we are running a binomial logistic regression using the data from `mtcars`, a built-in data set included with R. We will use `vs` (engine type as V-shaped or straight) as the dependent variable, and `cyl` (number of cylinders) as the independent variable. We will store our models for block 1 and block 2.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmb1 <- glm(vs ~ 1, data = mtcars, family = \"binomial\")\nmb2 <- glm(vs ~ cyl, data = mtcars, family = \"binomial\")\n```\n:::\n\n\n## Testing Goodness of Fit with `chi_log`\nTo assess the fit of our models, we may want to use the function `chi_log`. To use it, simply type in the name of your model as the first argument, followed by the data set that the model uses. Optionally, you can provide labels for each model using the third argument. Here I will label each block.\n\n::: {.cell}\n\n```{.r .cell-code}\nchi_log(mb1, mtcars, \"Block 1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPearson Goodness of Fit Test\n\n Null Hypothesis: The model fits\n Alternative Hypothesis: the model does not fit\n\n Pearson chi-squared for  Block 1:  32 \n Degrees of freedom for  Block 1:  31 \n P-value for  Block 1:  0.416744 \n```\n:::\n\n```{.r .cell-code}\nchi_log(mb2, mtcars, \"Block 2\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPearson Goodness of Fit Test\n\n Null Hypothesis: The model fits\n Alternative Hypothesis: the model does not fit\n\n Pearson chi-squared for  Block 2:  27.42 \n Degrees of freedom for  Block 2:  30 \n P-value for  Block 2:  0.6013516 \n```\n:::\n:::\n\nThe function gives us the chi-squared statistic, degrees of freedom, and a p-value. It also reminds us of the null and alternative hypotheses. Both models appear to be a good fit.\n\n## Accuracy Percentage with `predict_percent`\nWe may want to also check the accuracy of our models. To do this, we can use `predict_percent`. To use this function, enter the name of the model in the first argument, followed by the dependent variable we used in the model. For this, we must use the data$variable format. In the example below, we use the variable `vs` from the data set `mtcars`. Once again, we can label the output with a string as the optional third argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict_percent(mb1, mtcars$vs, \"Block 1\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy for Block 1: 56.25%\n```\n:::\n\n```{.r .cell-code}\npredict_percent(mb2, mtcars$vs, \"Block 2\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAccuracy for Block 2: 84.38%\n```\n:::\n:::\n\n\n## Calculating Odds Ratios with `or`\nTo calculate odds ratios for the models, simply pass the model through the function `or`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nor(mb1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Odds_Ratio  CI_Lower CI_Upper  p_values\n(Intercept)  0.7777778 0.3801366 1.558936 0.4806496\n```\n:::\n\n```{.r .cell-code}\nor(mb2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Odds_Ratio    CI_Lower     CI_Upper    p_values\n(Intercept) 10873.447296 95.35600799 6.507716e+07 0.002692584\ncyl             0.204474  0.04827075 4.455527e-01 0.001917098\n```\n:::\n:::\n\nThe output results in a data frame with the odds ratios, confidence intervals, and p-values.\n\n## Upper and Lower Fences with `fences`\nIf you want to revise and adjust your model, it can be helpful to limit outliers. To find upper and lower fences quickly, use the function `fences`. To do this, pass the continuous variable you are interested in examining through the function. Once again, use the format data$variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfences(mtcars$cyl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Lower Fence: -2 \n Upper Fence: 14\n```\n:::\n:::\n\n\n\n## Comparing Model Results with `compare_models`\nLastly, when you are putting together multiple models, it can be helpful to view them all at the same time, next to one another. This is particularly helpful if you have more than two models you are comparing. For this function, pass through however many models you have to compare, and optionally label each one, using a vector of strings for each model. To demonstrate, I will add on another model `mb3` that will have another continuous independent variable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmb3 <- glm(vs ~ cyl + wt, data = mtcars, family = \"binomial\")\n\ncompare_models(mb1, mb2, mb3, labels = c(\"Model 1 Block 1\", \"Model 1 Block 2\", \"Model Block 3\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$`Model 1 Block 1`\n\nCall:  glm(formula = vs ~ 1, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)  \n    -0.2513  \n\nDegrees of Freedom: 31 Total (i.e. Null);  31 Residual\nNull Deviance:\t    43.86 \nResidual Deviance: 43.86 \tAIC: 45.86\n\n$`Model 1 Block 2`\n\nCall:  glm(formula = vs ~ cyl, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl  \n      9.294       -1.587  \n\nDegrees of Freedom: 31 Total (i.e. Null);  30 Residual\nNull Deviance:\t    43.86 \nResidual Deviance: 17.96 \tAIC: 21.96\n\n$`Model Block 3`\n\nCall:  glm(formula = vs ~ cyl + wt, family = \"binomial\", data = mtcars)\n\nCoefficients:\n(Intercept)          cyl           wt  \n     10.619       -2.931        2.100  \n\nDegrees of Freedom: 31 Total (i.e. Null);  29 Residual\nNull Deviance:\t    43.86 \nResidual Deviance: 15.55 \tAIC: 21.55\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}